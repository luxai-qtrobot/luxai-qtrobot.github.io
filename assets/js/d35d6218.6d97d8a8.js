"use strict";(self.webpackChunkqtrobot_documentation=self.webpackChunkqtrobot_documentation||[]).push([[5581],{7217:(e,o,t)=>{t.r(o),t.d(o,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>n,metadata:()=>c,toc:()=>h});var r=t(5893),s=t(1151),i=t(9656);const n={id:"python_ros_services",title:"QTrobot interfaces using ROS Services",hide_table_of_contents:!0},a=void 0,c={id:"tutorials/python/python_ros_services",title:"QTrobot interfaces using ROS Services",description:"signalcellularalt &nbsp;Level:&nbsp; Basic",source:"@site/docs/tutorials/python/python_ros_services.mdx",sourceDirName:"tutorials/python",slug:"/tutorials/python/python_ros_services",permalink:"/docs/tutorials/python/python_ros_services",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"python_ros_services",title:"QTrobot interfaces using ROS Services",hide_table_of_contents:!0},sidebar:"code_tutorials_sidebar",previous:{title:"QTrobot interfaces using ROS Publishers",permalink:"/docs/tutorials/python/python_ros_publish"},next:{title:"QTrobot interfaces using ROS Subscribe",permalink:"/docs/tutorials/python/python_ros_subscribe"}},l={},h=[{value:"Create a python project",id:"create-a-python-project",level:2},{value:"QTrobot speech service",id:"qtrobot-speech-service",level:2},{value:"QTrobot talk text service",id:"qtrobot-talk-text-service",level:2},{value:"QTrobot emotion service",id:"qtrobot-emotion-service",level:2},{value:"QTrobot gesture service",id:"qtrobot-gesture-service",level:2},{value:"QTrobot audio service",id:"qtrobot-audio-service",level:2}];function d(e){const o={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(o.admonition,{title:"Overview",type:"info",children:[(0,r.jsxs)(o.p,{children:[(0,r.jsx)(i.Z,{children:"signal_cellular_alt"})," \xa0",(0,r.jsx)(o.strong,{children:"Level:"}),"\xa0 ",(0,r.jsx)(o.em,{children:"Basic"}),"\n",(0,r.jsx)("br",{})," ",(0,r.jsx)(i.Z,{children:" track_changes "})," \xa0",(0,r.jsx)(o.strong,{children:"Goal:"}),"\xa0 ",(0,r.jsx)(o.em,{children:"learn how to access QTrobot interfaces such as speech, emotion, gesture, etc. in python via ROS Services"}),"\n",(0,r.jsx)("br",{})," ",(0,r.jsx)(i.Z,{children:" task_alt "})," \xa0",(0,r.jsx)(o.strong,{children:"Requirements:"})]}),(0,r.jsxs)(o.ul,{children:["\n",(0,r.jsxs)(o.li,{children:["\xa0\xa0",(0,r.jsx)(o.a,{href:"/docs/intro_code",children:"Quick start with coding on QTrobot"})]}),"\n",(0,r.jsxs)(o.li,{children:["\xa0\xa0",(0,r.jsx)(o.a,{href:"/docs/tutorials/python/python_ros_project",children:"Create a ROS python project"})]}),"\n"]})]}),"\n",(0,r.jsxs)(o.p,{children:["If you have followed our previous tutorials, you should know how to start coding on QTrobot with python and got the basic knowledge of ROS framework. In this tutorial we will learn about how to access ",(0,r.jsx)(o.a,{href:"/docs/api_ros#list-of-available-interfaces",children:"QTrobot interfaces"})," such as speech and audio interface using ROS Services."]}),"\n",(0,r.jsx)(o.h2,{id:"create-a-python-project",children:"Create a python project"}),"\n",(0,r.jsxs)(o.p,{children:["First we create a python project for our tutorial. let's call it ",(0,r.jsx)(o.code,{children:"tutorial_qt_service"})," and add the required python file:"]}),"\n",(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{children:'cd ~/catkin_ws/src\ncatkin_create_pkg tutorial_qt_service rospy roscpp -D "Command QTrobot via ROS Services"\ncd tutorial_qt_service/src\ntouch tutorial_qt_service_node.py\nchmod +x tutorial_qt_service_node.py\n'})}),"\n",(0,r.jsx)(o.h2,{id:"qtrobot-speech-service",children:"QTrobot speech service"}),"\n",(0,r.jsxs)(o.p,{children:["Open the ",(0,r.jsx)(o.code,{children:"tutorial_qt_service_node.py"})," file and add the following code:"]}),"\n",(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{className:"language-python",children:"#!/usr/bin/env python\nimport sys\nimport rospy\nfrom qt_robot_interface.srv import *\n\nif __name__ == '__main__':\n    rospy.init_node('my_tutorial_node')\n    rospy.loginfo(\"my_tutorial_node started!\")\n\n    # define a ros service\n    speechSay = rospy.ServiceProxy('/qt_robot/speech/say', speech_say)\n    \n    # block/wait for ros service\n    rospy.wait_for_service('/qt_robot/speech/say') \n   \n    try:\n        # call a ros service with text message\n        speechSay(\"Hello! This is QT talking using text to speech\")\n    except KeyboardInterrupt:\n        pass\n\n    rospy.loginfo(\"finsihed!\")\n\n"})}),"\n",(0,r.jsxs)(o.p,{children:["ROS Services are defined by srv files, which contains a request message and a response message. First we import all from ",(0,r.jsx)(o.code,{children:"qt_robot_interface.srv"}),". This will import all srv files that are under ",(0,r.jsx)(o.code,{children:"qt_robot_interface.srv"}),". We need to use ",(0,r.jsx)(o.code,{children:"speech_say"}),"."]}),"\n",(0,r.jsxs)(o.admonition,{title:"Tip",type:"tip",children:[(0,r.jsx)(o.p,{children:"How do we know which parameters an interface uses? well, There is a useful command in ROS which tells you that:"}),(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{children:"rosservice info /qt_robot/speech/say\nType: qt_robot_interface/speech_say\nArgs: message\n...\n"})})]}),"\n",(0,r.jsxs)(o.p,{children:["Then we defined a service ",(0,r.jsx)(o.code,{children:"/qt_robot/speech/say"})," and call ",(0,r.jsx)(o.code,{children:"rospy.wait_for_service()"})," to block until a service is available."]}),"\n",(0,r.jsx)(o.p,{children:"Finally we called a ROS service with a text message to QTrobot speech interface which makes the robot read that message."}),"\n",(0,r.jsx)(o.h2,{id:"qtrobot-talk-text-service",children:"QTrobot talk text service"}),"\n",(0,r.jsxs)(o.p,{children:["The ",(0,r.jsx)(o.code,{children:"/qt_robot/behavior/talkText"})," interface is similar to ",(0,r.jsx)(o.code,{children:"/qt_robot/speech/say"})," interface with the only different that the talkText interface asks QTrobot to move his lips while reading the text messages. To try it, just add the following lines to our code:"]}),"\n",(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{className:"language-python",children:"behaviorTalkText = rospy.ServiceProxy('/qt_robot/behavior/talkText', behavior_talk_text)\nrospy.wait_for_service('/qt_robot/behavior/talkText')\nbehaviorTalkText(\"I am QT robot!\")\n"})}),"\n",(0,r.jsx)(o.h2,{id:"qtrobot-emotion-service",children:"QTrobot emotion service"}),"\n",(0,r.jsxs)(o.p,{children:["Now lets show an emotion on QTrobot face. QTrobot comes with plenty of predefined emotion animations. You can find the complete list of the available emotions either using the ",(0,r.jsx)(o.em,{children:"QTrobot Educator app"})," or by looking into the ",(0,r.jsx)(o.code,{children:"~/robot/data/emotions"})," folder in ",(0,r.jsx)(o.strong,{children:"QTRP"}),"."]}),"\n",(0,r.jsx)(o.p,{children:"Add the following lines to our code to show the 'happy' emotion under 'QT' category on QTrobot face:"}),"\n",(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{className:"language-python",children:"emotionShow = rospy.ServiceProxy('/qt_robot/emotion/show', emotion_show)\nrospy.wait_for_service('/qt_robot/emotion/show')\nemotionShow(\"QT/happy\")\n"})}),"\n",(0,r.jsx)(o.admonition,{title:"Note",type:"note",children:(0,r.jsxs)(o.p,{children:["As it shown in the above example, you should ",(0,r.jsx)(o.strong,{children:"not"})," give the emotion's file extension (",(0,r.jsx)(o.code,{children:".avi"}),") to the interface!"]})}),"\n",(0,r.jsx)(o.h2,{id:"qtrobot-gesture-service",children:"QTrobot gesture service"}),"\n",(0,r.jsxs)(o.p,{children:["Now lets play a gesture with QTrobot. QTrobot comes with plenty of predefined gestures. You can find the complete list of the available gestures either using the ",(0,r.jsx)(o.em,{children:"QTrobot Educator app"})," or by looking into the ",(0,r.jsx)(o.code,{children:"~/robot/data/gestures"})," folder in ",(0,r.jsx)(o.strong,{children:"QTRP"}),"."]}),"\n",(0,r.jsx)(o.p,{children:"Add the following lines to our code to play the 'clapping' gesture under 'QT' category:"}),"\n",(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{className:"language-python",children:"from qt_gesture_controller.srv import gesture_play\n\ngesturePlay = rospy.ServiceProxy('/qt_robot/gesture/play', gesture_play)\nrospy.wait_for_service('/qt_robot/gesture/play')\ngesturePlay(\"QT/happy\", 0)\n"})}),"\n",(0,r.jsx)(o.admonition,{title:"Note",type:"note",children:(0,r.jsxs)(o.p,{children:["As it shown in the above example, you should ",(0,r.jsx)(o.strong,{children:"not"})," give the gestures's file extension (",(0,r.jsx)(o.code,{children:".xml"}),") to the interface!"]})}),"\n",(0,r.jsx)(o.h2,{id:"qtrobot-audio-service",children:"QTrobot audio service"}),"\n",(0,r.jsxs)(o.p,{children:["Now lets play an audio file on QTrobot. QTrobot comes with some audio examples. You can find the complete list of the available audios either using the ",(0,r.jsx)(o.em,{children:"QTrobot Educator app"})," or by looking into the ",(0,r.jsx)(o.code,{children:"~/robot/data/audios"})," folder in ",(0,r.jsx)(o.strong,{children:"QTRP"}),".  QTrobot can play both audio ",(0,r.jsx)(o.em,{children:"wave"})," and ",(0,r.jsx)(o.em,{children:"mp3"})," files."]}),"\n",(0,r.jsx)(o.p,{children:"Add the following lines to our code to play the 'Komiku_Glouglou' audio file under 'QT' category:"}),"\n",(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{className:"language-python",children:"audioPlay = rospy.ServiceProxy('/qt_robot/audio/play', audio_play)\nrospy.wait_for_service('/qt_robot/audio/play')\naudioPlay(\"QT/Komiku_Glouglou\", \"\")\n"})}),"\n",(0,r.jsx)(o.admonition,{title:"Note",type:"note",children:(0,r.jsxs)(o.p,{children:["As it shown in the above example, you do not need to give the audio's file extension (",(0,r.jsx)(o.code,{children:".wav"})," or ",(0,r.jsx)(o.code,{children:".mp3"}),") to the interface!"]})})]})}function p(e={}){const{wrapper:o}={...(0,s.a)(),...e.components};return o?(0,r.jsx)(o,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);