"use strict";(self.webpackChunkqtrobot_documentation=self.webpackChunkqtrobot_documentation||[]).push([[4799],{4069:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>d,contentTitle:()=>c,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>l});var o=t(5893),s=t(1151),n=t(9656);const a={id:"python_ros_record",title:"QTrobot recording new gesture",hide_table_of_contents:!0},c=void 0,i={id:"tutorials/python/python_ros_record",title:"QTrobot recording new gesture",description:"signalcellularalt &nbsp;Level:&nbsp; Intermediate",source:"@site/docs/tutorials/python/python_ros_gestures.mdx",sourceDirName:"tutorials/python",slug:"/tutorials/python/python_ros_record",permalink:"/docs/tutorials/python/python_ros_record",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"python_ros_record",title:"QTrobot recording new gesture",hide_table_of_contents:!0},sidebar:"code_tutorials_sidebar",previous:{title:"Configure QTrobot TTS language",permalink:"/docs/tutorials/python/python_ros_speech"},next:{title:"Commanding QTrobot motors",permalink:"/docs/tutorials/python/python_ros_motors"}},d={},l=[{value:"Create a python project",id:"create-a-python-project",level:2},{value:"Code",id:"code",level:2},{value:"Explanation",id:"explanation",level:2}];function h(e){const r={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(r.admonition,{title:"Overview",type:"info",children:[(0,o.jsxs)(r.p,{children:[(0,o.jsx)(n.Z,{children:"signal_cellular_alt"})," \xa0",(0,o.jsx)(r.strong,{children:"Level:"}),"\xa0 ",(0,o.jsx)(r.em,{children:"Intermediate"}),"\r\n",(0,o.jsx)("br",{})," ",(0,o.jsx)(n.Z,{children:" track_changes "})," \xa0",(0,o.jsx)(r.strong,{children:"Goal:"}),"\xa0 ",(0,o.jsx)(r.em,{children:"learn how to record and play custom gesture with QTrobot Gesture interface"}),"\r\n",(0,o.jsx)("br",{})," ",(0,o.jsx)(n.Z,{children:" task_alt "})," \xa0",(0,o.jsx)(r.strong,{children:"Requirements:"})]}),(0,o.jsxs)(r.ul,{children:["\n",(0,o.jsxs)(r.li,{children:["\xa0\xa0",(0,o.jsx)(r.a,{href:"/docs/intro_code",children:"Quick start with coding on QTrobot"})]}),"\n",(0,o.jsxs)(r.li,{children:["\xa0\xa0",(0,o.jsx)(r.a,{href:"/docs/tutorials/python/python_ros_project",children:"Create a ROS python project"})]}),"\n",(0,o.jsxs)(r.li,{children:["\xa0\xa0",(0,o.jsx)(r.a,{href:"/docs/tutorials/python/python_ros_services",children:"QTrobot interfaces using ROS Services"})]}),"\n"]})]}),"\n",(0,o.jsxs)(r.p,{children:["In this tutorial you will learn how to record and play custom gesture with ",(0,o.jsx)(r.a,{href:"/docs/api_ros#gesture-interface",children:"QTrobot Gesture interface"})," using python."]}),"\n",(0,o.jsx)(r.h2,{id:"create-a-python-project",children:"Create a python project"}),"\n",(0,o.jsxs)(r.p,{children:["First we create a python project for our tutorial. let's call it ",(0,o.jsx)(r.code,{children:"tutorial_qt_record"})," and add the required python file:"]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:'cd ~/catkin_ws/src\r\ncatkin_create_pkg tutorial_qt_record rospy roscpp -D "Record new gestures"\r\ncd tutorial_qt_record/src\r\ntouch tutorial_qt_record_node.py\r\nchmod +x tutorial_qt_record_node.py\n'})}),"\n",(0,o.jsx)(r.h2,{id:"code",children:"Code"}),"\n",(0,o.jsx)(r.p,{children:"Lets see how we can record and play a new gesture."}),"\n",(0,o.jsxs)(r.p,{children:["Open the ",(0,o.jsx)(r.code,{children:"tutorial_qt_record_node.py"})," file and add the following code:"]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-python",children:"#!/usr/bin/env python\r\nimport sys\r\nimport rospy\r\nfrom qt_robot_interface.srv import *\r\nfrom qt_gesture_controller.srv import *\r\nfrom qt_motors_controller.srv import *\r\n\r\nif __name__ == '__main__':\r\n    rospy.init_node('my_tutorial_node')\r\n    rospy.loginfo(\"my_tutorial_node started!\")\r\n\r\n    speechSay = rospy.ServiceProxy('/qt_robot/speech/say', speech_say)\r\n    gestureRecord = rospy.ServiceProxy('/qt_robot/gesture/record', gesture_record)\r\n    gestureSave = rospy.ServiceProxy('/qt_robot/gesture/save', gesture_save)\r\n    setControlMode = rospy.ServiceProxy('/qt_robot/motors/setControlMode', set_control_mode)\r\n    gesturePlay = rospy.ServiceProxy('/qt_robot/gesture/play', gesture_play)\r\n\r\n\r\n    try:\r\n        name = \"my_gesture\"\r\n        parts = [\"left_arm\"]\r\n        input('Press enter to START recording ...\\n')\r\n        speechSay('Press enter to START recording.')\r\n        res = gestureRecord(parts, True, 0, 0)\r\n        if not res.status:\r\n            rospy.logfatal(\"Could not start recording gesture '%s' using '%s'.\" % (name, parts))\r\n        speechSay('When you want to STOP recording, just press enter again')\r\n        input('Press enter to STOP recording ...\\n')\r\n        res = gestureSave(name, \"\")\r\n        if not res.status:\r\n            rospy.logfatal(\"Could not save gesture '%s'.\" % name)\r\n        else:\r\n            rospy.loginfo(\"Gesture '%s' was recorded.\" % name)\r\n            speechSay(\"Your gesture was recorded.\" % name)\r\n        res = setControlMode(parts, 1)\r\n        if not res.status:\r\n            rospy.logfatal(\"Could not set control mode of '%s'.\" % parts)\r\n        else:\r\n            speechSay(\"Let's see what did you record.\")\r\n            gesturePlay(name, 0)\r\n\r\n    except KeyboardInterrupt:\r\n        pass\r\n\r\n    rospy.loginfo(\"finsihed!\")\n"})}),"\n",(0,o.jsx)(r.h2,{id:"explanation",children:"Explanation"}),"\n",(0,o.jsxs)(r.p,{children:["Let's dissect the code. First we import all from ",(0,o.jsx)(r.code,{children:"qt_robot_interface.srv"}),", because we need ",(0,o.jsx)(r.code,{children:"speech_say"}),". We also import ",(0,o.jsx)(r.code,{children:"qt_gesture_controller.srv"})," and ",(0,o.jsx)(r.code,{children:"qt_motors_controller.srv"})," for all gesture and motor services."]}),"\n",(0,o.jsx)(r.p,{children:"We define all services that we need to use. We will need services for recording, saving and playing gestures. Also we will use speech service and control mode to set the mode of QTrobot motors."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-python",children:"speechSay = rospy.ServiceProxy('/qt_robot/speech/say', speech_say)\r\ngestureRecord = rospy.ServiceProxy('/qt_robot/gesture/record', gesture_record)\r\ngestureSave = rospy.ServiceProxy('/qt_robot/gesture/save', gesture_save)\r\nsetControlMode = rospy.ServiceProxy('/qt_robot/motors/setControlMode', set_control_mode)\r\ngesturePlay = rospy.ServiceProxy('/qt_robot/gesture/play', gesture_play)\n"})}),"\n",(0,o.jsxs)(r.p,{children:["Next we name the gesture and in we select which body part we want to record. You can write ",(0,o.jsx)(r.code,{children:'["left_arm","right_arm","head"]'})," to record with entire QTrobot. In this tutorial we will use just ",(0,o.jsx)(r.code,{children:"left_arm"}),"."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-python",children:'name = "my_gesture"\r\nparts = ["left_arm"]\n'})}),"\n",(0,o.jsxs)(r.p,{children:["Next we use ",(0,o.jsx)(r.code,{children:"speechSay"})," service to let the user decide when to start the recording. After user pressed enter, With ",(0,o.jsx)(r.code,{children:"gestureRecord"})," call we start recording the gesture with the ",(0,o.jsx)(r.code,{children:"parts"})," that we selected. If there is any error on recording we print out and error message."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-python",children:"input('Press enter to START recording ...\\n')\r\nspeechSay('Press enter to START recording.')\r\nres = gestureRecord(parts, True, 0, 0)\r\nif not res.status:\r\n    rospy.logfatal(\"Could not start recording gesture '%s' using '%s'.\" % (name, parts))\n"})}),"\n",(0,o.jsxs)(r.p,{children:["We use the same ",(0,o.jsx)(r.code,{children:"speech_say"})," service for user interaction and when user decides to stop the recording we stop it using ",(0,o.jsx)(r.code,{children:"gestureSave"}),", which saves the gesture with selected name on ",(0,o.jsx)(r.em,{children:"QTRP"})," in folder ",(0,o.jsx)(r.code,{children:"~/robot/data/gestures/"}),"."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-python",children:"speechSay('When you want to STOP recording, just press enter again')\r\ninput('Press enter to STOP recording ...\\n')\r\nres = gestureSave(name, \"\")\r\nif not res.status:\r\n    rospy.logfatal(\"Could not save gesture '%s'.\" % name)\r\nelse:\r\n    rospy.loginfo(\"Gesture '%s' was recorded.\" % name)\r\n    speechSay(\"Your gesture was recorded.\" % name)\n"})}),"\n",(0,o.jsxs)(r.p,{children:["At the end we enable back the motors used for recording with ",(0,o.jsx)(r.code,{children:"setControlMode"})," and if everything is ok we play the gesture that we recorded with ",(0,o.jsx)(r.code,{children:"gesturePlay"}),"."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-python",children:'res = setControlMode(parts, 1)\r\nif not res.status:\r\n    rospy.logfatal("Could not set control mode of \'%s\'." % parts)\r\nelse:\r\n    speechSay("Let\'s see what did you record.")\r\n    gesturePlay(name, 0)\n'})})]})}function p(e={}){const{wrapper:r}={...(0,s.a)(),...e.components};return r?(0,o.jsx)(r,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}}}]);