"use strict";(self.webpackChunkqtrobot_documentation=self.webpackChunkqtrobot_documentation||[]).push([[4884],{188:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>d,default:()=>a,frontMatter:()=>i,metadata:()=>o,toc:()=>c});var r=s(5893),n=s(1151);const i={id:"api_ros",title:"QTrobot ROS API Reference",hide_table_of_contents:!1},d=void 0,o={id:"api_ros",title:"QTrobot ROS API Reference",description:"The QTrobot ROS interface aims to facilitate accessing basic robot functionalities through a set of user-friendly ROS APIs. ROS is the de-facto standard robotic framework and basic knowledge of ROS is required to work with the QTrobot\u2019s ROS SDK.",source:"@site/docs/api_ros.md",sourceDirName:".",slug:"/api_ros",permalink:"/docs/api_ros",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"api_ros",title:"QTrobot ROS API Reference",hide_table_of_contents:!1},sidebar:"api_ros",next:{title:"QTrobot JavaScript API Reference",permalink:"/docs/api_js"}},l={},c=[{value:"<strong>Naming convention</strong>",id:"naming-convention",level:2},{value:"<strong>List of available interfaces</strong>",id:"list-of-available-interfaces",level:2},{value:"Speech Interface",id:"speech-interface",level:3},{value:"Audio Interface",id:"audio-interface",level:3},{value:"Emotion Interface",id:"emotion-interface",level:3},{value:"Gesture Interface",id:"gesture-interface",level:3},{value:"Behavior Interface",id:"behavior-interface",level:3},{value:"Motor Interface",id:"motor-interface",level:3},{value:"<em><strong>4.6.1 QTrobot parts</strong></em>",id:"461-qtrobot-parts",level:4},{value:"Setting Interface",id:"setting-interface",level:3},{value:"Human 3D Tracking Interface",id:"human-3d-tracking-interface",level:3}];function h(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,n.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.a,{href:"https://www.luxai.com",children:"QTrobot"})," ROS interface aims to facilitate accessing basic robot functionalities through a set of user-friendly ROS APIs. ROS is the de-facto standard robotic framework and ",(0,r.jsx)(t.a,{href:"https://wiki.ros.org/Documentation",children:"basic knowledge of ROS"})," is required to work with the QTrobot\u2019s ROS SDK.\nMost of  QTrobot\u2019s functionalities can be accessed in both blocking and non-blocking modes using ROS publish/subscribe and Service/Client interfaces. Following are the main interfaces of QTrobot:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"QTrobot Emotion"}),":\xa0implements\xa0robot\xa0facial\xa0emotion"]}),"\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"QTrobot Speech"}),":\xa0implements\xa0robot\xa0text\xa0to\xa0speech\xa0functionality"]}),"\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"QTrobot Audio"}),":\xa0implement\xa0a\xa0simple\xa0player\xa0to\xa0play\xa0standard\xa0audio\xa0files"]}),"\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"QTrobot Gesture"}),":\xa0implements\xa0robot\xa0gesture\xa0control"]}),"\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"QTrobot Behavior"}),":\xa0implements\xa0more\xa0complex\xa0behaviors\xa0by\xa0combining\xa0the\xa0robot\xa0basic\xa0functionality"]}),"\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"QTrobot Motor"}),":\xa0implements\xa0robot\xa0motor\xa0controls\xa0using\xa0standard\xa0",(0,r.jsx)(t.a,{href:"http://wiki.ros.org/ros_control",children:"ros_control"})]}),"\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"QTrobot 3D-Camera"}),":\xa0implements\xa0different\xa0human\xa03D\xa0body\xa0and\xa0facial\xa0tracking\xa0using\xa0Intel\xa0Realsense\xa0camera\xa0and\xa0",(0,r.jsx)(t.a,{href:"https://nuitrack.com/",title:"wikilink",children:"Nuitrack SDK"})]}),"\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"QTrobot Settings"}),":\xa0implements\xa0some\xa0basic\xa0setting\xa0of\xa0robot\xa0such\xa0as\xa0speaker\xa0volume\xa0control"]}),"\n"]}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"naming-convention",children:(0,r.jsx)(t.strong,{children:"Naming convention"})}),"\n",(0,r.jsx)(t.p,{children:"Most of  QTrobot\u2019s functionalities can be accessed in both blocking and non-blocking modes using ROS publish/subscribe and Service/Client interfaces. For each of the main interfaces, there are two different way of accessing them:"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"Using\xa0ROS\xa0Publisher/Subscribers\xa0to\xa0allow\xa0non-blocking\xa0call\xa0to\xa0the\xa0interfaces"})})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"Using\xa0ROS\xa0Services\xa0for\xa0blocking\xa0and\xa0accessing\xa0more\xa0sophisticated\xa0interfaces"})})}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["The name of the most of the QTRobot ROS interfaces starts with ",(0,r.jsx)(t.code,{children:"/qt_robot/..."})," prefix. The word follows the prefix indicate the actual interface (e.g. ",(0,r.jsx)(t.code,{children:"/qt_robot/speech/.."}),"). Each interface may have more sub-functionalities which come after the main interface name. For example:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"/qt_robot/speech/say"}),"    : implements speech reading interface using QTrobot TTS"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"/qt_robot/speech/config"})," : implements configure() method of QTrobot TTS"]}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["For user\u2019s convenience we have given the same name to the service and subscriber for each QTrobot ROS interface. That means one can access, for example, the speech functionality using ROS service call or publish/subscribe via the same interface name (e.g. ",(0,r.jsx)(t.code,{children:"qt_robot/speech/say"}),"). Please notice that some of the complex services (e.g. speech configuration for language, pitch,\u2026) are accessible ",(0,r.jsx)(t.strong,{children:"only"})," via ROS service call."]}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"list-of-available-interfaces",children:(0,r.jsx)(t.strong,{children:"List of available interfaces"})}),"\n",(0,r.jsx)(t.p,{children:"Currently the following interfaces have been implemented:"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"INTERFACES"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Functionality"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface prefix"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#speech-interface",children:"Speech"})}),(0,r.jsx)(t.td,{children:"/qt_robot/speech/..."}),(0,r.jsx)(t.td,{children:"robot text to speech functionality"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#audio-interface",children:"Audio"})}),(0,r.jsx)(t.td,{children:"/qt_robot/audio/..."}),(0,r.jsx)(t.td,{children:"simple standard audio file player"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#emotion-interface",children:"Emotion"})}),(0,r.jsx)(t.td,{children:"/qt_robot/emotion/..."}),(0,r.jsx)(t.td,{children:"robot facial emotion"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#gesture-interface",children:"Gesture"})}),(0,r.jsx)(t.td,{children:"/qt_robot/gesture/..."}),(0,r.jsx)(t.td,{children:"robot gesture control"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#behavior-interface",children:"Behavior"})}),(0,r.jsx)(t.td,{children:"/qt_robot/behavior/..."}),(0,r.jsx)(t.td,{children:"more complex behaviors by combining the robot basic functionality"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#motor-interface",children:"Motor"})}),(0,r.jsx)(t.td,{children:"/qt_robot/motor/..."}),(0,r.jsxs)(t.td,{children:["robot motor controls using standard ",(0,r.jsx)(t.a,{href:"http://wiki.ros.org/ros_control",children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"ros_control"})})})]})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#setting-interface",children:"Setting"})}),(0,r.jsx)(t.td,{children:"/qt_robot/setting/..."}),(0,r.jsx)(t.td,{children:"basic setting of robot such as speaker volume control"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#human-3d-tracking-interface",children:"Human 3D Skeleton"})}),(0,r.jsx)(t.td,{children:"/qt_nuitrack_app/skeletons"}),(0,r.jsx)(t.td,{children:"Human full body skeleton information"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#human-3d-tracking-interface",children:"Human 3D Hand Pos"})}),(0,r.jsx)(t.td,{children:"/qt_nuitrack_app/hands"}),(0,r.jsx)(t.td,{children:"Human 3D hand pos and state"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#human-3d-tracking-interface",children:"Human Hand Gestures"})}),(0,r.jsx)(t.td,{children:"/qt_nuitrack_app/gestures"}),(0,r.jsx)(t.td,{children:"Some basic human gestures recognition"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"#human-3d-tracking-interface",children:"Human facial"})}),(0,r.jsx)(t.td,{children:"/qt_nuitrack_app/faces"}),(0,r.jsx)(t.td,{children:"human face detection, orientation, eyes and facial features pos, age/gender detection and facial emotion recognition"})]})]})]}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h3,{id:"speech-interface",children:"Speech Interface"}),"\n",(0,r.jsx)(t.p,{children:"This interface implements QTrobot text to speech functionality which support many languages. The supported languages can be different for each robot. following are some standard supported languages:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"en-US"}),"\xa0(american\xa0english)"]}),"\n",(0,r.jsxs)(t.li,{children:["\xa0",(0,r.jsx)(t.strong,{children:"fr-FR"}),"\xa0(French)"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"de-DE"}),"\xa0(German)"]}),"\n"]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SUBSCRIBERS"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Data Type"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/speech/say"}),(0,r.jsx)(t.td,{children:"'std_msgs/String' (text)"}),(0,r.jsx)(t.td,{children:"Read a text using built-in TTS"})]})]})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SERVICES"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Service Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Parameters"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/speech/say"}),(0,r.jsx)(t.td,{children:"'speech_say'"}),(0,r.jsx)(t.td,{children:"message"}),(0,r.jsx)(t.td,{children:"Read a text using built-in TTS"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/speech/config"}),(0,r.jsx)(t.td,{children:"'speech_config'"}),(0,r.jsx)(t.td,{children:"'language', 'pitch', 'speed'"}),(0,r.jsx)(t.td,{children:"Configure TTS"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/speech/stop"}),(0,r.jsx)(t.td,{children:"'speech_stop'"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Stops current speech activity."})]})]})]}),"\n",(0,r.jsx)(t.admonition,{title:"Info",type:"info",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsxs)(t.strong,{children:["Default language is set in ",(0,r.jsx)(t.code,{children:"/opt/ros/noetic/share/qt_robot_interface/config/qtrobot-interface.yaml"}),". the default pitch is usually '140' and speed is '80'. When calling 'speech_config', leave pitch and speed parameters to '0' if you do not want to change them."]})})})}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h3,{id:"audio-interface",children:"Audio Interface"}),"\n",(0,r.jsxs)(t.p,{children:["Play a standard audio file (e.g. wav, mp3). The audio file can be given using its complete name (with the file extension) such as ",(0,r.jsx)(t.strong,{children:"happy.mp3"})," or simply without the file extension: ",(0,r.jsx)(t.strong,{children:"happy"}),". In the second case, the player first looks for happy.mp3 to play and if it is not found it then tries with happy.wav and so on."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SUBSCRIBERS"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Data Type"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/audio/play"}),(0,r.jsx)(t.td,{children:"'std_msgs/String' (audio file name)"}),(0,r.jsx)(t.td,{children:"Play an audio file"})]})]})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SERVICES"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Service Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Parameters"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/audio/play"}),(0,r.jsx)(t.td,{children:"'audio_play'"}),(0,r.jsx)(t.td,{children:"'filename', 'filepath'"}),(0,r.jsx)(t.td,{children:"Play an audio file given by its filename and filepath"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/audio/stop"}),(0,r.jsx)(t.td,{children:"'audio_stop'"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Stops current audio activity."})]})]})]}),"\n",(0,r.jsx)(t.admonition,{title:"Info",type:"info",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsxs)(t.strong,{children:["The default path for the audio files is ",(0,r.jsx)(t.code,{children:"~/robot/data/audios/"}),". To play the audio file from the default path, pass an empty string to filepath parameter."]})})})}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h3,{id:"emotion-interface",children:"Emotion Interface"}),"\n",(0,r.jsx)(t.p,{children:"Change the robot facial emotions such as 'QT/happy', 'QT/sad', etc."}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SUBSCRIBERS"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Data Type"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/emotion/show"}),(0,r.jsx)(t.td,{children:"'std_msgs/String' (emotion name)"}),(0,r.jsx)(t.td,{children:"Show a facial emotion given by its name"})]})]})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SERVICES"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Service Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Parameters"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/emotion/show"}),(0,r.jsx)(t.td,{children:"'emotion_show'"}),(0,r.jsx)(t.td,{children:"'name'"}),(0,r.jsx)(t.td,{children:"Show a facial emotion given by its name"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/emotion/stop"}),(0,r.jsx)(t.td,{children:"'emotion_stop'"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Stops current emotion activity."})]})]})]}),"\n",(0,r.jsx)(t.admonition,{title:"Info",type:"info",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"The complete list of emotion files can be found in '~/robot/data/emotions/'."})})})}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h3,{id:"gesture-interface",children:"Gesture Interface"}),"\n",(0,r.jsxs)(t.p,{children:["Plays recorded robot gesture (arms, head) such as 'happy', 'angry', 'bye', etc. The complete list of gesture files can be found in ",(0,r.jsx)(t.code,{children:"~/robot/data/gestures/"}),"."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SUBSCRIBERS"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Data Type"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/gesture/play"}),(0,r.jsx)(t.td,{children:"'std_msgs/String' (gesture name)"}),(0,r.jsx)(t.td,{children:"Play a robot gesture given by its name"})]})]})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SERVICES"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Service Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Parameters"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/gesture/play"}),(0,r.jsx)(t.td,{children:"'gesture_play'"}),(0,r.jsx)(t.td,{children:"'name', 'speed'"}),(0,r.jsx)(t.td,{children:"Play a robot gesture given by its name and speed (default 1.0)"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/gesture/record"}),(0,r.jsx)(t.td,{children:"'gesture_record'"}),(0,r.jsx)(t.td,{children:"'parts', 'idleParts'"}),(0,r.jsx)(t.td,{children:"Start recording a new gesture. 'parts' is a string array of parts name ('head', 'left_arm','right_arm') which specifies which robot part will be used for recording the gesture. 'idleParts' must be set to 'true' to release the motor PWM and put them in idle mode. If not you must put them in idle mode using '/qt_robot/motors/setControlMode' interface"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/gesture/save"}),(0,r.jsx)(t.td,{children:"'gesture_save'"}),(0,r.jsx)(t.td,{children:"'name', 'path'"}),(0,r.jsx)(t.td,{children:"stops the current recording process and save the recorded gesture given by its 'name'. 'path' specifies where to save the gesture instead of the default path"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/gesture/list"}),(0,r.jsx)(t.td,{children:"'gesture_list'"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"return a list of a the available gestures within the default gesture path"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/gesture/stop"}),(0,r.jsx)(t.td,{children:"'gesture_stop'"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Stops current gesture activity."})]})]})]}),"\n",(0,r.jsx)(t.admonition,{title:"Info",type:"info",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"The default value for speed is 1.0 and it is the default speed with which the gesture got recorded."})})})}),"\n",(0,r.jsx)(t.admonition,{title:"Notice",type:"note",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsxs)(t.strong,{children:["If the speed param value is 0 the default speed will be used to play the gestures. Default path to record/play the gesture is ",(0,r.jsx)(t.code,{children:"~/robot/data/gestures/"}),"."]})})})}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h3,{id:"behavior-interface",children:"Behavior Interface"}),"\n",(0,r.jsx)(t.p,{children:"This interface implements higher-level and more complex behaviors by combing robot basic functionality."}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SUBSCRIBERS"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Data Type"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/behavior/talkText"}),(0,r.jsx)(t.td,{children:"'std_msgs/String' (message)"}),(0,r.jsx)(t.td,{children:"Read a text using TTS and show talking emotion"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/behavior/talkAudio"}),(0,r.jsx)(t.td,{children:"'std_msgs/String' (audio filename)"}),(0,r.jsx)(t.td,{children:"Play an audio file and show talking emotion"})]})]})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SERVICES"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Service Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Parameters"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/behavior/talkText"}),(0,r.jsx)(t.td,{children:"'behavior_talk_text'"}),(0,r.jsx)(t.td,{children:"'message'"}),(0,r.jsx)(t.td,{children:"Read a text using TTS and show talking emotion"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/behavior/talkAudio"}),(0,r.jsx)(t.td,{children:"'behavior_talk_audio'"}),(0,r.jsx)(t.td,{children:"'filename', 'filepath'"}),(0,r.jsx)(t.td,{children:"Play an audio file and show talking emotion"})]})]})]}),"\n",(0,r.jsx)(t.admonition,{title:"Info",type:"info",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"To play the audio file from the default path, pass an empty string to filepath param."})})})}),"\n",(0,r.jsx)(t.admonition,{title:"Notice",type:"note",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"The talkAudio and talkText services are mutually exclusive and cannot be used with Emotion Interface at the same time."})})})}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h3,{id:"motor-interface",children:"Motor Interface"}),"\n",(0,r.jsxs)(t.p,{children:["Motor interface provide access to the robot actuators using standard ",(0,r.jsx)(t.a,{href:"http://wiki.ros.org/ros_control",children:"ros_control"})," system. Currently the interface implements ROS 'JointStateController', 'JointGroupPositionController' and a custom 'QTMotorsController' controllers."]}),"\n",(0,r.jsx)(t.admonition,{title:"Warning",type:"warning",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"Before using the Motor interface, ensure that you fully understood ros_control system and have a clear understanding of what you do at the motor joint level."})})})}),"\n",(0,r.jsx)(t.h4,{id:"461-qtrobot-parts",children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"4.6.1 QTrobot parts"})})}),"\n",(0,r.jsx)(t.p,{children:"The robot joints are structured as different parts as shown bellow:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["\xa0",(0,r.jsx)(t.strong,{children:"head"})]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.strong,{children:"HeadYaw"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.strong,{children:"HeadPitch"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["\xa0",(0,r.jsx)(t.strong,{children:"right_arm"})]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.strong,{children:"RightShoulderPitch"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.strong,{children:"RightShoulderRoll"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.strong,{children:"RightElbowRoll"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["\xa0",(0,r.jsx)(t.strong,{children:"left_arm"})]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.strong,{children:"LeftShoulderPitch"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.strong,{children:"LeftShoulderRoll"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.strong,{children:"LeftElbowRoll"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SUBSCRIBERS"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Data Type"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/joints/state"}),(0,r.jsx)(t.td,{children:"sensor_msgs/JointState"}),(0,r.jsx)(t.td,{children:"publishes joint states (currently only positions)"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/head_position/command"}),(0,r.jsx)(t.td,{children:"std_msgs/Float64MultiArray"}),(0,r.jsx)(t.td,{children:"move the robot head to desired position given by (HeadYaw, HeadPitch)."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/right_arm_position/command"}),(0,r.jsx)(t.td,{children:"std_msgs/Float64MultiArray"}),(0,r.jsx)(t.td,{children:"move the right_arm to desired position given by (RightShoulderPitch, RightShoulderRoll, RightElbowRoll)."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/left_arm_position/command"}),(0,r.jsx)(t.td,{children:"std_msgs/Float64MultiArray"}),(0,r.jsx)(t.td,{children:"move the left_arm to desired position given by (LeftShoulderPitch, LeftShoulderRoll, LeftElbowRoll)."})]})]})]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SERVICES"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Service Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Parameters"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/motors/home"}),(0,r.jsx)(t.td,{children:"'home'"}),(0,r.jsx)(t.td,{children:"'parts'"}),(0,r.jsx)(t.td,{children:"moves the desired robot part to the home position. 'parts' is an array of robot parts and/or single joint name (e.g.['left_arm', 'right_arm', 'HeadPitch'])"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/motors/setControlMode"}),(0,r.jsx)(t.td,{children:"'set_control_mode'"}),(0,r.jsx)(t.td,{children:"'parts'"}),(0,r.jsx)(t.td,{children:"set the control mode (M_ON=0,M_OFF=1, M_BRAKE=2) of desired robot part. 'parts' is an array of robot parts and/or single joint name (e.g. ['left_arm', 'right_arm', 'HeadPitch']). M_ON: motor is controlled. M_OFF: motor is idle and M_BRAKE: motor is in brake mode (not controlled)"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/motors/setVelocity"}),(0,r.jsx)(t.td,{children:"'set_velocity'"}),(0,r.jsx)(t.td,{children:"'parts', 'velocity'"}),(0,r.jsx)(t.td,{children:"sets the moving velocity of the desired robot part. 'parts' is an array of robot parts and/or single joint name (e.g. ['left_arm', 'right_arm', 'HeadPitch']). 'velocity' is given as percentage."})]})]})]}),"\n",(0,r.jsx)(t.admonition,{title:"Warning",type:"warning",children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:(0,r.jsx)(t.strong,{children:"For safety purpose, every joint has a maximum velocity limits. For example you cannot run 'HeadPitch' joint with more than 20% of the maximum velocity."})})})}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h3,{id:"setting-interface",children:"Setting Interface"}),"\n",(0,r.jsx)(t.p,{children:"This interface provides some basic setting of robot such as speaker volume control."}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"SERVICES"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Service Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Parameters"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_robot/setting/setVolume"}),(0,r.jsx)(t.td,{children:"'setting_setVolume'"}),(0,r.jsx)(t.td,{children:"'volume'"}),(0,r.jsx)(t.td,{children:"set the robot speaker volume to the desired level (in percentage)"})]})]})]}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h3,{id:"human-3d-tracking-interface",children:"Human 3D Tracking Interface"}),"\n",(0,r.jsxs)(t.p,{children:["This interface implements different human 3D body and facial tracking including human full body skeleton, hands pos and gestures, facial and emotion recognition using Intel Realsense camera and ",(0,r.jsx)(t.a,{href:"https://nuitrack.com",children:"Nuitrack SDK"}),"."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:(0,r.jsx)(t.strong,{children:"PUBLISHERS"})}),(0,r.jsx)(t.th,{}),(0,r.jsx)(t.th,{})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Interface Name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Data Type"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Description"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_nuitrack_app/skeletons"}),(0,r.jsx)(t.td,{children:"'qt_nuitrack_app/Skeletons'"}),(0,r.jsx)(t.td,{children:"publishes human full body skeleton information"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_nuitrack_app/hands"}),(0,r.jsx)(t.td,{children:"'qt_nuitrack_app/Hands'"}),(0,r.jsx)(t.td,{children:"publishes human 3D hand pos and state"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_nuitrack_app/gestures"}),(0,r.jsx)(t.td,{children:"'qt_nuitrack_app/Gestures'"}),(0,r.jsx)(t.td,{children:"publishes some basic human gestures recognition"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/qt_nuitrack_app/faces"}),(0,r.jsx)(t.td,{children:"'qt_nuitrack_app/Faces'"}),(0,r.jsx)(t.td,{children:"publishes human face detection, orientation, eyes and facial features pos, age/gender detection and facial emotion recognition"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"/camera/color/image_raw"}),(0,r.jsx)(t.td,{children:"'sensor_msgs/Image'"}),(0,r.jsx)(t.td,{children:"publishes ROS standard 2D camera image"})]})]})]}),"\n",(0,r.jsx)(t.hr,{})]})}function a(e={}){const{wrapper:t}={...(0,n.a)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}}}]);