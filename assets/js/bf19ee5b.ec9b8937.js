"use strict";(self.webpackChunkqtrobot_documentation=self.webpackChunkqtrobot_documentation||[]).push([[2534],{9943:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>p,frontMatter:()=>i,metadata:()=>l,toc:()=>h});var t=o(5893),s=o(1151),r=o(9656);const i={id:"python_ros_vosk",title:"QTrobot Offline speech recognition",hide_table_of_contents:!0},c=void 0,l={id:"tutorials/python/python_ros_vosk",title:"QTrobot Offline speech recognition",description:"signalcellularalt &nbsp;Level:&nbsp; Advanced",source:"@site/docs/tutorials/python/python_ros_vosk.mdx",sourceDirName:"tutorials/python",slug:"/tutorials/python/python_ros_vosk",permalink:"/docs/tutorials/python/python_ros_vosk",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"python_ros_vosk",title:"QTrobot Offline speech recognition",hide_table_of_contents:!0},sidebar:"code_tutorials_sidebar",previous:{title:"Using QTrobot ReSpeaker microphone",permalink:"/docs/tutorials/python/python_ros_respeaker"},next:{title:"Controlling QTrobot arms using MoveIt",permalink:"/docs/tutorials/python/python_ros_moveit"}},a={},h=[{value:"Create a python project",id:"create-a-python-project",level:2},{value:"QTrobot speech service",id:"qtrobot-speech-service",level:2},{value:"Tips",id:"tips",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.admonition,{title:"Overview",type:"info",children:[(0,t.jsxs)(n.p,{children:[(0,t.jsx)(r.Z,{children:"signal_cellular_alt"})," \xa0",(0,t.jsx)(n.strong,{children:"Level:"}),"\xa0 ",(0,t.jsx)(n.em,{children:"Advanced"}),"\n",(0,t.jsx)("br",{})," ",(0,t.jsx)(r.Z,{children:" track_changes "})," \xa0",(0,t.jsx)(n.strong,{children:"Goal:"}),"\xa0 ",(0,t.jsx)(n.em,{children:"learn how to use QTrobot Offline speech recognition"}),"\n",(0,t.jsx)("br",{})," ",(0,t.jsx)(r.Z,{children:" task_alt "})," \xa0",(0,t.jsx)(n.strong,{children:"Requirements:"})]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\xa0\xa0",(0,t.jsx)(n.a,{href:"/docs/intro_code",children:"Quick start with coding on QTrobot"})]}),"\n",(0,t.jsxs)(n.li,{children:["\xa0\xa0",(0,t.jsx)(n.a,{href:"/docs/tutorials/python/python_ros_project",children:"Create a ROS python project"})]}),"\n",(0,t.jsxs)(n.li,{children:["\xa0\xa0",(0,t.jsx)(n.a,{href:"/docs/tutorials/python/python_ros_services",children:"QTrobot interfaces using ROS Services"})]}),"\n"]})]}),"\n",(0,t.jsxs)(n.p,{children:["In this tutorial we will learn about how to use ",(0,t.jsx)(n.code,{children:"QTrobot Offline speech recognition"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"create-a-python-project",children:"Create a python project"}),"\n",(0,t.jsxs)(n.p,{children:["First we create a python project for our tutorial. let's call it ",(0,t.jsx)(n.code,{children:"tutorial_qt_vosk"})," and add the required python file:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'cd ~/catkin_ws/src\ncatkin_create_pkg tutorial_qt_vosk rospy roscpp -D "Command QTrobot via ROS Services"\ncd tutorial_qt_vosk/src\ntouch tutorial_qt_vosk_node.py\nchmod +x tutorial_qt_vosk_node.py\n'})}),"\n",(0,t.jsx)(n.h2,{id:"qtrobot-speech-service",children:"QTrobot speech service"}),"\n",(0,t.jsx)(n.p,{children:"Following are some standard supported languages:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\xa0",(0,t.jsx)(n.strong,{children:"en_US"}),"\xa0(English)"]}),"\n",(0,t.jsxs)(n.li,{children:["\xa0",(0,t.jsx)(n.strong,{children:"fr_FR"}),"\xa0(French)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"de_DE"}),"\xa0(German)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"es_ES"})," (Spanish)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"it_IT"})," (Italian)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"pt_PT"})," (Portuguese)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"nl_NL"})," (Dutch)"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Open the ",(0,t.jsx)(n.code,{children:"tutorial_qt_service_node.py"})," file and add the following code:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python\nimport sys\nimport rospy\nfrom qt_robot_interface.srv import *\nfrom qt_vosk_app.srv import *\n\nif __name__ == '__main__':\n\n    rospy.init_node('my_tutorial_node')\n    rospy.loginfo(\"my_tutorial_node started!\")\n\n    # define a ros service\n    speechSay = rospy.ServiceProxy('/qt_robot/speech/say', speech_say)\n    recognize = rospy.ServiceProxy('/qt_robot/speech/recognize', speech_recognize)\n    # block/wait for ros service\n    rospy.wait_for_service('/qt_robot/speech/say')\n    rospy.wait_for_service('/qt_robot/speech/recognize')\n\n    try:\n        # call a ros service with text message\n        speechSay(\"Say something after the beep.\")\n        speechSay('#CAR HORN#')\n        resp = recognize(\"en_US\", ['blue', 'green', 'red'], 10)\n        rospy.loginfo(\"I got: %s\", resp.transcript)\n        speechSay(\"You said %s \" % resp.transcript)\n    except KeyboardInterrupt:\n        pass\n\n    rospy.loginfo(\"finsihed!\")\n\n"})}),"\n",(0,t.jsx)(n.h2,{id:"tips",children:"Tips"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"When you run the code or when you call the service from command line always wait a least 1 second before saying something, so that microphone has time to open."}),"\n",(0,t.jsx)(n.li,{children:"It might not work on the first call when you switch the language, second one will be ok."}),"\n",(0,t.jsx)(n.li,{children:"Using options for better detection of words. If you want to get exactly 'yes' or 'no', you just need to call the service with this options ['yes','no']. Even if you say some really long sentence, it will detect just 'yes' or 'no'."}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);