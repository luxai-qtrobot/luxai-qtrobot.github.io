<!doctype html>
<html class="docs-version-QTRD_v1" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.17">
<link rel="search" type="application/opensearchdescription+xml" title="QTrobot Documentation" href="/opensearch.xml">
<!-- Google Tag Manager -->
              <script>var ck=document.cookie;let internal=ck.search("internalTraffic=true");function enableGTM(){!function(e,t,n,a,o){e[a]=e[a]||[],e[a].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var r=t.getElementsByTagName(n)[0],c=t.createElement(n);c.async=!0,c.src="https://www.googletagmanager.com/gtm.js?id=GTM-KQ6W3F7",r.parentNode.insertBefore(c,r)}(window,document,"script","dataLayer")}-1==internal&&(console.log("Cookie not set!"),enableGTM())</script>
              <!-- End Google Tag Manager -->
<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"><title data-rh="true">QTrobot Vision and 3D Camera | QTrobot Documentation</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.luxai.com/docs/v1/modules/camera"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_version" content="QTRD_v1"><meta data-rh="true" name="docusaurus_tag" content="docs-default-QTRD_v1"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:version" content="QTRD_v1"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-QTRD_v1"><meta data-rh="true" property="og:title" content="QTrobot Vision and 3D Camera | QTrobot Documentation"><meta data-rh="true" name="description" content="QTrobot has an integrated 3D camera in the head. It is a Intel¬Æ RealSense‚Ñ¢ Depth Camera D455. It is connected to NUC mini PC (QTPC) via USB-C port and it is open for developers to configure and use it."><meta data-rh="true" property="og:description" content="QTrobot has an integrated 3D camera in the head. It is a Intel¬Æ RealSense‚Ñ¢ Depth Camera D455. It is connected to NUC mini PC (QTPC) via USB-C port and it is open for developers to configure and use it."><link data-rh="true" rel="icon" href="/img/luxai-favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.luxai.com/docs/v1/modules/camera"><link data-rh="true" rel="alternate" href="https://docs.luxai.com/docs/v1/modules/camera" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.luxai.com/docs/v1/modules/camera" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://NHG3L6L4QM-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.b5bf65b3.css">
<link rel="preload" href="/assets/js/runtime~main.3a6131f5.js" as="script">
<link rel="preload" href="/assets/js/main.a8baad6c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo_luxai_mini.png" alt="LuxAI" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo_luxai_mini.png" alt="LuxAI" class="themedImage_W2Cr themedImage--dark_oUvU"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" class="navbar__link">Visual Scripting</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/v1/intro_graphical">Quick start</a></li><li><a class="dropdown__link" href="/docs/v1/tutorials/intro_studio">Tutorials</a></li><li><a class="dropdown__link" href="/docs/v1/blocks_api">Blocks reference</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" class="navbar__link">Coding</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/v1/intro_code">Quick start</a></li><li><a class="dropdown__link" href="/docs/v1/tutorials/intro_ros">Tutorials</a></li><li><a class="dropdown__link navbar__link--active" href="/docs/v1/modules/display">Competences</a></li><li><a class="dropdown__link" href="/docs/v1/api_ros">API references</a></li></ul></div><a class="navbar__item navbar__link" href="/demos">Demos</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/docs/v1/intro_code">QTrobot V1</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/modules/camera">QTrobot V2</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/docs/v1/modules/camera">QTrobot V1</a></li></ul></div><a class="navbar__item navbar__link" href="/support">Support</a><a href="https://github.com/luxai-qtrobot" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="searchBox_qEbK"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><aside class="theme-doc-sidebar-container docSidebarContainer_rKC_"><div class="sidebar_CW9Y"><nav class="menu thin-scrollbar menu_SkdO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/v1/modules/display">Face and Emotion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/v1/modules/speakers">Sound and Speech</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/v1/modules/microphone">Audio Processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/docs/v1/modules/camera">Vision System</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/v1/modules/motors">Motion and Actuators</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/v1/modules/processor">Computation and Networking</a></li></ul></nav></div></aside><main class="docMainContainer_TCnq"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is documentation for <b>QTrobot for Research V1</b>.</div><div class="margin-top--md">For QTrobot for Research V2, please refer to the <a href="/docs/modules/camera">QTrobot V2</a> documentation.</div></div><div class="docItemContainer_vinB"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Xlws" aria-label="breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a class="breadcrumbs__link breadcrumbsItemLink_e5ie" href="/">üè†</a></li><li class="breadcrumbs__item breadcrumbs__item--active"><a class="breadcrumbs__link breadcrumbsItemLink_e5ie" href="/docs/v1/modules/camera">Vision System</a></li></ul></nav><span class="theme-doc-version-badge badge badge--secondary">Version: QTrobot V1</span><div class="tocCollapsible_jdIR theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_Fzxq">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>QTrobot Vision and 3D Camera</h1></header><p>QTrobot has an integrated 3D camera in the head. It is a <a href="https://store.intelrealsense.com/buy-intel-realsense-depth-camera-d455.html" target="_blank" rel="noopener noreferrer"><strong>Intel¬Æ RealSense‚Ñ¢ Depth Camera D455</strong></a>. It is connected to NUC mini PC (QTPC) via USB-C port and it is open for developers to configure and use it. </p><center><img width="80%" src="/img/camera.svg" alt="architecture"></center><hr><h2 class="anchor anchorWithStickyNavbar_mojV" id="software-interfaces">Software Interfaces<a class="hash-link" href="#software-interfaces" title="Direct link to heading">‚Äã</a></h2><p>Like any other standard camera, the QTrobot 3D camera is an standard Linux video capture device. Bellow you can see the example output of <code>v4l2-ctl --list-devices</code> command which lists all video capture devices in QTPC: </p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Intel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">R</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> RealSense</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">TM</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token number">430</span><span class="token plain">: Int </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">usb-0000:00:14.0-4</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain">:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        /dev/video0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        /dev/video1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        /dev/video2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        /dev/video3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        /dev/video4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        /dev/video5        </span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>QTrobot comes with the pre-installed software for human 3D body and facial tracking, image recognition and ros usb camera driver. This is installed on QTPC, because direct access to the 3D camera is required.</p><ul><li><a href="https://github.com/luxai-qtrobot/software/tree/master/apps/qt_nuitrack_app" target="_blank" rel="noopener noreferrer"><strong>qt_nuitrack_app</strong></a>: implements different human 3D body and facial tracking including human full body skeleton, hands position and gestures, facial and emotion recognition using <a href="https://nuitrack.com" target="_blank" rel="noopener noreferrer"><strong>Nuitrack SDK</strong></a>.</li><li><a href="http://wiki.ros.org/find_object_2d" target="_blank" rel="noopener noreferrer"><strong>find_object_2d</strong></a>: implements object recognition</li><li><a href="https://wiki.ros.org/usb_cam" target="_blank" rel="noopener noreferrer"><strong>usb_cam</strong></a>: ROS camera driver for V4L USB Cameras</li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="human-3d-body-and-facial-tracking">Human 3D body and facial tracking<a class="hash-link" href="#human-3d-body-and-facial-tracking" title="Direct link to heading">‚Äã</a></h2><p>QTrobot uses <code>qt_nuitrack_app</code> for human 3D body and facial tracking. The <code>qt_nuitrack_app</code> is installed in QTPC <code>~/catkin_ws</code> and it is running by default.
The <code>qt_nuitrack_app</code> uses <strong>Nuitrack‚Ñ¢</strong> which is a 3D tracking middleware developed by <strong>3DiVi Inc</strong>. This is a solution for skeleton tracking and gesture recognition that enables capabilities of Natural User Interface (NUI). <strong>Nuitrack‚Ñ¢ framework</strong> is multi-language and cross-platform. <strong>Nuitrack‚Ñ¢ API</strong>s include the set of interfaces for developing applications, which utilize Natural Interaction.</p><table><thead><tr><th>Key Features</th><th>Application Areas</th><th></th></tr></thead><tbody><tr><td><ul><li>Full Body Skeletal Tracking (19 Joints)</li><li>3D Point Cloud</li><li>Face tracking and facial features</li><li>Gesture Recognition</li><li>Unity and Unreal Engine Plugins</li><li>OpenNI 1.5 compatible</li></ul></td><td><ul><li>Robot Vision</li><li>Medical Rehabilitation</li><li>Full Body Tracking for AR / VR</li><li>Audience Analytics</li><li>Smart Home</li><li>Games and Training (Fitness, Dance Lessons)</li></ul></td><td><center><img style="max-width:300px" src="/img/facial_feature.png"></center></td></tr></tbody></table><p>The <code>qt_nuitrack_app</code> extracts data from <code>Nuitrack SDK</code> and publishes human skeletons, hands, gestures and faces information to its ROS topics:</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">/qt_nuitrack_app/faces</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">/qt_nuitrack_app/gestures</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">/qt_nuitrack_app/hands</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">/qt_nuitrack_app/skeletons</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="using-qt-nuitrack-interface-from-terminal">Using QT Nuitrack interface from terminal<a class="hash-link" href="#using-qt-nuitrack-interface-from-terminal" title="Direct link to heading">‚Äã</a></h3><p>Like many other ROS topics, you can subscribe to <code>/qt_nuitrack_app/gestures</code> to read detected gesture.</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">rostopic </span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">echo</span><span class="token plain"> /qt_nuitrack_app/gestures</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Stand in front of QTrobot and do one of following gestures <code>SWIPE UP</code>, <code>SWIPE DOWN</code>, <code>SWIPE LEFT</code> or <code>SWIPE RIGHT</code>.
If the gesture is detected you will see something like this example:</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">INFO</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">1629900965.371938</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain">: gestures:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  -</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    id: </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name: </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;SWIPE UP&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="using-qt-nuitrack-interface-from-code">Using QT Nuitrack interface from code<a class="hash-link" href="#using-qt-nuitrack-interface-from-code" title="Direct link to heading">‚Äã</a></h3><p>Take a look at our <a href="/docs/tutorials/python/python_ros_gestures"><strong>Python Human gesture detection</strong></a> tutorial to learn how to read gesture data from <code>qt_nuitrack_app</code> from a Python code. Here is a snippet:</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> qt_nuitrack_app</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">msg </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Gestures</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">gesture_callback</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">msg</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> msg</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">gestures</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">name </span><span class="token operator">==</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;SWIPE UP&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;I got: %s&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> msg</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">gestures</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">rospy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Subscriber</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;/qt_nuitrack_app/gestures&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> Gestures</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> gesture_callback</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>We have also other python tutorials using <code>qt_nuitrack_app</code>:</p><ul><li><a href="/docs/tutorials/python/python_ros_expression"><strong>Python - Human facial expression detection</strong></a></li><li><a href="/docs/tutorials/python/python_ros_hands"><strong>Python - Human hands detection</strong></a></li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="using-qt-nuitrack-interface-from-visual-studio-blocks">Using QT Nuitrack interface from visual studio blocks<a class="hash-link" href="#using-qt-nuitrack-interface-from-visual-studio-blocks" title="Direct link to heading">‚Äã</a></h3><p>QTrobot studio offers very flexible and powerful blocks to handle complex ROS messages and interact with other publishers, subscribers and services. You can follow <a href="/docs/tutorials/graphical/studio_ros"><strong>Using ROS blocks</strong></a> tutorial to learn about ROS blocs.</p><p>Take a look at our <a href="/docs/tutorials/graphical/studio_gesture_mem_game">Create an interactive memory game using human gestures</a> tutorials to learn how to call <code>qt_nuitrack_app</code> using QTrobot visual studio blocks.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="tips-for-better-skeleton-and-facial-emotion-recognition"><strong>Tips</strong> for better skeleton and facial emotion recognition<a class="hash-link" href="#tips-for-better-skeleton-and-facial-emotion-recognition" title="Direct link to heading">‚Äã</a></h3><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span> Use QTrobot in a fairly well luminated environment. Intel Realsense 3D cameras are design for mostly indoor applications and in general they are sensitive to lights. </span><br><br><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span> When using QTrobot with camera applications, do not put the robot against window or any other source of light (i.e. robot should not look towards window). That may create blurry and unclear camera image and decreases performance of 3D software. </span><br><br><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span>Stay in front of the QTrobot camera so that camera can see most parts of your body (around 1.5m-2m away from the robot). For skeletong, gesture, facial expression, etc. to work properly, nuitrack SDK requires first to see almost whole body (standing position) to detect it first. then you can move closer if it&#x27;s needed. </span><br><br><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span> Similarly, to have facial data recognized by <code>/qt_nuitrack_app/faces</code>, first almost your whole body should be visible to QTrobot&#x27;s camera. If you are in sitting position, just stand up and stay few steps away from QTrobot so that it can see your whole body. After detecting your face, you may walk closer and even sit in front of its camera.</span><br><h2 class="anchor anchorWithStickyNavbar_mojV" id="image-recognition-with-qtrobot">Image recognition with QTrobot<a class="hash-link" href="#image-recognition-with-qtrobot" title="Direct link to heading">‚Äã</a></h2><p>QTrobot uses ROS <a href="http://wiki.ros.org/find_object_2d" target="_blank" rel="noopener noreferrer">find_object_2d</a> module for easy and flexible image recognition.  Using a camera, objects are detected and published on a ROS topic with ID and position. Take a look at our <a href="/docs/tutorials/graphical/studio_card_mem_game"><strong>Create an interactive memory game using cards</strong></a> tutorial to learn how to read data from <code>find_objects_2d</code>.</p><p>Using QTrobot&#x27;s camera, the find_object_2d simply detect whatever images that are in <code>~/robot/data/images</code> folder on QTPC. For example, we can use the following images. These images already exist in the corresponding folder to be recognized by find_object_2d.</p><p><img loading="lazy" alt="emotion cards" src="/assets/images/mem_game_images-be51e4d25a5e8528fa19aa7e6868e844.png" width="1663" height="478"> </p><p>If we show one of the above card to QTrobot, the find_object_2d recognizes it and publishes the corresponding id (number in the filename) along with other information to <code>/find_object/objects</code> topic. The topic uses a message of standard type std_msgs/Float32MultiArray. The first element in the list is the id of the image which is of our interest for this scenario. </p><p>Like many other ROS topics, you can subscribe to <code>/find_object/objects</code> to read detected objects.</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">rostopic </span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">echo</span><span class="token plain"> /find_object/objects</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>For example, if we show the T card image (i.e 2.jpg), the following message will be published. The first element in data field (2.0) is the id of the 2.jpg image.</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">layout:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  dim: </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  data_offset: </span><span class="token number">0</span><span class="token plain"></span><br></span><span class="token-line docusaurus-highlight-code-line" style="color:#F8F8F2"><span class="token plain">data: </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">2.0</span><span class="token plain">, </span><span class="token number">553.0</span><span class="token plain">, </span><span class="token number">553.0</span><span class="token plain">, </span><span class="token number">0.582885205745697</span><span class="token plain">, -0.03982475772500038, </span><span class="token punctuation" style="color:rgb(248, 248, 242)">..</span><span class="token plain">.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">---</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="detecting-a-custom-object">Detecting a custom object<a class="hash-link" href="#detecting-a-custom-object" title="Direct link to heading">‚Äã</a></h3><p>Simply add images to <code>~/robot/data/images</code> folder on QTPC and re-run <code>find_object_2d</code>. Subscribe to the <code>/find_object/objects</code> topic and read the data.
Take a look at this example how to read data from <code>find_object_2d</code> from a Python code. Here is a snippet:</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> std_msgs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">msg </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Float32MultiArray</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">image_callback</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">msg</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">msg</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">rospy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Subscriber</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;/find_object/objects&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> Float32MultiArray</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> image_callback</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></div><div class="admonition-content"><p>ROS find_object_2d is already pre-installed on QTPC. To enable it you need to add <code>run_script start_find_object.sh;</code> to the <code>~/robot/autostart/autostart_screens.sh</code>. It needs to access <code>/camera/color/image_raw</code> topic to work. </p></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="tips-for-better-object-recognition"><strong>Tips</strong> for better object recognition<a class="hash-link" href="#tips-for-better-object-recognition" title="Direct link to heading">‚Äã</a></h3><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span> When using QTrobot with camera applications such as image recogntion, do not put the robot against window or any other source of light (i.e. robot should <strong>not</strong> look towards window light). That may create blurry and unclear camera image and decreases performance of 3D software. </span><br><br><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span> Print your image to be recognized on fairly big and visible card/paper. Don no use very thin paper (transparent) or print the image very small and invisible.</span><br><br><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span> Show the image fully and clearly to the robot. move the card/paper slightly back and forward in front of the QTrobot camera to find the idle distance with respect to your image card size. </span><br><br><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span> Do not use very simple image such as simply colored circle or other simple shapes. By default the <code>find_object_2d</code> uses image Detectors/descriptors engine which requires images with lots of features and details in that. In simple words, more complex images are better for this type of recognition. You can learn more about <a href="http://introlab.github.io/find-object/">Find Object image recognition</a> here. </span><br><br><span class="material-icons MuiIcon-root" aria-hidden="true"> lightbulb </span> <span>Use simple names for your images such as <code>15.jpg</code> and place them in <code>~/robot/data/images</code> folder on QTPC. Do not forget to relaunch the <code>find_object_2d</code> or reboot the robot to load your images. </span><h2 class="anchor anchorWithStickyNavbar_mojV" id="how-to-use-intel-realsense-sdk-with-qtrobot">How to use Intel RealSense SDK with QTrobot<a class="hash-link" href="#how-to-use-intel-realsense-sdk-with-qtrobot" title="Direct link to heading">‚Äã</a></h2><p>The <a href="https://github.com/IntelRealSense/librealsense/" target="_blank" rel="noopener noreferrer">Intel¬Æ RealSense‚Ñ¢ SDK 2.0</a> is a cross-platform library for Intel¬Æ RealSense‚Ñ¢ depth cameras, which allows depth and color streaming, and provides intrinsic and extrinsic calibration information. The library also offers synthetic streams (pointcloud, depth aligned to color and vise-versa), and a built-in support for record and playback of streaming sessions.</p><p>The SDK comes with:</p><ul><li><strong>Intel¬Æ RealSense‚Ñ¢ Viewer</strong>: With this application, you can quickly access your Intel¬Æ RealSense‚Ñ¢ Depth Camera to view the depth stream, visualize point clouds, record and playback streams, configure your camera settings, modify advanced controls, enable depth visualization and post processing and much more.</li><li><strong>Depth Quality Tool</strong>: This application allows you to test the camera‚Äôs depth quality, including: standard deviation from plane fit, normalized RMS ‚Äì the subpixel accuracy, distance accuracy and fill rate. You should be able to easily get and interpret several of the depth quality metrics and record and save the data for offline analysis.</li><li><strong>Debug Tools</strong>: Device enumeration, FW logger, etc as can be seen at the tools directory</li><li><strong>Code Samples</strong>: These simple examples demonstrate how to easily use the SDK to include code snippets that access the camera into your applications. Check some of the C++ examples including capture, pointcloud and more and basic C examples</li><li><strong>Wrappers</strong>: 	Python, C#/.NET, Node.js API, as well as integration with the following 3rd-party technologies: ROS, ROS2, LabVIEW, OpenCV, PCL, Unity, Matlab, OpenNI, UnrealEngine4 and more to come.</li></ul><p>You can follow this <a href="https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md" target="_blank" rel="noopener noreferrer">instalation process</a> for QTPC. Most of these interfaces/softwares <strong>exclusively</strong> need access to the camera. That means, for example, one should first stop <code>qt_nuitrack_app</code> or any other running software that is using camera, and run its own software. </p><p>To disable the <code>qt_nuitrack_app</code> you need to edit autostart script (<code>~/robot/autostart/autostart_screens.sh</code>) on <strong>QTPC</strong>, which runs on boot of the QTrobot.</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">nano</span><span class="token plain"> ~/robot/autostart/autostart_screens.sh</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>and comment this line below:</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">#run_script &quot;start_qt_nuitrack_app.sh&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>After that on every next reboot of the QTrobot <code>qt_nuitrack_app</code> will not run by default.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="how-to-use-standard-ros-usb_cam-with-qtrobot">How to use standard ROS usb_cam with QTrobot<a class="hash-link" href="#how-to-use-standard-ros-usb_cam-with-qtrobot" title="Direct link to heading">‚Äã</a></h2><p>ROS <a href="https://wiki.ros.org/usb_cam" target="_blank" rel="noopener noreferrer"><strong>usb_cam</strong></a> is ROS driver for generic USB cameras. It uses libusb_cam and publishes images as type of sensor_msgs::Image and uses <a href="https://wiki.ros.org/image_transport" target="_blank" rel="noopener noreferrer">image_transport</a> library to allow compressed image transport.</p><p>The usb_cam publishes raw image data from camera to <code>/camera/color/image_raw</code> topic. The message type is <code>sensor_msgs/Image</code>:</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Header header        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Header timestamp, etc</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">uint32 height         </span><span class="token comment" style="color:rgb(98, 114, 164)"># image height, that is, number of rows</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">uint32 width          </span><span class="token comment" style="color:rgb(98, 114, 164)"># image width, that is, number of columns</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">string encoding       </span><span class="token comment" style="color:rgb(98, 114, 164)"># Encoding of pixels -- channel meaning, ordering, size</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">uint8 is_bigendian    </span><span class="token comment" style="color:rgb(98, 114, 164)"># is this data bigendian?</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">uint32 step           </span><span class="token comment" style="color:rgb(98, 114, 164)"># Full row length in bytes</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">uint8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> data          </span><span class="token comment" style="color:rgb(98, 114, 164)"># actual matrix data, size is (step * rows)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Some cameras (particularly webcams) output their image data already in JPEG format (compressed image). When running the <code>usb_cam</code> you can read also <code>/camera/color/image_raw/compressed</code> which publises compressed image format <code>sensor_msgs/CompressedImage</code>:</p><div class="codeBlockContainer_I0IT language-bash theme-code-block"><div class="codeBlockContent_wNvx bash"><pre tabindex="0" class="prism-code language-bash codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Header header        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Header timestamp, etc </span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">string </span><span class="token function" style="color:rgb(80, 250, 123)">format</span><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Specifies the format of the data (jpeg, png)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">uint8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> data         </span><span class="token comment" style="color:rgb(98, 114, 164)"># Compressed image buffer</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></div><div class="admonition-content"><p>ROS usb_cam is already pre-installed on QTPC. To enable it you need to add <code>run_script start_ros_usb_cam.sh;</code> to the <code>~/robot/autostart/autostart_screens.sh</code> and disable the other interfaces that are using the camera.</p></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/v1/modules/microphone"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">QTrobot Audio processing and Microphone</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/v1/modules/motors"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">QTrobot Motion and Actuators</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#software-interfaces" class="table-of-contents__link toc-highlight">Software Interfaces</a></li><li><a href="#human-3d-body-and-facial-tracking" class="table-of-contents__link toc-highlight">Human 3D body and facial tracking</a><ul><li><a href="#using-qt-nuitrack-interface-from-terminal" class="table-of-contents__link toc-highlight">Using QT Nuitrack interface from terminal</a></li><li><a href="#using-qt-nuitrack-interface-from-code" class="table-of-contents__link toc-highlight">Using QT Nuitrack interface from code</a></li><li><a href="#using-qt-nuitrack-interface-from-visual-studio-blocks" class="table-of-contents__link toc-highlight">Using QT Nuitrack interface from visual studio blocks</a></li><li><a href="#tips-for-better-skeleton-and-facial-emotion-recognition" class="table-of-contents__link toc-highlight"><strong>Tips</strong> for better skeleton and facial emotion recognition</a></li></ul></li><li><a href="#image-recognition-with-qtrobot" class="table-of-contents__link toc-highlight">Image recognition with QTrobot</a><ul><li><a href="#detecting-a-custom-object" class="table-of-contents__link toc-highlight">Detecting a custom object</a></li><li><a href="#tips-for-better-object-recognition" class="table-of-contents__link toc-highlight"><strong>Tips</strong> for better object recognition</a></li></ul></li><li><a href="#how-to-use-intel-realsense-sdk-with-qtrobot" class="table-of-contents__link toc-highlight">How to use Intel RealSense SDK with QTrobot</a></li><li><a href="#how-to-use-standard-ros-usb_cam-with-qtrobot" class="table-of-contents__link toc-highlight">How to use standard ROS usb_cam with QTrobot</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Visual Scripting</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro_graphical">Quick start</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tutorials/intro_studio">Tutorials</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blocks_api">Blocks reference</a></li><li class="footer__item"><a href="https://qtrobot.luxai.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">QTrobot Studio</a></li></ul></div><div class="col footer__col"><div class="footer__title">Coding</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro_code">Quick start</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tutorials/intro_ros">Tutorials</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/modules/display">Competences</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/api_ros">API references</a></li></ul></div><div class="col footer__col"><div class="footer__title">GitHub</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/luxai-qtrobot/software" target="_blank" rel="noopener noreferrer" class="footer__link-item">Software</a></li><li class="footer__item"><a href="https://github.com/luxai-qtrobot/tutorials" target="_blank" rel="noopener noreferrer" class="footer__link-item">Tutorials</a></li><li class="footer__item"><a href="https://github.com/luxai-qtrobot/QA/issues?q=is%3Aopen+is%3Aissue+label%3Aquestion" target="_blank" rel="noopener noreferrer" class="footer__link-item">Q&amp;A</a></li></ul></div><div class="col footer__col"><div class="footer__title">LuxAI S.A.</div><ul class="footer__items"><li class="footer__item"><a href="https://luxai.com/humanoid-social-robot-for-research-and-teaching/" target="_blank" rel="noopener noreferrer" class="footer__link-item">QTrobot for research</a></li><li class="footer__item"><a href="https://luxai.com/assistive-tech-robot-for-special-needs-education/" target="_blank" rel="noopener noreferrer" class="footer__link-item">QTrobot for schools</a></li><li class="footer__item"><a href="https://luxai.com/shop/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Shop</a></li><li class="footer__item"><a class="footer__link-item" href="/support">Get support</a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://luxai.com" target="_blank" rel="noopener noreferrer" class="footerLogoLink_RC3H"><img src="/img/luxai-favicon.ico" alt="LuxAI" class="themedImage_W2Cr themedImage--light_TfLj footer__logo"><img src="/img/luxai-favicon.ico" alt="LuxAI" class="themedImage_W2Cr themedImage--dark_oUvU footer__logo"></a></div><div class="footer__copyright">Copyright ¬© 2023 LuxAI S.A.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.3a6131f5.js"></script>
<script src="/assets/js/main.a8baad6c.js"></script>
</body>
</html>