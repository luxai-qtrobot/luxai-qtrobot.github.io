<!doctype html>
<html class="docs-version-QTRD_v1" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.16">
<link rel="search" type="application/opensearchdescription+xml" title="QTrobot Documentation" href="/opensearch.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"><title data-rh="true">Human facial expression detection using ROS blocks | QTrobot Documentation</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.luxai.com/docs/v1/tutorials/graphical/studio_emotion"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:version" content="QTRD_v1"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-QTRD_v1"><meta data-rh="true" property="og:title" content="Human facial expression detection using ROS blocks | QTrobot Documentation"><meta data-rh="true" name="description" content="signalcellularalt &amp;nbsp;Level:&amp;nbsp; Advanced"><meta data-rh="true" property="og:description" content="signalcellularalt &amp;nbsp;Level:&amp;nbsp; Advanced"><link data-rh="true" rel="icon" href="/img/luxai-favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.luxai.com/docs/v1/tutorials/graphical/studio_emotion"><link data-rh="true" rel="alternate" href="https://docs.luxai.com/docs/v1/tutorials/graphical/studio_emotion" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.luxai.com/docs/v1/tutorials/graphical/studio_emotion" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://NHG3L6L4QM-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.2f2f2307.css">
<link rel="preload" href="/assets/js/runtime~main.813b5b46.js" as="script">
<link rel="preload" href="/assets/js/main.f06513a9.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo_luxai_mini.png" alt="LuxAI" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo_luxai_mini.png" alt="LuxAI" class="themedImage_W2Cr themedImage--dark_oUvU"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" class="navbar__link">Visual Scripting</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/v1/intro_graphical">Quick start</a></li><li><a class="dropdown__link navbar__link--active" href="/docs/v1/tutorials/intro_studio">Tutorials</a></li><li><a class="dropdown__link" href="/docs/v1/blocks_api">Blocks reference</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" class="navbar__link">Coding</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/v1/intro_code">Quick start</a></li><li><a class="dropdown__link" href="/docs/v1/tutorials/intro_ros">Tutorials</a></li><li><a class="dropdown__link" href="/docs/v1/modules/display">Competences</a></li><li><a class="dropdown__link" href="/docs/v1/api_ros">API references</a></li></ul></div><a class="navbar__item navbar__link" href="/demos">Demos</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/docs/v1/intro_code">QTrobot V1</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/tutorials/graphical/studio_emotion">QTrobot V2</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/docs/v1/tutorials/graphical/studio_emotion">QTrobot V1</a></li></ul></div><a class="navbar__item navbar__link" href="/support">Support</a><a href="https://github.com/luxai-qtrobot" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="searchBox_qEbK"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><aside class="theme-doc-sidebar-container docSidebarContainer_rKC_"><div class="sidebar_CW9Y"><nav class="menu thin-scrollbar menu_SkdO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/v1/tutorials/intro_studio">Introduction to QTrobot Studio</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/v1/tutorials/graphical/studio_story">Visual Scripting Tutorials</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/v1/tutorials/graphical/studio_story">Basic</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/v1/tutorials/graphical/studio_visuals">Intermediate</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/v1/tutorials/graphical/studio_ros">Advanced</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/v1/tutorials/graphical/studio_ros">Using ROS blocks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/v1/tutorials/graphical/studio_emotion">Human facial expression detection using ROS blocks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/v1/tutorials/graphical/studio_emotion_game">Create an emotion game using cards</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/v1/tutorials/graphical/studio_card_mem_game">Create an interactive memory game using cards</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/v1/tutorials/graphical/studio_gesture_mem_game">Create an interactive memory game using human gestures</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/v1/tutorials/graphical/studio_reporting_ros">Custom data collection using ROS</a></li></ul></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_cwdi"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_xORG"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_TCnq"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is documentation for <b>QTrobot for Research V1</b>.</div><div class="margin-top--md">For QTrobot for Research V2, please refer to the <a href="/docs/tutorials/graphical/studio_emotion">QTrobot V2</a> documentation.</div></div><div class="docItemContainer_vinB"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Xlws" aria-label="breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a class="breadcrumbs__link breadcrumbsItemLink_e5ie" href="/">üè†</a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link breadcrumbsItemLink_e5ie">Visual Scripting Tutorials</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link breadcrumbsItemLink_e5ie">Advanced</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><a class="breadcrumbs__link breadcrumbsItemLink_e5ie" href="/docs/v1/tutorials/graphical/studio_emotion">Human facial expression detection using ROS blocks</a></li></ul></nav><span class="theme-doc-version-badge badge badge--secondary">Version: QTrobot V1</span><div class="theme-doc-markdown markdown"><header><h1>Human facial expression detection using ROS blocks</h1></header><div class="admonition admonition-info alert alert--info"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Overview</h5></div><div class="admonition-content"><span class="material-icons MuiIcon-root" aria-hidden="true">signal_cellular_alt</span> <span>¬†<strong>Level:</strong>¬† <em>Advanced</em></span><br> <span class="material-icons MuiIcon-root" aria-hidden="true"> track_changes </span> <span>¬†<strong>Goal:</strong>¬† <em>learn how to detect Human facial expressions using ROS blocks</em></span><br> <span class="material-icons MuiIcon-root" aria-hidden="true"> task_alt </span> <span>¬†<strong>Requirements:</strong></span><ul><li>¬†<!-- -->¬†<a href="/docs/intro_graphical">Quick start with graphical programming</a>  </li><li>¬†<!-- -->¬†<a href="/docs/tutorials/graphical/studio_ros">Basic understanding of ROS blocks</a></li></ul></div></div><p>In this example, we create an emotion imitation application using our blocks from QTrobot Studio. Here is the scenario:</p><p><strong><em>QTrobot looks for a person&#x27;s face and recognizes one of these three emotions: happy, angry and surprise. Then QTrobot will imitate that emotion by showing the corresponding facial expression. If no person appears within some time, QTrobot looks around by randomly moving his head to left or right in search of a human face.</em></strong></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="how-does-the-qtrobots-emotion-recognition-work">How does the QTrobot&#x27;s emotion recognition work?<a class="hash-link" href="#how-does-the-qtrobots-emotion-recognition-work" title="Direct link to heading">‚Äã</a></h2><p>Now let‚Äôs see how we can easily implement our scenario in QTrobot Studio. There is <a href="/docs/api_ros#human-3d-tracking-interface">QTrobot nuitrack interface</a> which is running on the robot. Using QTrobot&#x27;s camera, the <code>qt_nuitrack_app</code> simply detects whatever somebody is standing in front of the QTrobot and reading his/hers face expressions/emotions. If we stand in front of the QTrobot, the <code>qt_nuitrack_app</code> recognizes the face expression and it publishes the corresponding message to <code>/qt_nuitrack_app/faces</code> topic.  The topic uses a message of type <code>qt_nuitrack_app/Faces</code>. Within this message, the value of faces, is an array of <code>FaceInfo</code> (multiple faces):</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">qt_nuitrack_app/FaceInfo[] faces</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  int32 id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  string gender</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  int32 age_years</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  string age_type</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  float64 emotion_neutral</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  float64 emotion_angry</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  float64 emotion_happy</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  float64 emotion_surprise</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  float64[] rectangle</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  float64[] left_eye</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  float64[] right_eye</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  float64[] angles</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>we are interested in <code>emotion_neutral</code>, <code>emotion_angry</code> and <code>emotion_surprise</code> for our scenario. The value of these fields is the confidence level of detected emotion ranged from <code>0.0</code> to <code>1.0</code>. Higher value represents higher confidence level in recognizing the corresponding emotion. In our example, we consider values above <code>0.9</code> as confident enough.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="implementation">Implementation<a class="hash-link" href="#implementation" title="Direct link to heading">‚Äã</a></h2><p>First we try to read a message from <code>/qt_nuitrack_app/faces</code> topic using <a href="/docs/blocks_api#ros-subscriber-block">ROS Subscriber block</a>  and check if the message is not empty.  After that, we extend it so that we read a detected emotion confidence level and react accordingly. Now we have our main building blocks, we implement the logic of the game as it is described in the scenario, and finally we put all the pieces together and adds some speech messages to make our games more interesting. </p><h3 class="anchor anchorWithStickyNavbar_mojV" id="1-read-the-detected-emotion">1. Read the detected emotion<a class="hash-link" href="#1-read-the-detected-emotion" title="Direct link to heading">‚Äã</a></h3><p>We can use the <a href="/docs/blocks_api#ros-subscriber-block">ROS Subscriber block</a> to read the message published by <code>qt_nuitrack_app/faces</code> as it shown here: </p><div id="blocksview1" style="height:220px;width:100%;padding:3px;background-color:#614b7f">   </div><h3 class="anchor anchorWithStickyNavbar_mojV" id="2-extend-the-blocks-to-extract-emotion-confidence-level">2. Extend the blocks to extract emotion confidence level<a class="hash-link" href="#2-extend-the-blocks-to-extract-emotion-confidence-level" title="Direct link to heading">‚Äã</a></h3><p>In our scenario we are interested to know which emotion the user has shown and react accordingly.</p><p>Our <strong>ROS Subscriber</strong> block waits until a human facial emotion is detected (store it in <code>faces</code> variable) or <code>10s</code> passed without appearance of any person in front of the QTrobot. Then we check if any face has been detected by simple checking the validity of <code>faces</code>. If valid, this variable holds an <code>array</code> of detect <code>faces</code>. In our scenario we are interested in the first detected <code>face</code>. Thus, we need to get the first item of <code>faces</code> array. We call this <code>my_face</code> which is of type <code>FaceInfo</code>. Then we simply check the confidence value of each interested <code>emotions</code>. For example, if the confidence value of <code>emotion_happy</code> is more than <code>0.9</code>, we show <code>QTrobot Happy emotion</code>. We do the similar thing for other emotions.</p><div id="blocksview2" style="height:420px;width:100%;padding:3px;background-color:#614b7f">   </div><br><h3 class="anchor anchorWithStickyNavbar_mojV" id="3-make-qtrobot-to-look-around">3. Make QTrobot to look around<a class="hash-link" href="#3-make-qtrobot-to-look-around" title="Direct link to heading">‚Äã</a></h3><p>Now we just need to implement the look-around part in case no one appears in front of the robot. We want to move only the robot <code>head yaw joint</code> (left and right) to a random position. For this purpose, we use standard <code>random-integer</code> block to create message with random number between <code>-40</code> to <code>40</code> degree (for <code>HeadYaw</code> joint). Then we simply publish it to <code>/qt_robot/head_position/command</code> topic. Using the <code>random-integer</code> blocks, we also show yawing face randomly every few times that QTrobot does not see any face.</p><p>Let see how we can implement it using our blocks: </p><div id="blocksview3" style="height:350px;width:100%;padding:3px;background-color:#614b7f">   </div><br><h3 class="anchor anchorWithStickyNavbar_mojV" id="5-put-it-all-together">5. Put it all together<a class="hash-link" href="#5-put-it-all-together" title="Direct link to heading">‚Äã</a></h3><p>Now we have all our building blocks we can put them together and finalize our scenario. We wrap all blocks by LuxAI <code>repeat until I press stop</code> block. This repeat blocks keeps our game running until we stop it using Educator Tablet. Then we add a condition block (IF) to check the detection of the user. If the user is not present for <code>10 seconds</code>, QTrobot will look around. Here is the complete source of our memory game: </p><div id="blocksview4" style="height:600px;width:100%;padding:3px;background-color:#614b7f">   </div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/v1/tutorials/graphical/studio_ros"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Using ROS blocks</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/v1/tutorials/graphical/studio_emotion_game"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Create an emotion game using cards</div></a></div></nav></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Visual Scripting</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro_graphical">Quick start</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tutorials/intro_studio">Tutorials</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blocks_api">Blocks reference</a></li><li class="footer__item"><a href="https://qtrobot.luxai.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">QTrobot Studio</a></li></ul></div><div class="col footer__col"><div class="footer__title">Coding</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro_code">Quick start</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tutorials/intro_ros">Tutorials</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/modules/display">Competences</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/api_ros">API references</a></li></ul></div><div class="col footer__col"><div class="footer__title">GitHub</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/luxai-qtrobot/software" target="_blank" rel="noopener noreferrer" class="footer__link-item">Software</a></li><li class="footer__item"><a href="https://github.com/luxai-qtrobot/tutorials" target="_blank" rel="noopener noreferrer" class="footer__link-item">Tutorials</a></li><li class="footer__item"><a href="https://github.com/luxai-qtrobot/QA/issues?q=is%3Aopen+is%3Aissue+label%3Aquestion" target="_blank" rel="noopener noreferrer" class="footer__link-item">Q&amp;A</a></li></ul></div><div class="col footer__col"><div class="footer__title">LuxAI S.A.</div><ul class="footer__items"><li class="footer__item"><a href="https://luxai.com/humanoid-social-robot-for-research-and-teaching/" target="_blank" rel="noopener noreferrer" class="footer__link-item">QTrobot for research</a></li><li class="footer__item"><a href="https://luxai.com/assistive-tech-robot-for-special-needs-education/" target="_blank" rel="noopener noreferrer" class="footer__link-item">QTrobot for schools</a></li><li class="footer__item"><a href="https://luxai.com/shop/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Shop</a></li><li class="footer__item"><a class="footer__link-item" href="/support">Get support</a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://luxai.com" target="_blank" rel="noopener noreferrer" class="footerLogoLink_RC3H"><img src="/img/luxai-favicon.ico" alt="LuxAI" class="themedImage_W2Cr themedImage--light_TfLj footer__logo"><img src="/img/luxai-favicon.ico" alt="LuxAI" class="themedImage_W2Cr themedImage--dark_oUvU footer__logo"></a></div><div class="footer__copyright">Copyright ¬© 2022 LuxAI S.A.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.813b5b46.js"></script>
<script src="/assets/js/main.f06513a9.js"></script>
</body>
</html>