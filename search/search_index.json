{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Developer Guide \u00b6 Welcome to Developer Guide. Here you can find all tutorials and demos for our QTrobot . Getting Started User Manual What is QTrobot? \u00b6 QTrobot, is a commercial available toddler-like humanoid robot built by LuxAI S.A. It is a socially engaging and interactive robot with a wide areas of application. QTrobot is currently being used for emotional training of children with autism, post-stroke rehabilitation and elderly cognitive and physical rehabilitation. Getting Started \u00b6 In the following sections you will find different way of programing QTrobot. Programming on the QTrobot \u00b6 QTrobot comes with an internal high-performance Intel NUC running Ubuntu 16.04 LTS operating system. Programming QTrobot is as easy as doing on your desktop PC. Just connect a keyboard/mouse and monitor to the robot and Voila ! Programming on your PC \u00b6 Warning You don NOT need this installation if you are programming directly on the QTrobot. 1. Installing ROS \u00b6 The following steps guide you through the installation of ROS Kinetic. For the complete installation guide of ROS see Install ROS Notice Please notice that QTrobot can be used with other versions of ROS such as Lunar and Melodic. Installing ROS 1. Configure your Ubuntu repositories You need to configure your Ubuntu repositories to allow \"restricted\" \"universe\" and \"multiverse\". You can check Ubuntu documentation for doing this. 2. Setup your sources.list Setup your computer to accept software from packages.ros.org. sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' 3. Set up your keys sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 4. Install Now you can update and install ros-kinetic-desktop-full sudo apt-get update && sudo apt-get install ros-kinetic-desktop-full 5. Setup Catkin workspace source /opt/ros/kinetic/setup.bash mkdir -p ~/catkin_ws/src && cd ~/catkin_ws/ && catkin_make 2. Configure ROS environment for QTrobot \u00b6 The following steps guide you through the configuration of your ROS environment for QTrobot. ROS environment for QTrobot You need to edit your ~/ . bash_aliases and add following lines. Change ROS_IP to your PC IP. source /opt/ros/kinetic/setup.bash source ~/catkin_ws/devel/setup.bash ## QTrobot export ROS_IP = <your PC IP address> export ROS_MASTER_URI = http://192.168.100.1:11311 Which is my IP address ? To get your IP address, First you need to connect to the QTrobot WiFi hotspot. Then open a terminal on your PC and run the following command: ifconfig To apply this configuration you can open a new terminal or run this command: source ~/.bash_aliases 3. Check your ROS setup \u00b6 Last step is to connect to the QTrobot WiFi hotspot and test your ROS environment. Test To test your environment you can list all rostopics from QTrobot. You can do that with running this command. rostopic list If everything is working you should see output similar to this one. /rosout /qt_robot/audio/play /qt_robot/behavior/talkAudio /qt_robot/emotion/show /qt_robot/gesture/play /qt_robot/head_position/command /qt_robot/joints/state ... Now you can start having fun. Connect to QTrobot via ssh \u00b6 Your QTrobot comes with two integrated computers both running Ubuntu 16.04 LTS operating system. QTROBOT (ARM Cortex-A53) : This is the embedded computer of QTrobot which runs the robot main software such as motors controller, gestures, emotions and implement most of the ROS interfaces. The ROS server is running on this machine. QTPC (Intel NUC i5) : This is the high-performance computer of the robot which allows you to develop and run your high computational codes. QTPC is connected to QTROBOT via LAN and communicates to all robot modules using ROS. This machine also implements some of the QTrobot ROS interfaces such as 3D camera images. Accessing QTPC via SSH After connecting to the robot WIFI hotspot, open a terminal from your PC and SSH to the robot using IP 192 . 168 . 100 . 2 . ssh qtrobot@192.168.100.2 qtrobot@qt ' s password:*******","title":"Home"},{"location":"#developer-guide","text":"Welcome to Developer Guide. Here you can find all tutorials and demos for our QTrobot . Getting Started User Manual","title":"Developer Guide"},{"location":"#what-is-qtrobot","text":"QTrobot, is a commercial available toddler-like humanoid robot built by LuxAI S.A. It is a socially engaging and interactive robot with a wide areas of application. QTrobot is currently being used for emotional training of children with autism, post-stroke rehabilitation and elderly cognitive and physical rehabilitation.","title":"What is QTrobot?"},{"location":"#getting-started","text":"In the following sections you will find different way of programing QTrobot.","title":"Getting Started"},{"location":"#programming-on-the-qtrobot","text":"QTrobot comes with an internal high-performance Intel NUC running Ubuntu 16.04 LTS operating system. Programming QTrobot is as easy as doing on your desktop PC. Just connect a keyboard/mouse and monitor to the robot and Voila !","title":"Programming on the QTrobot"},{"location":"#programming-on-your-pc","text":"Warning You don NOT need this installation if you are programming directly on the QTrobot.","title":"Programming on your PC"},{"location":"#1-installing-ros","text":"The following steps guide you through the installation of ROS Kinetic. For the complete installation guide of ROS see Install ROS Notice Please notice that QTrobot can be used with other versions of ROS such as Lunar and Melodic. Installing ROS 1. Configure your Ubuntu repositories You need to configure your Ubuntu repositories to allow \"restricted\" \"universe\" and \"multiverse\". You can check Ubuntu documentation for doing this. 2. Setup your sources.list Setup your computer to accept software from packages.ros.org. sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' 3. Set up your keys sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 4. Install Now you can update and install ros-kinetic-desktop-full sudo apt-get update && sudo apt-get install ros-kinetic-desktop-full 5. Setup Catkin workspace source /opt/ros/kinetic/setup.bash mkdir -p ~/catkin_ws/src && cd ~/catkin_ws/ && catkin_make","title":"1. Installing ROS"},{"location":"#2-configure-ros-environment-for-qtrobot","text":"The following steps guide you through the configuration of your ROS environment for QTrobot. ROS environment for QTrobot You need to edit your ~/ . bash_aliases and add following lines. Change ROS_IP to your PC IP. source /opt/ros/kinetic/setup.bash source ~/catkin_ws/devel/setup.bash ## QTrobot export ROS_IP = <your PC IP address> export ROS_MASTER_URI = http://192.168.100.1:11311 Which is my IP address ? To get your IP address, First you need to connect to the QTrobot WiFi hotspot. Then open a terminal on your PC and run the following command: ifconfig To apply this configuration you can open a new terminal or run this command: source ~/.bash_aliases","title":"2. Configure ROS environment for QTrobot"},{"location":"#3-check-your-ros-setup","text":"Last step is to connect to the QTrobot WiFi hotspot and test your ROS environment. Test To test your environment you can list all rostopics from QTrobot. You can do that with running this command. rostopic list If everything is working you should see output similar to this one. /rosout /qt_robot/audio/play /qt_robot/behavior/talkAudio /qt_robot/emotion/show /qt_robot/gesture/play /qt_robot/head_position/command /qt_robot/joints/state ... Now you can start having fun.","title":"3. Check your ROS setup"},{"location":"#connect-to-qtrobot-via-ssh","text":"Your QTrobot comes with two integrated computers both running Ubuntu 16.04 LTS operating system. QTROBOT (ARM Cortex-A53) : This is the embedded computer of QTrobot which runs the robot main software such as motors controller, gestures, emotions and implement most of the ROS interfaces. The ROS server is running on this machine. QTPC (Intel NUC i5) : This is the high-performance computer of the robot which allows you to develop and run your high computational codes. QTPC is connected to QTROBOT via LAN and communicates to all robot modules using ROS. This machine also implements some of the QTrobot ROS interfaces such as 3D camera images. Accessing QTPC via SSH After connecting to the robot WIFI hotspot, open a terminal from your PC and SSH to the robot using IP 192 . 168 . 100 . 2 . ssh qtrobot@192.168.100.2 qtrobot@qt ' s password:*******","title":"Connect to QTrobot via ssh"},{"location":"QA/","text":"Frequently Asked Questions \u00b6 This QTrobot FAQ is a summary of the issues from our Github repo . You can always open a new issue/feature request for any interfaces and we do our best to fix/implement them. The rest of the code including all demo application are open source and you are more than welcome to contribute in our Tutorial repo . Can't find what you're looking for? ASK YOUR QUESTION HERE","title":"**Frequently Asked Questions**"},{"location":"QA/#frequently-asked-questions","text":"This QTrobot FAQ is a summary of the issues from our Github repo . You can always open a new issue/feature request for any interfaces and we do our best to fix/implement them. The rest of the code including all demo application are open source and you are more than welcome to contribute in our Tutorial repo . Can't find what you're looking for? ASK YOUR QUESTION HERE","title":"Frequently Asked Questions"},{"location":"about/","text":"About \u00b6 This QTrobot tutorial website is for code samples and tutorials for programming QTrobot by LuxAI S.A. . Demo application and examples are open source and you are more than welcome to contribute in our Tutorial repo.","title":"About"},{"location":"about/#about","text":"This QTrobot tutorial website is for code samples and tutorials for programming QTrobot by LuxAI S.A. . Demo application and examples are open source and you are more than welcome to contribute in our Tutorial repo.","title":"About"},{"location":"demos/","text":"Demos \u00b6 About Here is the list of all demos with QTrobot. All demos and code you can find in our github tutorial repository. Range of Motion & DOF contains motor movement demo source code! Emotion Game Image recognition emotion demo source code! Memory Game Image recognition memory demo source code! Gesture recognition Gesture recognition with 3D camera source code! Face, Age & Gender recognition Face, Age & Gender recognition with 3D camera source code! Voice interaction Voice interaction with Far-Field Microphone Array source code! Voice activity & direction detection Voice activity & direction detection with Far-Field Microphone Array source code! Skeleton Tracking Skeleton Tracking with 3D camera","title":"API"},{"location":"demos/#demos","text":"About Here is the list of all demos with QTrobot. All demos and code you can find in our github tutorial repository.","title":"Demos"},{"location":"examples/","text":"Examples \u00b6 About Here is the list of all examples with QTrobot . All examples and code you can find in our github tutorial repository . Interfaces \u00b6 Audio interface : demonstrates how to make robot sing something Emotion interface : demonstrates how to make robot show some emotion Speech interface : demonstrates how to make robot say something Motor \u00b6 Motors command : demonstrates how to command robot motors positions Motors gesture : demonstrates how to run prerecorded gestures Motors state : demonstrates how to read robot joints state such as positions Voice \u00b6 Voice activity : demonstrates how to show voice activity Voice direction : demonstrates how to read direction of voice Todo Vision","title":"**Examples**"},{"location":"examples/#examples","text":"About Here is the list of all examples with QTrobot . All examples and code you can find in our github tutorial repository .","title":"Examples"},{"location":"examples/#interfaces","text":"Audio interface : demonstrates how to make robot sing something Emotion interface : demonstrates how to make robot show some emotion Speech interface : demonstrates how to make robot say something","title":"Interfaces"},{"location":"examples/#motor","text":"Motors command : demonstrates how to command robot motors positions Motors gesture : demonstrates how to run prerecorded gestures Motors state : demonstrates how to read robot joints state such as positions","title":"Motor"},{"location":"examples/#voice","text":"Voice activity : demonstrates how to show voice activity Voice direction : demonstrates how to read direction of voice Todo Vision","title":"Voice"},{"location":"manual/","text":"User Manual \u00b6 In the following sections you will find user manual of the QTrobot. 1. What is QTrobot? \u00b6 QTrobot, is a toddler-like humanoid robot built by LuxAI S.A. It is a socially engaging and interactive robot with a wide area of application. QTrobot is currently being used for emotional training of children with autism, post-stroke rehabilitation, elderly cognitive and physical rehabilitation as well as research in the field of human robot interaction. 2. QTrobot Power \u00b6 QTrobot power button has three color states, each indicating the robot current power state: LED OFF: robot is disconnected from its main power supply. LED with Dim Light: robot is connected to its power supply but is not running. LED Fully ON: robot is running. Power ON \u00b6 To power the robot on, simply connect the robot's power supply 1 .This triggers the power on process and your robot becomes ready less than a minute. After powering on, you can see the robot face is on and the motors are in their home position. If the robot is off and it is connected to the power supply 2 simply push the power button to turn on the robot. Power OFF \u00b6 To power off the robot, simply press the power button when it is on. You can see that the robot motors move to the parking position and the robot display turns off in less than one minute. The Dim light at the power button indicates that it is safe to disconnect the power supply. Warning Avoid turning off the robot by cutting the power supply. This may damage your product. Methods to power off the QTrobot \u00b6 Apart from using the power button, you can power off the robot in different ways: Powering off using the robot control panel Connect to robot WIFI hotspot Access the control panel using http : // qtrrobot or http : // 192 . 168 . 100 . 1 in your web browser Click on \"Power off\" button Power off using QTrobot tablet App Connect to robot WIFI hotspot Open the Tablet App Shutdown the robot from the main menu Power off using developer terminal Connect to robot WIFI hotspot Login into robot via SSH using provided credentials Power the robot off ssh qtrobot@qtrobot sudo poweroff 3. Connecting to QTrobot WiFi Hotspot \u00b6 QTrobot comes with integrated WIFI interfaces. One of them provide the hotspot to remotely connect to the robot and the other one can be used to connect the robot to public WIF and internet. From your device/PC/tablet, just look for the robot WIFI hotspot SSID and connect to it. The hotspot name is your robot name (e.g. QT100). 4. Connect to QTrobot via ssh \u00b6 Your QTrobot comes with two integrated computers both running Ubuntu 16.04 LTS operating system. QTROBOT (ARM Cortex-A53) : This is the embedded computer of QTrobot which runs the robot main software such as motors controller, gestures, emotions and implement most of the ROS interfaces. The ROS server is running on this machine. QTPC (Intel NUC i5) : This is the high-performance computer of the robot which allows you to develop and run your high computational codes. QTPC is connected to QTROBOT via LAN and communicates to all robot modules using ROS. This machine also implements some of the QTrobot ROS interfaces such as 3D camera images. Accessing QTROBOT via SSH \u00b6 After connecting to the robot WIFI hotspot, open a terminal from your PC and SSH to the robot using 'qtrobot' as hostname or using IP 192 . 168 . 100 . 1 3 . ssh qtrobot@qtrobot qtrobot@qt password:******* Accessing QTPC via SSH \u00b6 There are two ways to SSH into QTPC: Via QTROBOT: after connecting to robot WIFI hotspot, first SSH to QTRBOT, then from QTROBOT terminal SSH into QTPC. ssh qtrobot@qtrobot qtrobot@qt password:******* ssh qtpc Directly SSH to QTPC: after connecting to robot WIFI hotspot, open a terminal from your PC and ssh to QTPC using 192 . 168 . 100 . 2 ssh qtrobot@192.168.100.2 qtrobot@qt password:******* 5. Accessing The Control Panel \u00b6 QTrobot has two web-based control panels one for QTROBOT and the other for QTPCP. These panels facilitate robot configuration such as connecting to the internet or to enable/disable robot startup scripts (see section Robot Autostart Scripts ). You can connect separately to each control panel using their corresponding IPs. To connect to the QTROBOT or QTPC web control panel, after connecting to the robot WIFI hotspot: For QTROBOT, open a browser and type http : // 192 . 168 . 100 . 1 : 8080 or http : // qtrobot For QTPC, open a browser and type http : // 192 . 168 . 100 . 2 : 8080 Log in to the panel using the QTrobot's username and password provided to you. 6. Connecting to a Home Network and Internet \u00b6 You can connect the robot to your home network and internet using the WIFI from QTPC either via terminal or using the control panel of QTPC Warning Do not use the QTROBOT WIFI to connect to a network. Instead use WIFI from QTPC! Connecting to the Internet from Terminal \u00b6 Open a terminal and SSH to QTPC and use 'nmtui' tool: qtrobot@qtpc:~$ sudo nmtui Connecting to the Internet from Control panel \u00b6 Connect to the QTPC control panel and navigate to \"Configure WIFI\". Then simply follow the instructions. 7. Robot Autostart scripts \u00b6 Warning Assure that you completely understood the purpose of each script and you are aware of what you are doing What are autostart scripts? \u00b6 Autostart scripts are simply some bash scripts which are executed at robot startup time. These scripts prepare robot network, setup ROS environment, launch QTrobot motor and other controllers, setup log files and etc. Where are they located? \u00b6 there are two sets of autostart scripts on QTrobot: 1. Autostart scripts on RPI 2. Autostart scripts on NUC Both sets are located under ~/ robot / autostart folder. How they are executed at startup time? \u00b6 The scripts are run by linux Cron job scheduler. In fact, a specific corn job is configured to run autostart_screens . sh script at linux boot. The other scripts are launched by autostart_screens . sh and their output are redirected to the corresponding log files. To add your own script (e.g. start_my_script . sh ) you can simply add the following line to the autostart_screens . sh : { wait_for_network run_script \"start_qtroutes.sh\" ... ... run_script \"start_my_script.sh\" } & >> ${ LOG_FILE } How can I access them? \u00b6 You can access them via terminal of NUC/RPI or via QTrobot web interface for enable/disable them: Web interface on RPI: http : // 192 . 168 . 100 . 1 : 8080 Web interface on NUC: http : // 192 . 168 . 100 . 2 : 8080 What are the main autostart scripts? \u00b6 As I explained above, there are some important scripts which prepare the robot network, ROS environment and launch the motor controller and other robot interfaces. All of these scripts are running on RPI and are necessary for functionality of QTrobot. Here are the main startup scripts on RPI : \u00b6 start_qt_routes . sh : prepares network routing between RPI and NUC for internet sharing and etc. start_roscore . sh : launches roscore start_qtpc . sh : power on NUC via wake-on-lan. start_qt_motor . sh : launch qt_motor node including motor and gesture controllers. start_qt_robot_interface . sh : launch qt_robot_interface node which implements QTrobot emotion (face), audio, speech, behavior and other interfaces. start_qt_webconfing . sh : launch QTrobot web config interface on RPI Here are the main startup scripts on NUC : \u00b6 The NUC pc is most convenient place to develop code and run your own autostart scripts and apps. Most of the default scripts are simply running the QTrobot open source demos and examples and can be safely disabled and/or modified. There is nothing especial running by autostart scripts on NUC except: - start_qt_nuitrack_app . sh : which run Nuitrack skeleton tracking and camera interfaces. - start_qt_webconfing . sh : launch QTrobot web config interface on NUC Where are the log files? \u00b6 All programs/ROS nodes which are run by QTrobot autostart scripts redirect their standard output (info/war/error messages) to their corresponding log file. These log files can be found under ~/ robot / autostart / logs folder. 8. Working directly on QTPC \u00b6 Your robot has a standard Ubuntu-based PC. You can use QTPC in the same way you use a standard desktop. That greatly facilitates and accelerates your development cycle as you have a full-featured desktop directly with your QTrobot. To do that: Connect a USB-C extension (or USB-C to HDMI cable) to the USB-C port of QTrobot. Connect your mouse and keyboard to your USB-C extension. Alternatively you can use weirless mouse/keyboard and connect the dongle directly to USB3 port of QTrobot. Connect the HDMI cable of your display to the USB-C extension or use a USB-C to HDMI cable. You will see Ubuntu desktop running Notice You may need to connect the HDMI cable before powering up the robot to make QTPC aware of any external display. 9. QTrobot ROS API \u00b6 The QTrobot (LuxAI) interface aims to facilitate accessing basic robot functionalities leveraging a set of user-friendly ROS interfaces. Each robot\u2019s functionality can be accessed in blocking and non-blocking mode using ROS publish/subscribe and Service/Client interfaces. Info Visit QTrobot ROS wiki for ROS API Demos & Examples Please check our Demos and Examples to check how to use and implement QTrobot interfaces 10. Calling QTrobot APIs \u00b6 You can access each robot's functionality via its publish/subscribe or service/client interfaces. For example, to use the robot 'Speech' functionality from terminal using ROS publisher, you can try: rostopic pub /qt_robot/speech/say std_msgs/String \"data: 'Hello!'\" or by using ROS service call: rosservice call /qt_robot/speech/say \"message: 'Hello!'\" or from a python script: import rospy from std_msgs.msg import String # create a publisher pub = rospy.Publisher ( '/qt_robot/speech/say' , String, queue_size = 10 ) # publish a text message to TTS (non-blocking) pub.publish ( \"Hello! I am QT!\" ) Only use the provided power supply with your robot. \u21a9 In this case you can notice a dim light on the power button. \u21a9 Windows users can use Putty ( www.putty.org ) \u21a9","title":"Trainer Manual"},{"location":"manual/#user-manual","text":"In the following sections you will find user manual of the QTrobot.","title":"User Manual"},{"location":"manual/#1-what-is-qtrobot","text":"QTrobot, is a toddler-like humanoid robot built by LuxAI S.A. It is a socially engaging and interactive robot with a wide area of application. QTrobot is currently being used for emotional training of children with autism, post-stroke rehabilitation, elderly cognitive and physical rehabilitation as well as research in the field of human robot interaction.","title":"1. What is QTrobot?"},{"location":"manual/#2-qtrobot-power","text":"QTrobot power button has three color states, each indicating the robot current power state: LED OFF: robot is disconnected from its main power supply. LED with Dim Light: robot is connected to its power supply but is not running. LED Fully ON: robot is running.","title":"2. QTrobot Power"},{"location":"manual/#power-on","text":"To power the robot on, simply connect the robot's power supply 1 .This triggers the power on process and your robot becomes ready less than a minute. After powering on, you can see the robot face is on and the motors are in their home position. If the robot is off and it is connected to the power supply 2 simply push the power button to turn on the robot.","title":"Power ON"},{"location":"manual/#power-off","text":"To power off the robot, simply press the power button when it is on. You can see that the robot motors move to the parking position and the robot display turns off in less than one minute. The Dim light at the power button indicates that it is safe to disconnect the power supply. Warning Avoid turning off the robot by cutting the power supply. This may damage your product.","title":"Power OFF"},{"location":"manual/#methods-to-power-off-the-qtrobot","text":"Apart from using the power button, you can power off the robot in different ways: Powering off using the robot control panel Connect to robot WIFI hotspot Access the control panel using http : // qtrrobot or http : // 192 . 168 . 100 . 1 in your web browser Click on \"Power off\" button Power off using QTrobot tablet App Connect to robot WIFI hotspot Open the Tablet App Shutdown the robot from the main menu Power off using developer terminal Connect to robot WIFI hotspot Login into robot via SSH using provided credentials Power the robot off ssh qtrobot@qtrobot sudo poweroff","title":"Methods to power off the QTrobot"},{"location":"manual/#3-connecting-to-qtrobot-wifi-hotspot","text":"QTrobot comes with integrated WIFI interfaces. One of them provide the hotspot to remotely connect to the robot and the other one can be used to connect the robot to public WIF and internet. From your device/PC/tablet, just look for the robot WIFI hotspot SSID and connect to it. The hotspot name is your robot name (e.g. QT100).","title":"3. Connecting to QTrobot WiFi Hotspot"},{"location":"manual/#4-connect-to-qtrobot-via-ssh","text":"Your QTrobot comes with two integrated computers both running Ubuntu 16.04 LTS operating system. QTROBOT (ARM Cortex-A53) : This is the embedded computer of QTrobot which runs the robot main software such as motors controller, gestures, emotions and implement most of the ROS interfaces. The ROS server is running on this machine. QTPC (Intel NUC i5) : This is the high-performance computer of the robot which allows you to develop and run your high computational codes. QTPC is connected to QTROBOT via LAN and communicates to all robot modules using ROS. This machine also implements some of the QTrobot ROS interfaces such as 3D camera images.","title":"4. Connect to QTrobot via ssh"},{"location":"manual/#accessing-qtrobot-via-ssh","text":"After connecting to the robot WIFI hotspot, open a terminal from your PC and SSH to the robot using 'qtrobot' as hostname or using IP 192 . 168 . 100 . 1 3 . ssh qtrobot@qtrobot qtrobot@qt password:*******","title":"Accessing QTROBOT via SSH"},{"location":"manual/#accessing-qtpc-via-ssh","text":"There are two ways to SSH into QTPC: Via QTROBOT: after connecting to robot WIFI hotspot, first SSH to QTRBOT, then from QTROBOT terminal SSH into QTPC. ssh qtrobot@qtrobot qtrobot@qt password:******* ssh qtpc Directly SSH to QTPC: after connecting to robot WIFI hotspot, open a terminal from your PC and ssh to QTPC using 192 . 168 . 100 . 2 ssh qtrobot@192.168.100.2 qtrobot@qt password:*******","title":"Accessing QTPC via SSH"},{"location":"manual/#5-accessing-the-control-panel","text":"QTrobot has two web-based control panels one for QTROBOT and the other for QTPCP. These panels facilitate robot configuration such as connecting to the internet or to enable/disable robot startup scripts (see section Robot Autostart Scripts ). You can connect separately to each control panel using their corresponding IPs. To connect to the QTROBOT or QTPC web control panel, after connecting to the robot WIFI hotspot: For QTROBOT, open a browser and type http : // 192 . 168 . 100 . 1 : 8080 or http : // qtrobot For QTPC, open a browser and type http : // 192 . 168 . 100 . 2 : 8080 Log in to the panel using the QTrobot's username and password provided to you.","title":"5. Accessing The Control Panel"},{"location":"manual/#6-connecting-to-a-home-network-and-internet","text":"You can connect the robot to your home network and internet using the WIFI from QTPC either via terminal or using the control panel of QTPC Warning Do not use the QTROBOT WIFI to connect to a network. Instead use WIFI from QTPC!","title":"6. Connecting to a Home Network and Internet"},{"location":"manual/#connecting-to-the-internet-from-terminal","text":"Open a terminal and SSH to QTPC and use 'nmtui' tool: qtrobot@qtpc:~$ sudo nmtui","title":"Connecting to the Internet from Terminal"},{"location":"manual/#connecting-to-the-internet-from-control-panel","text":"Connect to the QTPC control panel and navigate to \"Configure WIFI\". Then simply follow the instructions.","title":"Connecting to the Internet from Control panel"},{"location":"manual/#7-robot-autostart-scripts","text":"Warning Assure that you completely understood the purpose of each script and you are aware of what you are doing","title":"7. Robot Autostart scripts"},{"location":"manual/#what-are-autostart-scripts","text":"Autostart scripts are simply some bash scripts which are executed at robot startup time. These scripts prepare robot network, setup ROS environment, launch QTrobot motor and other controllers, setup log files and etc.","title":"What are autostart scripts?"},{"location":"manual/#where-are-they-located","text":"there are two sets of autostart scripts on QTrobot: 1. Autostart scripts on RPI 2. Autostart scripts on NUC Both sets are located under ~/ robot / autostart folder.","title":"Where are they located?"},{"location":"manual/#how-they-are-executed-at-startup-time","text":"The scripts are run by linux Cron job scheduler. In fact, a specific corn job is configured to run autostart_screens . sh script at linux boot. The other scripts are launched by autostart_screens . sh and their output are redirected to the corresponding log files. To add your own script (e.g. start_my_script . sh ) you can simply add the following line to the autostart_screens . sh : { wait_for_network run_script \"start_qtroutes.sh\" ... ... run_script \"start_my_script.sh\" } & >> ${ LOG_FILE }","title":"How they are executed at startup time?"},{"location":"manual/#how-can-i-access-them","text":"You can access them via terminal of NUC/RPI or via QTrobot web interface for enable/disable them: Web interface on RPI: http : // 192 . 168 . 100 . 1 : 8080 Web interface on NUC: http : // 192 . 168 . 100 . 2 : 8080","title":"How can I access them?"},{"location":"manual/#what-are-the-main-autostart-scripts","text":"As I explained above, there are some important scripts which prepare the robot network, ROS environment and launch the motor controller and other robot interfaces. All of these scripts are running on RPI and are necessary for functionality of QTrobot.","title":"What are the main autostart scripts?"},{"location":"manual/#here-are-the-main-startup-scripts-on-rpi","text":"start_qt_routes . sh : prepares network routing between RPI and NUC for internet sharing and etc. start_roscore . sh : launches roscore start_qtpc . sh : power on NUC via wake-on-lan. start_qt_motor . sh : launch qt_motor node including motor and gesture controllers. start_qt_robot_interface . sh : launch qt_robot_interface node which implements QTrobot emotion (face), audio, speech, behavior and other interfaces. start_qt_webconfing . sh : launch QTrobot web config interface on RPI","title":"Here are the main startup scripts on RPI:"},{"location":"manual/#here-are-the-main-startup-scripts-on-nuc","text":"The NUC pc is most convenient place to develop code and run your own autostart scripts and apps. Most of the default scripts are simply running the QTrobot open source demos and examples and can be safely disabled and/or modified. There is nothing especial running by autostart scripts on NUC except: - start_qt_nuitrack_app . sh : which run Nuitrack skeleton tracking and camera interfaces. - start_qt_webconfing . sh : launch QTrobot web config interface on NUC","title":"Here are the main startup scripts on NUC:"},{"location":"manual/#where-are-the-log-files","text":"All programs/ROS nodes which are run by QTrobot autostart scripts redirect their standard output (info/war/error messages) to their corresponding log file. These log files can be found under ~/ robot / autostart / logs folder.","title":"Where are the log files?"},{"location":"manual/#8-working-directly-on-qtpc","text":"Your robot has a standard Ubuntu-based PC. You can use QTPC in the same way you use a standard desktop. That greatly facilitates and accelerates your development cycle as you have a full-featured desktop directly with your QTrobot. To do that: Connect a USB-C extension (or USB-C to HDMI cable) to the USB-C port of QTrobot. Connect your mouse and keyboard to your USB-C extension. Alternatively you can use weirless mouse/keyboard and connect the dongle directly to USB3 port of QTrobot. Connect the HDMI cable of your display to the USB-C extension or use a USB-C to HDMI cable. You will see Ubuntu desktop running Notice You may need to connect the HDMI cable before powering up the robot to make QTPC aware of any external display.","title":"8. Working directly on QTPC"},{"location":"manual/#9-qtrobot-ros-api","text":"The QTrobot (LuxAI) interface aims to facilitate accessing basic robot functionalities leveraging a set of user-friendly ROS interfaces. Each robot\u2019s functionality can be accessed in blocking and non-blocking mode using ROS publish/subscribe and Service/Client interfaces. Info Visit QTrobot ROS wiki for ROS API Demos & Examples Please check our Demos and Examples to check how to use and implement QTrobot interfaces","title":"9. QTrobot ROS API"},{"location":"manual/#10-calling-qtrobot-apis","text":"You can access each robot's functionality via its publish/subscribe or service/client interfaces. For example, to use the robot 'Speech' functionality from terminal using ROS publisher, you can try: rostopic pub /qt_robot/speech/say std_msgs/String \"data: 'Hello!'\" or by using ROS service call: rosservice call /qt_robot/speech/say \"message: 'Hello!'\" or from a python script: import rospy from std_msgs.msg import String # create a publisher pub = rospy.Publisher ( '/qt_robot/speech/say' , String, queue_size = 10 ) # publish a text message to TTS (non-blocking) pub.publish ( \"Hello! I am QT!\" ) Only use the provided power supply with your robot. \u21a9 In this case you can notice a dim light on the power button. \u21a9 Windows users can use Putty ( www.putty.org ) \u21a9","title":"10. Calling QTrobot APIs"},{"location":"QA/Microphone-Topic/","text":"Can I stream microphone audio? \u00b6 When using audio_common you just need to configure capture.launch file to use proper device, so our mic is hw:1,0. Running audio_capture it will create \"/audio/audio\" topic and on that topic you can listen to the mic, read data etc. There is already tutorial on that page how to set it up. You can also try this respeaker_ros and use some of this topics : - /sound_direction # Result of DoA - /sound_localization # Result of DoA as Pose - /is_speeching # Result of VAD - /audio # Raw audio - /speech_audio # Audio data while speeching","title":"Microphone Topic"},{"location":"QA/Microphone-Topic/#can-i-stream-microphone-audio","text":"When using audio_common you just need to configure capture.launch file to use proper device, so our mic is hw:1,0. Running audio_capture it will create \"/audio/audio\" topic and on that topic you can listen to the mic, read data etc. There is already tutorial on that page how to set it up. You can also try this respeaker_ros and use some of this topics : - /sound_direction # Result of DoA - /sound_localization # Result of DoA as Pose - /is_speeching # Result of VAD - /audio # Raw audio - /speech_audio # Audio data while speeching","title":"Can I stream microphone audio?"},{"location":"QA/QTrobot-Csharp/","text":"Can I use C# to program QTrobot? \u00b6 QTrobot APIs are based on the most popular software framework in robotic, ROS \u2013 a publish/subscribe middleware. ROS by default supports C++ and Python but other languages are covered via different open-source and well-maintained client libraries. Indeed you can use C# to program QTrobot. You can refer to ros-sharp open-source library which leverages websockets for underlying communication and cover all QTrobot APIs. It has good integration with Unity3D too. We have also developed different Android apps using websockets in Jscript and using native Java APIs for our robot.","title":"Can I use C# to program QTrobot?"},{"location":"QA/QTrobot-Csharp/#can-i-use-c-to-program-qtrobot","text":"QTrobot APIs are based on the most popular software framework in robotic, ROS \u2013 a publish/subscribe middleware. ROS by default supports C++ and Python but other languages are covered via different open-source and well-maintained client libraries. Indeed you can use C# to program QTrobot. You can refer to ros-sharp open-source library which leverages websockets for underlying communication and cover all QTrobot APIs. It has good integration with Unity3D too. We have also developed different Android apps using websockets in Jscript and using native Java APIs for our robot.","title":"Can I use C# to program QTrobot?"},{"location":"QA/QTrobot-Mouse&Keyboard/","text":"How to connect Bluetooth mouse/keyboard to QTrobot? \u00b6 This tutorial explain how to pair and connect a Bluetooth mouse/keyboard to QTrobot NUC pc via terminal/ssh. The same procedure works also for RPI. Notice : for RPI you may need to run the bluetoothctl with sudo ! Step 1: ssh to QTPC \u00b6 connect to the QTrobot wifi and ssh into QTPC: $ ssh qtrobot @192.168.100.2 Step 2: launch bluetoothctl \u00b6 qtrobot @QTPC : ~ $ bluetoothctl [ NEW ] Controller F8 : 63 : 3 F : 40 : 61 : B2 QTPC [ default ] Step 3: turn bluetooth power on and register the agent \u00b6 [ bluetooth ] # power on Changing power on succeeded [ bluetooth ] # agent on Agent registered [ bluetooth ] # default - agent Default agent request successful Step 4: scan and pair the bluetooth device \u00b6 to scan the bluettoth devices: [ bluetooth ] # scan on Discovery started [ CHG ] Controller F8 : 63 : 3 F : 40 : 61 : B2 Discovering : yes [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Name : Bluetooth 3.0 Keyboard ... in my case Device 17 : 13 : 00 : 00 : 8 A : 04 Name : Bluetooth 3 . 0 Keyboard is what I am looking for. Now to pair the bluetooth device: [ bluetooth ] # pair 17 : 13 : 00 : 00 : 8 A : 04 Attempting to pair with 17 : 13 : 00 : 00 : 8 A : 04 [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Connected : yes [ agent ] PIN code : xxxx ... [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Paired : yes Pairing successful Some keyboards require to type a PIN code for pairing. Just type the code using your bluetooth keyboard . You do not see anything on the terminal. The code is sent directly by your keyboard while you are typing it. Step 5: trust and connect to the device: \u00b6 trust the device: [ bluetooth ] # trust 17 : 13 : 00 : 00 : 8 A : 04 [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Trusted : yes and finally connect to the bluettoh/keyboard mouse: [ bluetooth ]# connect 17 : 13 : 00 : 00 : 8 A : 04 Attempting to connect to 17 : 13 : 00 : 00 : 8 A : 04 [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Connected : yes Connection successful","title":"How to connect Bluetooth mouse/keyboard to QTrobot?"},{"location":"QA/QTrobot-Mouse&Keyboard/#how-to-connect-bluetooth-mousekeyboard-to-qtrobot","text":"This tutorial explain how to pair and connect a Bluetooth mouse/keyboard to QTrobot NUC pc via terminal/ssh. The same procedure works also for RPI. Notice : for RPI you may need to run the bluetoothctl with sudo !","title":"How to connect Bluetooth mouse/keyboard to QTrobot?"},{"location":"QA/QTrobot-Mouse&Keyboard/#step-1-ssh-to-qtpc","text":"connect to the QTrobot wifi and ssh into QTPC: $ ssh qtrobot @192.168.100.2","title":"Step 1: ssh to QTPC"},{"location":"QA/QTrobot-Mouse&Keyboard/#step-2-launch-bluetoothctl","text":"qtrobot @QTPC : ~ $ bluetoothctl [ NEW ] Controller F8 : 63 : 3 F : 40 : 61 : B2 QTPC [ default ]","title":"Step 2: launch bluetoothctl"},{"location":"QA/QTrobot-Mouse&Keyboard/#step-3-turn-bluetooth-power-on-and-register-the-agent","text":"[ bluetooth ] # power on Changing power on succeeded [ bluetooth ] # agent on Agent registered [ bluetooth ] # default - agent Default agent request successful","title":"Step 3: turn bluetooth power on and register the agent"},{"location":"QA/QTrobot-Mouse&Keyboard/#step-4-scan-and-pair-the-bluetooth-device","text":"to scan the bluettoth devices: [ bluetooth ] # scan on Discovery started [ CHG ] Controller F8 : 63 : 3 F : 40 : 61 : B2 Discovering : yes [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Name : Bluetooth 3.0 Keyboard ... in my case Device 17 : 13 : 00 : 00 : 8 A : 04 Name : Bluetooth 3 . 0 Keyboard is what I am looking for. Now to pair the bluetooth device: [ bluetooth ] # pair 17 : 13 : 00 : 00 : 8 A : 04 Attempting to pair with 17 : 13 : 00 : 00 : 8 A : 04 [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Connected : yes [ agent ] PIN code : xxxx ... [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Paired : yes Pairing successful Some keyboards require to type a PIN code for pairing. Just type the code using your bluetooth keyboard . You do not see anything on the terminal. The code is sent directly by your keyboard while you are typing it.","title":"Step 4: scan and pair the bluetooth device"},{"location":"QA/QTrobot-Mouse&Keyboard/#step-5-trust-and-connect-to-the-device","text":"trust the device: [ bluetooth ] # trust 17 : 13 : 00 : 00 : 8 A : 04 [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Trusted : yes and finally connect to the bluettoh/keyboard mouse: [ bluetooth ]# connect 17 : 13 : 00 : 00 : 8 A : 04 Attempting to connect to 17 : 13 : 00 : 00 : 8 A : 04 [ CHG ] Device 17 : 13 : 00 : 00 : 8 A : 04 Connected : yes Connection successful","title":"Step 5: trust and connect to the device:"},{"location":"QA/QTrobot-SDK/","text":"Is QTrobot SDK open source? \u00b6 QTrobot SDK software is not licensed as ope source. For the time being, we do not have any plan to make them open source. But these are just few software components which implement the required basic ROS interfaces such as motor control, gesture, speech, emotion. The main components (implemented as ROS node) are: qt_motor including motor_controller and gesture_controller plugins implement robot motor joints control and robot gesture record/play functionalities. qt_robot_interface implements speech, audio, basic behavior and setting functionalities. You can always open a new issue/feature request for those interfaces and we do our best to fix/implement them. The rest of the codes including all demo application are open source and you are more than welcome to contribute to those. :)","title":"Is QTrobot SDK open source?"},{"location":"QA/QTrobot-SDK/#is-qtrobot-sdk-open-source","text":"QTrobot SDK software is not licensed as ope source. For the time being, we do not have any plan to make them open source. But these are just few software components which implement the required basic ROS interfaces such as motor control, gesture, speech, emotion. The main components (implemented as ROS node) are: qt_motor including motor_controller and gesture_controller plugins implement robot motor joints control and robot gesture record/play functionalities. qt_robot_interface implements speech, audio, basic behavior and setting functionalities. You can always open a new issue/feature request for those interfaces and we do our best to fix/implement them. The rest of the codes including all demo application are open source and you are more than welcome to contribute to those. :)","title":"Is QTrobot SDK open source?"},{"location":"QA/QTrobot-autostart/","text":"What are autostart scripts? \u00b6 Autostart scripts are simply some bash scripts which are executed at robot startup time. These scripts prepare robot network, setup ROS environment, launch QTrobot motor and other controllers, setup log files and etc. Where are they located? \u00b6 there are two sets of autostart scripts on QTrobot: 1. Autostart scripts on RPI 2. Autostart scripts on NUC Both sets are located under ~/ robot / autostart folder. How they are executed at startup time? \u00b6 The scripts are run by linux Cron job scheduler. In fact, a specific corn job is configured to run autostart_screens . sh script at linux boot. The other scripts are launched by autostart_screens . sh and their output are redirected to the corresponding log files. To add your own script (e.g. start_my_script . sh ) you can simply add the following line to the autostart_screens . sh : { wait_for_network run_script \"start_qtroutes.sh\" ... ... run_script \"start_my_script.sh\" } & >> ${ LOG_FILE } How can I access them? \u00b6 You can access them via terminal of NUC/RPI or via QTrobot web interface for enable/disable them: Web interface on RPI: http : // 192 . 168 . 100 . 1 : 8080 Web interface on NUC: http : // 192 . 168 . 100 . 2 : 8080 What are the main autostart scripts? \u00b6 As I explained above, there are some important scripts which prepare the robot network, ROS environment and launch the motor controller and other robot interfaces. All of these scripts are running on RPI and are necessary for functionality of QTrobot. Here are the main startup scripts on RPI : \u00b6 start_qt_routes . sh : prepares network routing between RPI and NUC for internet sharing and etc. start_roscore . sh : launches roscore start_qtpc . sh : power on NUC via wake-on-lan. start_qt_motor . sh : launch qt_motor node including motor and gesture controllers. start_qt_robot_interface . sh : launch qt_robot_interface node which implements QTrobot emotion (face), audio, speech, behavior and other interfaces. - start_qt_webconfing . sh : launch QTrobot web config interface on RPI Here are the main startup scripts on NUC : \u00b6 The NUC pc is most convenient place to develop code and run your own autostart scripts and apps. Most of the default scripts are simply running the QTrobot open source demos and examples and can be safely disabled and/or modified. There is nothing especial running by autostart scripts on NUC except: - start_qt_nuitrack_app . sh : which run Nuitrack skeleton tracking and camera interfaces. - start_qt_webconfing . sh : launch QTrobot web config interface on NUC Where are the log files? \u00b6 All programs/ROS nodes which are run by QTrobot autostart scripts redirect their standard output (info/war/error messages) to their corresponding log file. These log files can be found under ~/ robot / autostart / logs folder.","title":"What are autostart scripts?"},{"location":"QA/QTrobot-autostart/#what-are-autostart-scripts","text":"Autostart scripts are simply some bash scripts which are executed at robot startup time. These scripts prepare robot network, setup ROS environment, launch QTrobot motor and other controllers, setup log files and etc.","title":"What are autostart scripts?"},{"location":"QA/QTrobot-autostart/#where-are-they-located","text":"there are two sets of autostart scripts on QTrobot: 1. Autostart scripts on RPI 2. Autostart scripts on NUC Both sets are located under ~/ robot / autostart folder.","title":"Where are they located?"},{"location":"QA/QTrobot-autostart/#how-they-are-executed-at-startup-time","text":"The scripts are run by linux Cron job scheduler. In fact, a specific corn job is configured to run autostart_screens . sh script at linux boot. The other scripts are launched by autostart_screens . sh and their output are redirected to the corresponding log files. To add your own script (e.g. start_my_script . sh ) you can simply add the following line to the autostart_screens . sh : { wait_for_network run_script \"start_qtroutes.sh\" ... ... run_script \"start_my_script.sh\" } & >> ${ LOG_FILE }","title":"How they are executed at startup time?"},{"location":"QA/QTrobot-autostart/#how-can-i-access-them","text":"You can access them via terminal of NUC/RPI or via QTrobot web interface for enable/disable them: Web interface on RPI: http : // 192 . 168 . 100 . 1 : 8080 Web interface on NUC: http : // 192 . 168 . 100 . 2 : 8080","title":"How can I access them?"},{"location":"QA/QTrobot-autostart/#what-are-the-main-autostart-scripts","text":"As I explained above, there are some important scripts which prepare the robot network, ROS environment and launch the motor controller and other robot interfaces. All of these scripts are running on RPI and are necessary for functionality of QTrobot.","title":"What are the main autostart scripts?"},{"location":"QA/QTrobot-autostart/#here-are-the-main-startup-scripts-on-rpi","text":"start_qt_routes . sh : prepares network routing between RPI and NUC for internet sharing and etc. start_roscore . sh : launches roscore start_qtpc . sh : power on NUC via wake-on-lan. start_qt_motor . sh : launch qt_motor node including motor and gesture controllers. start_qt_robot_interface . sh : launch qt_robot_interface node which implements QTrobot emotion (face), audio, speech, behavior and other interfaces. - start_qt_webconfing . sh : launch QTrobot web config interface on RPI","title":"Here are the main startup scripts on RPI:"},{"location":"QA/QTrobot-autostart/#here-are-the-main-startup-scripts-on-nuc","text":"The NUC pc is most convenient place to develop code and run your own autostart scripts and apps. Most of the default scripts are simply running the QTrobot open source demos and examples and can be safely disabled and/or modified. There is nothing especial running by autostart scripts on NUC except: - start_qt_nuitrack_app . sh : which run Nuitrack skeleton tracking and camera interfaces. - start_qt_webconfing . sh : launch QTrobot web config interface on NUC","title":"Here are the main startup scripts on NUC:"},{"location":"QA/QTrobot-autostart/#where-are-the-log-files","text":"All programs/ROS nodes which are run by QTrobot autostart scripts redirect their standard output (info/war/error messages) to their corresponding log file. These log files can be found under ~/ robot / autostart / logs folder.","title":"Where are the log files?"},{"location":"QA/QTrobot-backup/","text":"Can I do a backup of QTrobot? \u00b6 QTrobot has two computational components: RPI (Ubuntu 16.04 LTS) Intel NUC PC (Ubuntu 16.04 LTS) Except Nuitrack ROS interface (qt_nuitrack_app) all other qt software are running on RPI. qt_nuitrack_app and other demo apps are all available on our github and you can recover/update it whenever you want. You can backup the config files of RPI for your own recovery. All QTrobot startup scripts, gestures, emotions, etc. are located under ~/robot folder in RPI. In case of emergency recovery, we can send you the SD card image. we can prepare this image somehow you can flash it to a USB stick, plug it into QTrobot (USB) to recover the image.","title":"Can I do a backup of QTrobot?"},{"location":"QA/QTrobot-backup/#can-i-do-a-backup-of-qtrobot","text":"QTrobot has two computational components: RPI (Ubuntu 16.04 LTS) Intel NUC PC (Ubuntu 16.04 LTS) Except Nuitrack ROS interface (qt_nuitrack_app) all other qt software are running on RPI. qt_nuitrack_app and other demo apps are all available on our github and you can recover/update it whenever you want. You can backup the config files of RPI for your own recovery. All QTrobot startup scripts, gestures, emotions, etc. are located under ~/robot folder in RPI. In case of emergency recovery, we can send you the SD card image. we can prepare this image somehow you can flash it to a USB stick, plug it into QTrobot (USB) to recover the image.","title":"Can I do a backup of QTrobot?"},{"location":"QA/QTrobot-joint-limits/","text":"Does the QT Motor interface implement joint limits? \u00b6 The short answer is Yes . QTrobot motor interface sets all joint, torque limits of each motor independently at the startup. Each motor separately does the joint limit check on each position command that it receives. NOTICE : This does not mean that the QTrobot has self collision awareness when moving its joints!","title":"Does the QT Motor interface implement joint limits?"},{"location":"QA/QTrobot-joint-limits/#does-the-qt-motor-interface-implement-joint-limits","text":"The short answer is Yes . QTrobot motor interface sets all joint, torque limits of each motor independently at the startup. Each motor separately does the joint limit check on each position command that it receives. NOTICE : This does not mean that the QTrobot has self collision awareness when moving its joints!","title":"Does the QT Motor interface implement joint limits?"},{"location":"QA/QTrobot-port-forward/","text":"How to disable port forward on QTrobot? \u00b6 Okay. here is the instruction how to disable port forwarding on QTrobot: - access QTrobot RPI via ssh. - navigate to ~/ robot / autostarts and open start_qt_routes . sh for editing (e.g. using vim/nano) - comment this line exec echo \" $QT_USERNAME \" | sudo - kS iptables - t nat - A PREROUTING - p tcp -- dport 80 - j REDIRECT -- to - port 8080 - reboot the robot. NOTICE : Doing this, you need to access QTrobot RPI web-config interface using http : // qtrobot : 8080 or http : // 192 . 168 . 100 . 1 : 8080","title":"How to disable port forward on QTrobot?"},{"location":"QA/QTrobot-port-forward/#how-to-disable-port-forward-on-qtrobot","text":"Okay. here is the instruction how to disable port forwarding on QTrobot: - access QTrobot RPI via ssh. - navigate to ~/ robot / autostarts and open start_qt_routes . sh for editing (e.g. using vim/nano) - comment this line exec echo \" $QT_USERNAME \" | sudo - kS iptables - t nat - A PREROUTING - p tcp -- dport 80 - j REDIRECT -- to - port 8080 - reboot the robot. NOTICE : Doing this, you need to access QTrobot RPI web-config interface using http : // qtrobot : 8080 or http : // 192 . 168 . 100 . 1 : 8080","title":"How to disable port forward on QTrobot?"},{"location":"QA/Wifi-configuration/","text":"How do I setup Wifi on QTrobot? \u00b6 Let me clarify the QTrobot WIFIs and web interface. As it has been explained in different places (#7) QTrobot has an RPI and one NUC PC. RPI WIFI is configured as Hotsopt with unique ssid for each robot (e.g. QT100). the web interface is accessible via http : // 192 . 168 . 100 . 1 : 8080 NUC WIFI is free and you can use it to connect to the internet either via it's Ubuntu desktop, terminal programs via ssh or using NUC web interface via http : // 192 . 168 . 100 . 2 : 8080 The reason that web interface of RPI does not allow you to change its WIFI configuration is intuitive: you cannot access it remotely any more via its hotspot! QTrobot gave you three simple options to connect it to the internet: Using NUC WIFI Using an external WIFI dongle attached to RPI USB port (back of the robot) Using external Ethernet adapter attached to NUC USB-C port (see the attached picture) Notice: It does not matter which option you use to connect the robot to the internet. The internet will be always shared and routed between RPI and NUC! Notice: If you connect external WIFI dongle to the RPI 's USB port, you need to reboot the robot and then it will be shown up in the RPI web interface!","title":"How do I setup Wifi on QTrobot?"},{"location":"QA/Wifi-configuration/#how-do-i-setup-wifi-on-qtrobot","text":"Let me clarify the QTrobot WIFIs and web interface. As it has been explained in different places (#7) QTrobot has an RPI and one NUC PC. RPI WIFI is configured as Hotsopt with unique ssid for each robot (e.g. QT100). the web interface is accessible via http : // 192 . 168 . 100 . 1 : 8080 NUC WIFI is free and you can use it to connect to the internet either via it's Ubuntu desktop, terminal programs via ssh or using NUC web interface via http : // 192 . 168 . 100 . 2 : 8080 The reason that web interface of RPI does not allow you to change its WIFI configuration is intuitive: you cannot access it remotely any more via its hotspot! QTrobot gave you three simple options to connect it to the internet: Using NUC WIFI Using an external WIFI dongle attached to RPI USB port (back of the robot) Using external Ethernet adapter attached to NUC USB-C port (see the attached picture) Notice: It does not matter which option you use to connect the robot to the internet. The internet will be always shared and routed between RPI and NUC! Notice: If you connect external WIFI dongle to the RPI 's USB port, you need to reboot the robot and then it will be shown up in the RPI web interface!","title":"How do I setup Wifi on QTrobot?"},{"location":"demos/qt_emotion_game/","text":"Emotion Game Demo \u00b6 About This is face recognition, age and gender demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository. Video \u00b6 Code \u00b6 Check code here #include <ctime> #include <cstdlib> #include <sstream> #include <std_msgs/Float64MultiArray.h> #include \"qt_emotion_app/qt_emotion_app.h\" #include \"qt_idle_app/suspend.h\" #include <boost/thread/thread.hpp> #include <yaml-cpp/yaml.h> /** * @brief The PlayStateCB class */ class PlayStateCB : public rfsm :: StateCallback { public : PlayStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), inState ( false ), serviceHelper ( srvHelper ), with_audio_files ( false ) { srand ( time ( 0 )); if ( ! nh . getParam ( \"/qt_emotion_app/with_audio_files\" , with_audio_files )) { ROS_WARN_STREAM ( \"Cannot find param /qt_emotion_app/with_audio_files.\" ); } if ( with_audio_files ) { if ( ! nh . getParam ( \"/qt_emotion_app/audio_path\" , audio_path )) { ROS_WARN_STREAM ( \"Cannot find param /qt_emotion_app/audio_path.\" ); } ROS_INFO_STREAM ( \"Using audios from '\" << audio_path << \"'\" ); } else { std :: string speech_message_file ; if ( ! nh . getParam ( \"/qt_emotion_app/speech_message_file\" , speech_message_file )) { ROS_WARN_STREAM ( \"Cannot find param /qt_emotion_app/speech_message_file.\" ); } ROS_INFO_STREAM ( \"Loading speech messages from '\" << speech_message_file << \"'\" ); try { speechMessages = YAML :: LoadFile ( speech_message_file ); } catch ( YAML :: BadFile ) { ROS_ERROR_STREAM ( \"Cannot load speech file '\" << speech_message_file << \"'\" ); ros :: shutdown (); return ; } ROS_INFO_STREAM ( \"Using speech in \" << speechMessages [ \"language\" ]. as < std :: string > ()); } } virtual void entry () { inState = true ; ROS_INFO ( \"Play.entry()\" ); ROS_INFO ( \"Play.entry()\" ); if ( ! with_audio_files ) { // set speech language to English std :: string lang = speechMessages [ \"language\" ]. as < std :: string > (); if ( ! serviceHelper . speechConfig ( lang )) { ROS_WARN_STREAM ( \"Cannot set speech language to \" << lang ); } } ROS_INFO_STREAM ( \"emotion: \" << shown_lables ); if ( shown_lables == \"happy\" ) { talk ( \"emotion_recognition_001\" ); serviceHelper . showEmotionPlayGesture ( \"QT/happy\" , \"QT/happy\" , 0.5 , true ); } else if ( shown_lables == \"sad\" ) { talk ( \"emotion_recognition_002\" ); serviceHelper . showEmotionPlayGesture ( \"QT/sad\" , \"QT/sad\" , 1.0 , true ); talk ( \"emotion_recognition_003\" ); } else if ( shown_lables == \"angry\" ) { talk ( \"emotion_recognition_004\" ); serviceHelper . showEmotionPlayGesture ( \"QT/angry\" , \"QT/angry\" , 0.5 , true ); talk ( \"emotion_recognition_005\" ); serviceHelper . showEmotionPlayGesture ( \"QT/breathing_exercise\" , \"QT/breathing_exercise\" , 0.5 , true ); } else if ( shown_lables == \"disgusted\" ) { talk ( \"emotion_recognition_006\" ); serviceHelper . showEmotion ( \"QT/disgusted\" ); talk ( \"emotion_recognition_007\" ); } else if ( shown_lables == \"surprised\" ) { talk ( \"emotion_recognition_008\" ); serviceHelper . showEmotionPlayGesture ( \"QT/surprise\" , \"QT/surprise\" , 2.0 , true ); talk ( \"emotion_recognition_009\" ); } } virtual void exit () { ROS_INFO ( \"Play.exit()\" ); serviceHelper . homeAll (); ros :: Duration ( 1.0 ). sleep (); inState = false ; if ( ! with_audio_files ) { // set speech language to English if ( ! serviceHelper . speechConfig ( \"default\" )) { ROS_WARN_STREAM ( \"Cannot set back speech language to 'default'\" ); } } } void onObjectsDetected ( const std :: string & lables ) { mutexLables . lock (); shown_lables = lables ; mutexLables . unlock (); if ( ! inState && lables . size ()) rfsm . sendEvent ( \"e_start_game\" ); } void interrupt () { interrupted = true ; } bool talk ( std :: string message ){ bool ret = true ; if ( with_audio_files ) { ret = serviceHelper . talkAudio ( message , audio_path ); if ( ! ret ) ROS_WARN_STREAM ( \"Could not play audio \" << message ); } else { try { ROS_INFO_STREAM ( \"talking '\" << speechMessages [ message ]. as < std :: string > () << \"'\" ); ret = serviceHelper . talkText ( speechMessages [ message ]. as < std :: string > ()); } catch (...) { ret = false ; } if ( ! ret ) ROS_WARN_STREAM ( \"Could not talk message \" << message ); } return ret ; } private : bool inState ; bool interrupted ; std :: string shown_lables ; boost :: mutex mutexLables ; rfsm :: StateMachine & rfsm ; std :: string audio_path ; bool with_audio_files ; YAML :: Node speechMessages ; QTrobotServiceHelper & serviceHelper ; }; /** * @brief The WaitingStateCB class */ class WaitingStateCB : public rfsm :: StateCallback { public : WaitingStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), serviceHelper ( srvHelper ){ idleAppClient = nh . serviceClient < qt_idle_app :: suspend > ( \"/qt_idle_app/suspend\" ); if ( ! idleAppClient . exists ()) { ROS_WARN ( \"Could connect to /qt_idle_app/suspend\" ); } } virtual void entry () { ROS_INFO ( \"Waiting.entry()\" ); // resume qt_idle_app suspendIdleApp ( false ); } virtual void exit () { ROS_INFO ( \"Waiting.exit()\" ); // suspend qt_idle_app suspendIdleApp ( true ); // home all robot serviceHelper . homeAll (); } private : bool suspendIdleApp ( bool flag ) { qt_idle_app :: suspend cmdSuspend ; cmdSuspend . request . flag = flag ; if ( ! idleAppClient . call ( cmdSuspend )) { ROS_WARN ( \"Could not call service qt_idle_app::suspend\" ); return false ; } return cmdSuspend . response . status ; } private : bool inState ; rfsm :: StateMachine & rfsm ; ros :: ServiceClient idleAppClient ; QTrobotServiceHelper serviceHelper ; }; QTEmotionApp :: QTEmotionApp ( ros :: NodeHandle & nh ) : serviceHelper ( nh ) { std :: string fsm_file ; if ( ! nh . getParam ( \"/qt_emotion_app/fsm\" , fsm_file )) { ROS_ERROR_STREAM ( \"Cannot find param /qt_emotion_app/fsm\" ); ros :: shutdown (); } if ( ! rfsm . load ( fsm_file )) { ROS_ERROR_STREAM ( \"Cannot load \" << fsm_file ); ros :: shutdown (); } //serviceSuspend = nh.advertiseService(\"qt_emotion_app/suspend\", &QTEmotionApp::suspendCB, this); subObjects = nh . subscribe ( \"/find_object/objects\" , 10 , & QTEmotionApp :: objectsSubCB , this ); // Waiting callback waitingStateCB = new WaitingStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Waiting\" , * waitingStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } // Play callback playStateCB = new PlayStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Game.Play\" , * playStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } timer = nh . createTimer ( ros :: Duration ( 0.3 ), & QTEmotionApp :: timerCallback , this ); } QTEmotionApp ::~ QTEmotionApp () { timer . stop (); } void QTEmotionApp :: timerCallback ( const ros :: TimerEvent & event ) { mutexRFSM . lock (); rfsm . run (); mutexRFSM . unlock (); } bool QTEmotionApp :: suspend ( bool flag ) { if ( flag ) { //dynamic_cast<LookAroundStateCB*>(lookAroundStateCB)->interrupt(); dynamic_cast < PlayStateCB *> ( playStateCB ) -> interrupt (); rfsm . sendEvent ( \"e_suspend\" ); mutexRFSM . lock (); rfsm . run (); // to ensure being in suspended state mutexRFSM . unlock (); } else { rfsm . sendEvent ( \"e_resume\" ); } return true ; } void QTEmotionApp :: objectsSubCB ( const std_msgs :: Float32MultiArray :: ConstPtr & objects ) { if ( objects -> data . size () <= 0 ) return ; std :: string lables ; for ( size_t i = 0 ; i < objects -> data . size (); i += 12 ) { if ( objects -> data [ i ] == 3 ) lables = \"surprised\" ; else if ( objects -> data [ i ] == 4 ) lables = \"disgusted\" ; else if ( objects -> data [ i ] == 5 ) lables = \"angry\" ; else if ( objects -> data [ i ] == 6 ) lables = \"sad\" ; else if ( objects -> data [ i ] == 7 ) lables = \"happy\" ; } // call related callbacks if ( lables . size ()) { dynamic_cast < PlayStateCB *> ( playStateCB ) -> onObjectsDetected ( lables ); } }","title":"**Emotion Game Demo**"},{"location":"demos/qt_emotion_game/#emotion-game-demo","text":"About This is face recognition, age and gender demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository.","title":"Emotion Game Demo"},{"location":"demos/qt_emotion_game/#video","text":"","title":"Video"},{"location":"demos/qt_emotion_game/#code","text":"Check code here #include <ctime> #include <cstdlib> #include <sstream> #include <std_msgs/Float64MultiArray.h> #include \"qt_emotion_app/qt_emotion_app.h\" #include \"qt_idle_app/suspend.h\" #include <boost/thread/thread.hpp> #include <yaml-cpp/yaml.h> /** * @brief The PlayStateCB class */ class PlayStateCB : public rfsm :: StateCallback { public : PlayStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), inState ( false ), serviceHelper ( srvHelper ), with_audio_files ( false ) { srand ( time ( 0 )); if ( ! nh . getParam ( \"/qt_emotion_app/with_audio_files\" , with_audio_files )) { ROS_WARN_STREAM ( \"Cannot find param /qt_emotion_app/with_audio_files.\" ); } if ( with_audio_files ) { if ( ! nh . getParam ( \"/qt_emotion_app/audio_path\" , audio_path )) { ROS_WARN_STREAM ( \"Cannot find param /qt_emotion_app/audio_path.\" ); } ROS_INFO_STREAM ( \"Using audios from '\" << audio_path << \"'\" ); } else { std :: string speech_message_file ; if ( ! nh . getParam ( \"/qt_emotion_app/speech_message_file\" , speech_message_file )) { ROS_WARN_STREAM ( \"Cannot find param /qt_emotion_app/speech_message_file.\" ); } ROS_INFO_STREAM ( \"Loading speech messages from '\" << speech_message_file << \"'\" ); try { speechMessages = YAML :: LoadFile ( speech_message_file ); } catch ( YAML :: BadFile ) { ROS_ERROR_STREAM ( \"Cannot load speech file '\" << speech_message_file << \"'\" ); ros :: shutdown (); return ; } ROS_INFO_STREAM ( \"Using speech in \" << speechMessages [ \"language\" ]. as < std :: string > ()); } } virtual void entry () { inState = true ; ROS_INFO ( \"Play.entry()\" ); ROS_INFO ( \"Play.entry()\" ); if ( ! with_audio_files ) { // set speech language to English std :: string lang = speechMessages [ \"language\" ]. as < std :: string > (); if ( ! serviceHelper . speechConfig ( lang )) { ROS_WARN_STREAM ( \"Cannot set speech language to \" << lang ); } } ROS_INFO_STREAM ( \"emotion: \" << shown_lables ); if ( shown_lables == \"happy\" ) { talk ( \"emotion_recognition_001\" ); serviceHelper . showEmotionPlayGesture ( \"QT/happy\" , \"QT/happy\" , 0.5 , true ); } else if ( shown_lables == \"sad\" ) { talk ( \"emotion_recognition_002\" ); serviceHelper . showEmotionPlayGesture ( \"QT/sad\" , \"QT/sad\" , 1.0 , true ); talk ( \"emotion_recognition_003\" ); } else if ( shown_lables == \"angry\" ) { talk ( \"emotion_recognition_004\" ); serviceHelper . showEmotionPlayGesture ( \"QT/angry\" , \"QT/angry\" , 0.5 , true ); talk ( \"emotion_recognition_005\" ); serviceHelper . showEmotionPlayGesture ( \"QT/breathing_exercise\" , \"QT/breathing_exercise\" , 0.5 , true ); } else if ( shown_lables == \"disgusted\" ) { talk ( \"emotion_recognition_006\" ); serviceHelper . showEmotion ( \"QT/disgusted\" ); talk ( \"emotion_recognition_007\" ); } else if ( shown_lables == \"surprised\" ) { talk ( \"emotion_recognition_008\" ); serviceHelper . showEmotionPlayGesture ( \"QT/surprise\" , \"QT/surprise\" , 2.0 , true ); talk ( \"emotion_recognition_009\" ); } } virtual void exit () { ROS_INFO ( \"Play.exit()\" ); serviceHelper . homeAll (); ros :: Duration ( 1.0 ). sleep (); inState = false ; if ( ! with_audio_files ) { // set speech language to English if ( ! serviceHelper . speechConfig ( \"default\" )) { ROS_WARN_STREAM ( \"Cannot set back speech language to 'default'\" ); } } } void onObjectsDetected ( const std :: string & lables ) { mutexLables . lock (); shown_lables = lables ; mutexLables . unlock (); if ( ! inState && lables . size ()) rfsm . sendEvent ( \"e_start_game\" ); } void interrupt () { interrupted = true ; } bool talk ( std :: string message ){ bool ret = true ; if ( with_audio_files ) { ret = serviceHelper . talkAudio ( message , audio_path ); if ( ! ret ) ROS_WARN_STREAM ( \"Could not play audio \" << message ); } else { try { ROS_INFO_STREAM ( \"talking '\" << speechMessages [ message ]. as < std :: string > () << \"'\" ); ret = serviceHelper . talkText ( speechMessages [ message ]. as < std :: string > ()); } catch (...) { ret = false ; } if ( ! ret ) ROS_WARN_STREAM ( \"Could not talk message \" << message ); } return ret ; } private : bool inState ; bool interrupted ; std :: string shown_lables ; boost :: mutex mutexLables ; rfsm :: StateMachine & rfsm ; std :: string audio_path ; bool with_audio_files ; YAML :: Node speechMessages ; QTrobotServiceHelper & serviceHelper ; }; /** * @brief The WaitingStateCB class */ class WaitingStateCB : public rfsm :: StateCallback { public : WaitingStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), serviceHelper ( srvHelper ){ idleAppClient = nh . serviceClient < qt_idle_app :: suspend > ( \"/qt_idle_app/suspend\" ); if ( ! idleAppClient . exists ()) { ROS_WARN ( \"Could connect to /qt_idle_app/suspend\" ); } } virtual void entry () { ROS_INFO ( \"Waiting.entry()\" ); // resume qt_idle_app suspendIdleApp ( false ); } virtual void exit () { ROS_INFO ( \"Waiting.exit()\" ); // suspend qt_idle_app suspendIdleApp ( true ); // home all robot serviceHelper . homeAll (); } private : bool suspendIdleApp ( bool flag ) { qt_idle_app :: suspend cmdSuspend ; cmdSuspend . request . flag = flag ; if ( ! idleAppClient . call ( cmdSuspend )) { ROS_WARN ( \"Could not call service qt_idle_app::suspend\" ); return false ; } return cmdSuspend . response . status ; } private : bool inState ; rfsm :: StateMachine & rfsm ; ros :: ServiceClient idleAppClient ; QTrobotServiceHelper serviceHelper ; }; QTEmotionApp :: QTEmotionApp ( ros :: NodeHandle & nh ) : serviceHelper ( nh ) { std :: string fsm_file ; if ( ! nh . getParam ( \"/qt_emotion_app/fsm\" , fsm_file )) { ROS_ERROR_STREAM ( \"Cannot find param /qt_emotion_app/fsm\" ); ros :: shutdown (); } if ( ! rfsm . load ( fsm_file )) { ROS_ERROR_STREAM ( \"Cannot load \" << fsm_file ); ros :: shutdown (); } //serviceSuspend = nh.advertiseService(\"qt_emotion_app/suspend\", &QTEmotionApp::suspendCB, this); subObjects = nh . subscribe ( \"/find_object/objects\" , 10 , & QTEmotionApp :: objectsSubCB , this ); // Waiting callback waitingStateCB = new WaitingStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Waiting\" , * waitingStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } // Play callback playStateCB = new PlayStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Game.Play\" , * playStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } timer = nh . createTimer ( ros :: Duration ( 0.3 ), & QTEmotionApp :: timerCallback , this ); } QTEmotionApp ::~ QTEmotionApp () { timer . stop (); } void QTEmotionApp :: timerCallback ( const ros :: TimerEvent & event ) { mutexRFSM . lock (); rfsm . run (); mutexRFSM . unlock (); } bool QTEmotionApp :: suspend ( bool flag ) { if ( flag ) { //dynamic_cast<LookAroundStateCB*>(lookAroundStateCB)->interrupt(); dynamic_cast < PlayStateCB *> ( playStateCB ) -> interrupt (); rfsm . sendEvent ( \"e_suspend\" ); mutexRFSM . lock (); rfsm . run (); // to ensure being in suspended state mutexRFSM . unlock (); } else { rfsm . sendEvent ( \"e_resume\" ); } return true ; } void QTEmotionApp :: objectsSubCB ( const std_msgs :: Float32MultiArray :: ConstPtr & objects ) { if ( objects -> data . size () <= 0 ) return ; std :: string lables ; for ( size_t i = 0 ; i < objects -> data . size (); i += 12 ) { if ( objects -> data [ i ] == 3 ) lables = \"surprised\" ; else if ( objects -> data [ i ] == 4 ) lables = \"disgusted\" ; else if ( objects -> data [ i ] == 5 ) lables = \"angry\" ; else if ( objects -> data [ i ] == 6 ) lables = \"sad\" ; else if ( objects -> data [ i ] == 7 ) lables = \"happy\" ; } // call related callbacks if ( lables . size ()) { dynamic_cast < PlayStateCB *> ( playStateCB ) -> onObjectsDetected ( lables ); } }","title":"Code"},{"location":"demos/qt_face_recognition/","text":"Face recognition, Age & Gender \u00b6 About This is face recognition, age and gender demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository. Video \u00b6 Code \u00b6 Check code here #!/usr/bin/env python from __future__ import print_function # import sys import rospy import cv2 import threading from sensor_msgs.msg import Image from cv_bridge import CvBridge , CvBridgeError from qt_nuitrack_app.msg import Faces , FaceInfo class image_converter : faces = None faces_time = None def __init__ ( self ): self . lock = threading . Lock () self . bridge = CvBridge () self . image_pub = rospy . Publisher ( \"/face_recognition/out\" , Image , queue_size = 1 ) self . image_sub = rospy . Subscriber ( \"/camera/color/image_raw\" , Image , self . image_callback ) self . face_sub = rospy . Subscriber ( \"/qt_nuitrack_app/faces\" , Faces , self . face_callback ) def face_callback ( self , data ): # print(\"face_callback\") self . lock . acquire () self . faces = data . faces self . faces_time = rospy . Time . now () self . lock . release () def image_callback ( self , data ): try : cv_image = self . bridge . imgmsg_to_cv2 ( data , \"bgr8\" ) except CvBridgeError as e : print ( e ) ( rows , cols , channels ) = cv_image . shape self . lock . acquire () new_faces = self . faces new_faces_time = self . faces_time self . lock . release () if new_faces and ( rospy . Time . now () - new_faces_time ) < rospy . Duration ( 5.0 ): for face in new_faces : rect = face . rectangle cv2 . rectangle ( cv_image , ( int ( rect [ 0 ] * cols ), int ( rect [ 1 ] * rows )), ( int ( rect [ 0 ] * cols + rect [ 2 ] * cols ), int ( rect [ 1 ] * rows + rect [ 3 ] * rows )), ( 0 , 255 , 0 ), 2 ) x = int ( rect [ 0 ] * cols ) y = int ( rect [ 1 ] * rows ) w = int ( rect [ 2 ] * cols ) h = int ( rect [ 3 ] * rows ) #cv2.putText(cv_image, \"Gender:\", (x, y+h+10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), lineType=cv2.LINE_AA) cv2 . putText ( cv_image , \"Gender: %s \" % face . gender , ( x , y + h + 20 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . putText ( cv_image , \"Age: %d \" % face . age_years , ( x , y + h + 40 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) # Neutral cv2 . putText ( cv_image , \"Neutral:\" , ( x , y + h + 60 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 50 ), ( x + 80 + int ( face . emotion_neutral * 100 ), y + h + 10 + 50 ), ( 0 , 255 , 0 ), cv2 . FILLED ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 50 ), ( x + 80 + 100 , y + h + 10 + 50 ), ( 255 , 255 , 255 ), 1 ) # Angry cv2 . putText ( cv_image , \"Angry:\" , ( x , y + h + 80 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 70 ), ( x + 80 + int ( face . emotion_angry * 100 ), y + h + 10 + 70 ), ( 0 , 255 , 0 ), cv2 . FILLED ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 70 ), ( x + 80 + 100 , y + h + 10 + 70 ), ( 255 , 255 , 255 ), 1 ) # Happy cv2 . putText ( cv_image , \"Happy:\" , ( x , y + h + 100 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 90 ), ( x + 80 + int ( face . emotion_happy * 100 ), y + h + 10 + 90 ), ( 0 , 255 , 0 ), cv2 . FILLED ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 90 ), ( x + 80 + 100 , y + h + 10 + 90 ), ( 255 , 255 , 255 ), 1 ) cv2 . putText ( cv_image , \"Surprise:\" , ( x , y + h + 120 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 110 ), ( x + 80 + int ( face . emotion_surprise * 100 ), y + h + 10 + 110 ), ( 0 , 255 , 0 ), cv2 . FILLED ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 110 ), ( x + 80 + 100 , y + h + 10 + 110 ), ( 255 , 255 , 255 ), 1 ) try : self . image_pub . publish ( self . bridge . cv2_to_imgmsg ( cv_image , \"bgr8\" )) except CvBridgeError as e : print ( e ) if __name__ == '__main__' : rospy . init_node ( 'qt_face_recognition' , anonymous = True ) ic = image_converter () try : rospy . spin () except KeyboardInterrupt : print ( \"Shutting down\" )","title":"**Face recognition, Age & Gender**"},{"location":"demos/qt_face_recognition/#face-recognition-age-gender","text":"About This is face recognition, age and gender demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository.","title":"Face recognition, Age &amp; Gender"},{"location":"demos/qt_face_recognition/#video","text":"","title":"Video"},{"location":"demos/qt_face_recognition/#code","text":"Check code here #!/usr/bin/env python from __future__ import print_function # import sys import rospy import cv2 import threading from sensor_msgs.msg import Image from cv_bridge import CvBridge , CvBridgeError from qt_nuitrack_app.msg import Faces , FaceInfo class image_converter : faces = None faces_time = None def __init__ ( self ): self . lock = threading . Lock () self . bridge = CvBridge () self . image_pub = rospy . Publisher ( \"/face_recognition/out\" , Image , queue_size = 1 ) self . image_sub = rospy . Subscriber ( \"/camera/color/image_raw\" , Image , self . image_callback ) self . face_sub = rospy . Subscriber ( \"/qt_nuitrack_app/faces\" , Faces , self . face_callback ) def face_callback ( self , data ): # print(\"face_callback\") self . lock . acquire () self . faces = data . faces self . faces_time = rospy . Time . now () self . lock . release () def image_callback ( self , data ): try : cv_image = self . bridge . imgmsg_to_cv2 ( data , \"bgr8\" ) except CvBridgeError as e : print ( e ) ( rows , cols , channels ) = cv_image . shape self . lock . acquire () new_faces = self . faces new_faces_time = self . faces_time self . lock . release () if new_faces and ( rospy . Time . now () - new_faces_time ) < rospy . Duration ( 5.0 ): for face in new_faces : rect = face . rectangle cv2 . rectangle ( cv_image , ( int ( rect [ 0 ] * cols ), int ( rect [ 1 ] * rows )), ( int ( rect [ 0 ] * cols + rect [ 2 ] * cols ), int ( rect [ 1 ] * rows + rect [ 3 ] * rows )), ( 0 , 255 , 0 ), 2 ) x = int ( rect [ 0 ] * cols ) y = int ( rect [ 1 ] * rows ) w = int ( rect [ 2 ] * cols ) h = int ( rect [ 3 ] * rows ) #cv2.putText(cv_image, \"Gender:\", (x, y+h+10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), lineType=cv2.LINE_AA) cv2 . putText ( cv_image , \"Gender: %s \" % face . gender , ( x , y + h + 20 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . putText ( cv_image , \"Age: %d \" % face . age_years , ( x , y + h + 40 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) # Neutral cv2 . putText ( cv_image , \"Neutral:\" , ( x , y + h + 60 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 50 ), ( x + 80 + int ( face . emotion_neutral * 100 ), y + h + 10 + 50 ), ( 0 , 255 , 0 ), cv2 . FILLED ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 50 ), ( x + 80 + 100 , y + h + 10 + 50 ), ( 255 , 255 , 255 ), 1 ) # Angry cv2 . putText ( cv_image , \"Angry:\" , ( x , y + h + 80 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 70 ), ( x + 80 + int ( face . emotion_angry * 100 ), y + h + 10 + 70 ), ( 0 , 255 , 0 ), cv2 . FILLED ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 70 ), ( x + 80 + 100 , y + h + 10 + 70 ), ( 255 , 255 , 255 ), 1 ) # Happy cv2 . putText ( cv_image , \"Happy:\" , ( x , y + h + 100 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 90 ), ( x + 80 + int ( face . emotion_happy * 100 ), y + h + 10 + 90 ), ( 0 , 255 , 0 ), cv2 . FILLED ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 90 ), ( x + 80 + 100 , y + h + 10 + 90 ), ( 255 , 255 , 255 ), 1 ) cv2 . putText ( cv_image , \"Surprise:\" , ( x , y + h + 120 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.5 , ( 0 , 255 , 0 ), 1 , lineType = cv2 . LINE_AA ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 110 ), ( x + 80 + int ( face . emotion_surprise * 100 ), y + h + 10 + 110 ), ( 0 , 255 , 0 ), cv2 . FILLED ) cv2 . rectangle ( cv_image , ( x + 80 , y + h + 110 ), ( x + 80 + 100 , y + h + 10 + 110 ), ( 255 , 255 , 255 ), 1 ) try : self . image_pub . publish ( self . bridge . cv2_to_imgmsg ( cv_image , \"bgr8\" )) except CvBridgeError as e : print ( e ) if __name__ == '__main__' : rospy . init_node ( 'qt_face_recognition' , anonymous = True ) ic = image_converter () try : rospy . spin () except KeyboardInterrupt : print ( \"Shutting down\" )","title":"Code"},{"location":"demos/qt_gesture_recognition/","text":"Gesture Game Demo \u00b6 About This is gesture game demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository. Video \u00b6 Code \u00b6 Check code here #include <ctime> #include <cstdlib> #include <sstream> #include <std_msgs/Float64MultiArray.h> #include <boost/thread/thread.hpp> #include <yaml-cpp/yaml.h> #include \"qt_gesturegame_app/qt_gesturegame_app.h\" #include \"qt_idle_app/suspend.h\" #define ROBOT_MEMORY_INCREMENT 1 static char GestureTable [] = { 'U' , 'R' , 'L' }; static int current_user_id = - 1 ; /** * @brief The PlayStateCB class */ class PlayStateCB : public rfsm :: StateCallback { public : PlayStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), serviceHelper ( srvHelper ){ srand ( time ( 0 )); if ( ! nh . getParam ( \"/qt_gesturegame_app/with_audio_files\" , with_audio_files )) { ROS_WARN_STREAM ( \"Cannot find param /qt_gesturegame_app/with_audio_files.\" ); } if ( with_audio_files ) { if ( ! nh . getParam ( \"/qt_gesturegame_app/audio_path\" , audio_path )) { ROS_WARN_STREAM ( \"Cannot find param /qt_gesturegame_app/audio_path.\" ); } ROS_INFO_STREAM ( \"Using audios from '\" << audio_path << \"'\" ); } else { std :: string speech_message_file ; if ( ! nh . getParam ( \"/qt_gesturegame_app/speech_message_file\" , speech_message_file )) { ROS_WARN_STREAM ( \"Cannot find param /qt_gesturegame_app/speech_message_file.\" ); } ROS_INFO_STREAM ( \"Loading speech messages from '\" << speech_message_file << \"'\" ); try { speechMessages = YAML :: LoadFile ( speech_message_file ); } catch ( YAML :: BadFile ) { ROS_ERROR_STREAM ( \"Cannot load speech file '\" << speech_message_file << \"'\" ); ros :: shutdown (); return ; } ROS_INFO_STREAM ( \"Using speech in \" << speechMessages [ \"language\" ]. as < std :: string > ()); } } virtual void entry () { ROS_INFO ( \"Play.entry()\" ); if ( ! with_audio_files ) { // set speech language std :: string lang = speechMessages [ \"language\" ]. as < std :: string > (); if ( ! serviceHelper . speechConfig ( lang )) { ROS_WARN_STREAM ( \"Cannot set speech language to \" << lang ); } } prevLevel = - 1 ; if ( with_audio_files ) serviceHelper . talkAudioPlayGesture ( \"memory_game_001\" , \"QT/challenge\" , 2.0 , true , audio_path ); else serviceHelper . talkTextPlayGesture ( speechMessages [ \"memory_game_001\" ]. as < std :: string > (), \"QT/challenge\" , 2.0 , true ); ros :: Duration ( 1.0 ). sleep (); // doo interrupted = false ; robotMemory . clear (); playerMemory . clear (); start_time = ros :: Time :: now (); while ( ! ros :: isShuttingDown () && ! interrupted ) { // motivate player if ( robotMemory . size () == 4 ) talk ( \"memory_game_002\" ); // update robot memory for ( size_t rep = 0 ; rep < ROBOT_MEMORY_INCREMENT ; rep ++ ) { robotMemory += GestureTable [( rand () % 3 )]; } ROS_INFO_STREAM ( \"Show \" << robotMemory ); if ( robotMemory . size () == ROBOT_MEMORY_INCREMENT ) talk ( \"memory_game_003\" ); else talk ( \"memory_game_004\" ); for ( size_t i = 0 ; i < robotMemory . size (); i ++ ) { if ( robotMemory [ i ] == 'U' ) serviceHelper . playGesture ( \"QT/up_right\" , 1.2 ); else if ( robotMemory [ i ] == 'R' ) serviceHelper . playGesture ( \"QT/swipe_right\" , 1.2 ); else if ( robotMemory [ i ] == 'L' ) serviceHelper . playGesture ( \"QT/swipe_left\" , 1.2 ); else ROS_WARN_STREAM ( \"Unknown gesture \" << robotMemory [ i ]); } //ros::Duration(2.0).sleep(); // clear player memory playerMemory . clear (); ROS_INFO_STREAM ( \"Your turn...\" ); talk ( \"memory_game_005\" ); // loop until player take enough moves size_t robotMemorySize = robotMemory . size (); while (( playerMemory . size () <= robotMemorySize ) && ! ros :: isShuttingDown () && ! interrupted ) { mutexLables . lock (); shown_gesture . clear (); mutexLables . unlock (); // wait until user show a lable (read from user shwon image) ROS_INFO ( \"Reading...\" ); ros :: Time start_read_time = ros :: Time :: now (); bool read = false ; while ( ! read && ! ros :: isShuttingDown () && ! interrupted ) { if (( ros :: Time :: now () - start_read_time ). toSec () > 10.0 ) { ROS_INFO ( \"timeout! Okay! it seems you do not want to play anymore!\" ); if ( with_audio_files ) serviceHelper . talkAudioPlayGesture ( \"memory_game_006\" , \"QT/angry\" , 1.0 , true , audio_path ); else serviceHelper . talkTextPlayGesture ( speechMessages [ \"memory_game_006\" ]. as < std :: string > (), \"QT/angry\" , 1.0 , true ); interrupted = true ; break ; } mutexLables . lock (); if ( shown_gesture . size ()) { ROS_INFO_STREAM ( \"shown \" << shown_gesture ); read = true ; if ( shown_gesture == \"SWIPE UP\" ) { playerMemory += \"U\" ; talk ( \"memory_game_015\" ); } else if ( shown_gesture == \"SWIPE RIGHT\" ) { playerMemory += \"R\" ; talk ( \"memory_game_007\" ); } else if ( shown_gesture == \"SWIPE LEFT\" ) { playerMemory += \"L\" ; talk ( \"memory_game_008\" ); } else { read = false ; } } mutexLables . unlock (); } //ros::Duration(0.5).sleep(); if ( playerMemory . size () <= robotMemorySize ) { // ignore the last one if ( playerMemory . size () && ( playerMemory != robotMemory . substr ( 0 , playerMemory . size ()))) break ; } else // add the last gesture to robot memory robotMemory . push_back ( playerMemory . back ()); } // end of moves loop ROS_INFO_STREAM ( \"Player memory: \" << playerMemory ); ROS_INFO_STREAM ( \"Robot memory : \" << robotMemory ); if (( playerMemory != robotMemory ) && ! interrupted ) { //ros::Duration(1.0).sleep(); talk ( \"memory_game_009\" ); serviceHelper . showEmotion ( \"QT/shy\" ); break ; } } // end of main loop } virtual void exit () { int level = robotMemory . size () / 2 ; ros :: Duration game_duration = ros :: Time :: now () - start_time ; if ( robotMemory . size () < 5 ) { ROS_INFO ( \"It was a short game!\" ); talk ( \"memory_game_010\" ); } else if ( robotMemory . size () >= 5 ) { ROS_INFO ( \"Well Done! It was a good game!\" ); talk ( \"memory_game_011\" ); } else if ( robotMemory . size () >= 8 ) { talk ( \"memory_game_012\" ); } if ( prevLevel != - 1 ) { if ( level < prevLevel ) talk ( \"memory_game_013\" ); else talk ( \"memory_game_014\" ); } serviceHelper . showEmotionPlayGesture ( \"QT/kiss\" , \"QT/kiss\" , 2.0 , true ); if ( ! with_audio_files ) { // set speech language to default if ( ! serviceHelper . speechConfig ( \"default\" )) { ROS_WARN_STREAM ( \"Cannot set speech language to 'default'\" ); } } } void onGestureDetected ( const std :: string & gesture , int id ) { if (( gesture == \"SWIPE DOWN\" ) || ( gesture == \"WAVING\" )) return ; if ( id != current_user_id ) return ; mutexLables . lock (); shown_gesture = gesture ; mutexLables . unlock (); } void interrupt () { interrupted = true ; } bool talk ( std :: string message ){ bool ret = true ; if ( with_audio_files ) { ret = serviceHelper . talkAudio ( message , audio_path ); if ( ! ret ) ROS_WARN_STREAM ( \"Could not play audio \" << message ); } else { try { ROS_INFO_STREAM ( \"talking '\" << speechMessages [ message ]. as < std :: string > () << \"'\" ); ret = serviceHelper . talkText ( speechMessages [ message ]. as < std :: string > ()); } catch (...) { ret = false ; } if ( ! ret ) ROS_WARN_STREAM ( \"Could not talk message \" << message ); } return ret ; } private : bool interrupted ; int prevLevel ; ros :: Time start_time ; std :: string shown_gesture ; std :: string robotMemory ; std :: string playerMemory ; boost :: mutex mutexLables ; rfsm :: StateMachine & rfsm ; std :: string audio_path ; bool with_audio_files ; YAML :: Node speechMessages ; QTrobotServiceHelper & serviceHelper ; }; /** * @brief The WaitingStateCB class */ class WaitingStateCB : public rfsm :: StateCallback { public : WaitingStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), inState ( false ), serviceHelper ( srvHelper ){ idleAppClient = nh . serviceClient < qt_idle_app :: suspend > ( \"/qt_idle_app/suspend\" ); if ( ! idleAppClient . exists ()) { ROS_WARN ( \"Could connect to /qt_idle_app/suspend\" ); } } virtual void entry () { ROS_INFO ( \"Waiting.entry()\" ); // resume qt_idle_app suspendIdleApp ( false ); inState = true ; } virtual void exit () { ROS_INFO ( \"Waiting.exit()\" ); // suspend qt_idle_app suspendIdleApp ( true ); // home all robot serviceHelper . homeAll (); inState = false ; } void onGestureDetected ( const std :: string & gesture , int id ) { // TODO check if both Q & T are shown if ( inState && gesture == \"SWIPE UP\" ) { /* static int gesture_count = 0; static ros::Time prev_gesture_time = ros::Time::now(); if((ros::Time::now()-prev_gesture_time).toSec() > 3.0) { gesture_count = 0; prev_gesture_time = ros::Time::now(); return; } if(gesture_count >= 1) { gesture_count = 0; current_user_id = id; rfsm.sendEvent(\"e_start_game\"); return; } if(gesture_count == 0) { gesture_count++; prev_gesture_time = ros::Time::now(); return; } gesture_count++; */ current_user_id = id ; rfsm . sendEvent ( \"e_start_game\" ); } } private : bool suspendIdleApp ( bool flag ) { qt_idle_app :: suspend cmdSuspend ; cmdSuspend . request . flag = flag ; if ( ! idleAppClient . call ( cmdSuspend )) { ROS_WARN ( \"Could not call service qt_idle_app::suspend\" ); return false ; } return cmdSuspend . response . status ; } private : bool inState ; rfsm :: StateMachine & rfsm ; ros :: ServiceClient idleAppClient ; QTrobotServiceHelper & serviceHelper ; }; QTGestureGameApp :: QTGestureGameApp ( ros :: NodeHandle & nh ) : serviceHelper ( nh ) { std :: string fsm_file ; if ( ! nh . getParam ( \"/qt_gesturegame_app/fsm\" , fsm_file )) { ROS_ERROR_STREAM ( \"Cannot find param /qt_gesturegame_app/fsm\" ); ros :: shutdown (); } if ( ! rfsm . load ( fsm_file )) { ROS_ERROR_STREAM ( \"Cannot load \" << fsm_file ); ros :: shutdown (); } //serviceSuspend = nh.advertiseService(\"qt_gesturegame_app/suspend\", &QTGestureGameApp::suspendCB, this); subGestures = nh . subscribe ( \"/qt_nuitrack_app/gestures\" , 10 , & QTGestureGameApp :: gestureSubCB , this ); // set speech language to English if ( ! serviceHelper . speechConfig ( \"en-US\" )) { ROS_ERROR_STREAM ( \"Cannot set speech language to 'en-US'\" ); ros :: shutdown (); } // Waiting callback waitingStateCB = new WaitingStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Waiting\" , * waitingStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } // Play callback playStateCB = new PlayStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Game.Play\" , * playStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } fsmTimer = nh . createTimer ( ros :: Duration ( 0.3 ), & QTGestureGameApp :: fsmTimerCallback , this ); } QTGestureGameApp ::~ QTGestureGameApp () { fsmTimer . stop (); } void QTGestureGameApp :: fsmTimerCallback ( const ros :: TimerEvent & event ) { mutexRFSM . lock (); rfsm . run (); mutexRFSM . unlock (); } /* void QTGestureGameApp::onNewGestures(const tdv::nuitrack::GestureData::Ptr gesture_data) { //ROS_INFO_STREAM(\"onNewGestures...\"); const std::vector<tdv::nuitrack::Gesture> gestures = gesture_data->getGestures(); for( const tdv::nuitrack::Gesture& gesture : gestures ){ ROS_INFO_STREAM(gesture.userId << \": \" << type2string(gesture.type)); if(gesture.type == GestureType::GESTURE_SWIPE_UP || gesture.type == GestureType::GESTURE_SWIPE_RIGHT || gesture.type == GestureType::GESTURE_SWIPE_LEFT) { dynamic_cast<WaitingStateCB*>(waitingStateCB)->onGestureDetected(type2string(gesture.type)); dynamic_cast<PlayStateCB*>(playStateCB)->onGestureDetected(type2string(gesture.type)); return; } } } */ bool QTGestureGameApp :: suspend ( bool flag ) { if ( flag ) { //dynamic_cast<LookAroundStateCB*>(lookAroundStateCB)->interrupt(); dynamic_cast < PlayStateCB *> ( playStateCB ) -> interrupt (); rfsm . sendEvent ( \"e_suspend\" ); mutexRFSM . lock (); rfsm . run (); // to ensure being in suspended state mutexRFSM . unlock (); } else { rfsm . sendEvent ( \"e_resume\" ); } return true ; } void QTGestureGameApp :: gestureSubCB ( const qt_nuitrack_app :: Gestures :: ConstPtr & gestures ) { for ( int i = 0 ; i < gestures -> gestures . size (); i ++ ) { ROS_INFO_STREAM ( \"gesture: \" << gestures -> gestures [ i ]. name << \", id: \" << gestures -> gestures [ i ]. id ); dynamic_cast < WaitingStateCB *> ( waitingStateCB ) -> onGestureDetected ( gestures -> gestures [ i ]. name , gestures -> gestures [ i ]. id ); dynamic_cast < PlayStateCB *> ( playStateCB ) -> onGestureDetected ( gestures -> gestures [ i ]. name , gestures -> gestures [ i ]. id ); } } /* void QTGestureGameApp::objectsSubCB(const std_msgs::Float32MultiArray::ConstPtr& objects) { if(objects->data.size() <= 0 ) return; std::string lables; for(size_t i=0; i<objects->data.size(); i+=12) { if(objects->data[i] == 1) lables.push_back('Q'); else if(objects->data[i] == 2) lables.push_back('T'); } // call related callbacks if(lables.size()) { dynamic_cast<WaitingStateCB*>(waitingStateCB)->onObjectsDetected(lables); dynamic_cast<PlayStateCB*>(playStateCB)->onObjectsDetected(lables); } } */","title":"**Gesture Game Demo**"},{"location":"demos/qt_gesture_recognition/#gesture-game-demo","text":"About This is gesture game demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository.","title":"Gesture Game Demo"},{"location":"demos/qt_gesture_recognition/#video","text":"","title":"Video"},{"location":"demos/qt_gesture_recognition/#code","text":"Check code here #include <ctime> #include <cstdlib> #include <sstream> #include <std_msgs/Float64MultiArray.h> #include <boost/thread/thread.hpp> #include <yaml-cpp/yaml.h> #include \"qt_gesturegame_app/qt_gesturegame_app.h\" #include \"qt_idle_app/suspend.h\" #define ROBOT_MEMORY_INCREMENT 1 static char GestureTable [] = { 'U' , 'R' , 'L' }; static int current_user_id = - 1 ; /** * @brief The PlayStateCB class */ class PlayStateCB : public rfsm :: StateCallback { public : PlayStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), serviceHelper ( srvHelper ){ srand ( time ( 0 )); if ( ! nh . getParam ( \"/qt_gesturegame_app/with_audio_files\" , with_audio_files )) { ROS_WARN_STREAM ( \"Cannot find param /qt_gesturegame_app/with_audio_files.\" ); } if ( with_audio_files ) { if ( ! nh . getParam ( \"/qt_gesturegame_app/audio_path\" , audio_path )) { ROS_WARN_STREAM ( \"Cannot find param /qt_gesturegame_app/audio_path.\" ); } ROS_INFO_STREAM ( \"Using audios from '\" << audio_path << \"'\" ); } else { std :: string speech_message_file ; if ( ! nh . getParam ( \"/qt_gesturegame_app/speech_message_file\" , speech_message_file )) { ROS_WARN_STREAM ( \"Cannot find param /qt_gesturegame_app/speech_message_file.\" ); } ROS_INFO_STREAM ( \"Loading speech messages from '\" << speech_message_file << \"'\" ); try { speechMessages = YAML :: LoadFile ( speech_message_file ); } catch ( YAML :: BadFile ) { ROS_ERROR_STREAM ( \"Cannot load speech file '\" << speech_message_file << \"'\" ); ros :: shutdown (); return ; } ROS_INFO_STREAM ( \"Using speech in \" << speechMessages [ \"language\" ]. as < std :: string > ()); } } virtual void entry () { ROS_INFO ( \"Play.entry()\" ); if ( ! with_audio_files ) { // set speech language std :: string lang = speechMessages [ \"language\" ]. as < std :: string > (); if ( ! serviceHelper . speechConfig ( lang )) { ROS_WARN_STREAM ( \"Cannot set speech language to \" << lang ); } } prevLevel = - 1 ; if ( with_audio_files ) serviceHelper . talkAudioPlayGesture ( \"memory_game_001\" , \"QT/challenge\" , 2.0 , true , audio_path ); else serviceHelper . talkTextPlayGesture ( speechMessages [ \"memory_game_001\" ]. as < std :: string > (), \"QT/challenge\" , 2.0 , true ); ros :: Duration ( 1.0 ). sleep (); // doo interrupted = false ; robotMemory . clear (); playerMemory . clear (); start_time = ros :: Time :: now (); while ( ! ros :: isShuttingDown () && ! interrupted ) { // motivate player if ( robotMemory . size () == 4 ) talk ( \"memory_game_002\" ); // update robot memory for ( size_t rep = 0 ; rep < ROBOT_MEMORY_INCREMENT ; rep ++ ) { robotMemory += GestureTable [( rand () % 3 )]; } ROS_INFO_STREAM ( \"Show \" << robotMemory ); if ( robotMemory . size () == ROBOT_MEMORY_INCREMENT ) talk ( \"memory_game_003\" ); else talk ( \"memory_game_004\" ); for ( size_t i = 0 ; i < robotMemory . size (); i ++ ) { if ( robotMemory [ i ] == 'U' ) serviceHelper . playGesture ( \"QT/up_right\" , 1.2 ); else if ( robotMemory [ i ] == 'R' ) serviceHelper . playGesture ( \"QT/swipe_right\" , 1.2 ); else if ( robotMemory [ i ] == 'L' ) serviceHelper . playGesture ( \"QT/swipe_left\" , 1.2 ); else ROS_WARN_STREAM ( \"Unknown gesture \" << robotMemory [ i ]); } //ros::Duration(2.0).sleep(); // clear player memory playerMemory . clear (); ROS_INFO_STREAM ( \"Your turn...\" ); talk ( \"memory_game_005\" ); // loop until player take enough moves size_t robotMemorySize = robotMemory . size (); while (( playerMemory . size () <= robotMemorySize ) && ! ros :: isShuttingDown () && ! interrupted ) { mutexLables . lock (); shown_gesture . clear (); mutexLables . unlock (); // wait until user show a lable (read from user shwon image) ROS_INFO ( \"Reading...\" ); ros :: Time start_read_time = ros :: Time :: now (); bool read = false ; while ( ! read && ! ros :: isShuttingDown () && ! interrupted ) { if (( ros :: Time :: now () - start_read_time ). toSec () > 10.0 ) { ROS_INFO ( \"timeout! Okay! it seems you do not want to play anymore!\" ); if ( with_audio_files ) serviceHelper . talkAudioPlayGesture ( \"memory_game_006\" , \"QT/angry\" , 1.0 , true , audio_path ); else serviceHelper . talkTextPlayGesture ( speechMessages [ \"memory_game_006\" ]. as < std :: string > (), \"QT/angry\" , 1.0 , true ); interrupted = true ; break ; } mutexLables . lock (); if ( shown_gesture . size ()) { ROS_INFO_STREAM ( \"shown \" << shown_gesture ); read = true ; if ( shown_gesture == \"SWIPE UP\" ) { playerMemory += \"U\" ; talk ( \"memory_game_015\" ); } else if ( shown_gesture == \"SWIPE RIGHT\" ) { playerMemory += \"R\" ; talk ( \"memory_game_007\" ); } else if ( shown_gesture == \"SWIPE LEFT\" ) { playerMemory += \"L\" ; talk ( \"memory_game_008\" ); } else { read = false ; } } mutexLables . unlock (); } //ros::Duration(0.5).sleep(); if ( playerMemory . size () <= robotMemorySize ) { // ignore the last one if ( playerMemory . size () && ( playerMemory != robotMemory . substr ( 0 , playerMemory . size ()))) break ; } else // add the last gesture to robot memory robotMemory . push_back ( playerMemory . back ()); } // end of moves loop ROS_INFO_STREAM ( \"Player memory: \" << playerMemory ); ROS_INFO_STREAM ( \"Robot memory : \" << robotMemory ); if (( playerMemory != robotMemory ) && ! interrupted ) { //ros::Duration(1.0).sleep(); talk ( \"memory_game_009\" ); serviceHelper . showEmotion ( \"QT/shy\" ); break ; } } // end of main loop } virtual void exit () { int level = robotMemory . size () / 2 ; ros :: Duration game_duration = ros :: Time :: now () - start_time ; if ( robotMemory . size () < 5 ) { ROS_INFO ( \"It was a short game!\" ); talk ( \"memory_game_010\" ); } else if ( robotMemory . size () >= 5 ) { ROS_INFO ( \"Well Done! It was a good game!\" ); talk ( \"memory_game_011\" ); } else if ( robotMemory . size () >= 8 ) { talk ( \"memory_game_012\" ); } if ( prevLevel != - 1 ) { if ( level < prevLevel ) talk ( \"memory_game_013\" ); else talk ( \"memory_game_014\" ); } serviceHelper . showEmotionPlayGesture ( \"QT/kiss\" , \"QT/kiss\" , 2.0 , true ); if ( ! with_audio_files ) { // set speech language to default if ( ! serviceHelper . speechConfig ( \"default\" )) { ROS_WARN_STREAM ( \"Cannot set speech language to 'default'\" ); } } } void onGestureDetected ( const std :: string & gesture , int id ) { if (( gesture == \"SWIPE DOWN\" ) || ( gesture == \"WAVING\" )) return ; if ( id != current_user_id ) return ; mutexLables . lock (); shown_gesture = gesture ; mutexLables . unlock (); } void interrupt () { interrupted = true ; } bool talk ( std :: string message ){ bool ret = true ; if ( with_audio_files ) { ret = serviceHelper . talkAudio ( message , audio_path ); if ( ! ret ) ROS_WARN_STREAM ( \"Could not play audio \" << message ); } else { try { ROS_INFO_STREAM ( \"talking '\" << speechMessages [ message ]. as < std :: string > () << \"'\" ); ret = serviceHelper . talkText ( speechMessages [ message ]. as < std :: string > ()); } catch (...) { ret = false ; } if ( ! ret ) ROS_WARN_STREAM ( \"Could not talk message \" << message ); } return ret ; } private : bool interrupted ; int prevLevel ; ros :: Time start_time ; std :: string shown_gesture ; std :: string robotMemory ; std :: string playerMemory ; boost :: mutex mutexLables ; rfsm :: StateMachine & rfsm ; std :: string audio_path ; bool with_audio_files ; YAML :: Node speechMessages ; QTrobotServiceHelper & serviceHelper ; }; /** * @brief The WaitingStateCB class */ class WaitingStateCB : public rfsm :: StateCallback { public : WaitingStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), inState ( false ), serviceHelper ( srvHelper ){ idleAppClient = nh . serviceClient < qt_idle_app :: suspend > ( \"/qt_idle_app/suspend\" ); if ( ! idleAppClient . exists ()) { ROS_WARN ( \"Could connect to /qt_idle_app/suspend\" ); } } virtual void entry () { ROS_INFO ( \"Waiting.entry()\" ); // resume qt_idle_app suspendIdleApp ( false ); inState = true ; } virtual void exit () { ROS_INFO ( \"Waiting.exit()\" ); // suspend qt_idle_app suspendIdleApp ( true ); // home all robot serviceHelper . homeAll (); inState = false ; } void onGestureDetected ( const std :: string & gesture , int id ) { // TODO check if both Q & T are shown if ( inState && gesture == \"SWIPE UP\" ) { /* static int gesture_count = 0; static ros::Time prev_gesture_time = ros::Time::now(); if((ros::Time::now()-prev_gesture_time).toSec() > 3.0) { gesture_count = 0; prev_gesture_time = ros::Time::now(); return; } if(gesture_count >= 1) { gesture_count = 0; current_user_id = id; rfsm.sendEvent(\"e_start_game\"); return; } if(gesture_count == 0) { gesture_count++; prev_gesture_time = ros::Time::now(); return; } gesture_count++; */ current_user_id = id ; rfsm . sendEvent ( \"e_start_game\" ); } } private : bool suspendIdleApp ( bool flag ) { qt_idle_app :: suspend cmdSuspend ; cmdSuspend . request . flag = flag ; if ( ! idleAppClient . call ( cmdSuspend )) { ROS_WARN ( \"Could not call service qt_idle_app::suspend\" ); return false ; } return cmdSuspend . response . status ; } private : bool inState ; rfsm :: StateMachine & rfsm ; ros :: ServiceClient idleAppClient ; QTrobotServiceHelper & serviceHelper ; }; QTGestureGameApp :: QTGestureGameApp ( ros :: NodeHandle & nh ) : serviceHelper ( nh ) { std :: string fsm_file ; if ( ! nh . getParam ( \"/qt_gesturegame_app/fsm\" , fsm_file )) { ROS_ERROR_STREAM ( \"Cannot find param /qt_gesturegame_app/fsm\" ); ros :: shutdown (); } if ( ! rfsm . load ( fsm_file )) { ROS_ERROR_STREAM ( \"Cannot load \" << fsm_file ); ros :: shutdown (); } //serviceSuspend = nh.advertiseService(\"qt_gesturegame_app/suspend\", &QTGestureGameApp::suspendCB, this); subGestures = nh . subscribe ( \"/qt_nuitrack_app/gestures\" , 10 , & QTGestureGameApp :: gestureSubCB , this ); // set speech language to English if ( ! serviceHelper . speechConfig ( \"en-US\" )) { ROS_ERROR_STREAM ( \"Cannot set speech language to 'en-US'\" ); ros :: shutdown (); } // Waiting callback waitingStateCB = new WaitingStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Waiting\" , * waitingStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } // Play callback playStateCB = new PlayStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Game.Play\" , * playStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } fsmTimer = nh . createTimer ( ros :: Duration ( 0.3 ), & QTGestureGameApp :: fsmTimerCallback , this ); } QTGestureGameApp ::~ QTGestureGameApp () { fsmTimer . stop (); } void QTGestureGameApp :: fsmTimerCallback ( const ros :: TimerEvent & event ) { mutexRFSM . lock (); rfsm . run (); mutexRFSM . unlock (); } /* void QTGestureGameApp::onNewGestures(const tdv::nuitrack::GestureData::Ptr gesture_data) { //ROS_INFO_STREAM(\"onNewGestures...\"); const std::vector<tdv::nuitrack::Gesture> gestures = gesture_data->getGestures(); for( const tdv::nuitrack::Gesture& gesture : gestures ){ ROS_INFO_STREAM(gesture.userId << \": \" << type2string(gesture.type)); if(gesture.type == GestureType::GESTURE_SWIPE_UP || gesture.type == GestureType::GESTURE_SWIPE_RIGHT || gesture.type == GestureType::GESTURE_SWIPE_LEFT) { dynamic_cast<WaitingStateCB*>(waitingStateCB)->onGestureDetected(type2string(gesture.type)); dynamic_cast<PlayStateCB*>(playStateCB)->onGestureDetected(type2string(gesture.type)); return; } } } */ bool QTGestureGameApp :: suspend ( bool flag ) { if ( flag ) { //dynamic_cast<LookAroundStateCB*>(lookAroundStateCB)->interrupt(); dynamic_cast < PlayStateCB *> ( playStateCB ) -> interrupt (); rfsm . sendEvent ( \"e_suspend\" ); mutexRFSM . lock (); rfsm . run (); // to ensure being in suspended state mutexRFSM . unlock (); } else { rfsm . sendEvent ( \"e_resume\" ); } return true ; } void QTGestureGameApp :: gestureSubCB ( const qt_nuitrack_app :: Gestures :: ConstPtr & gestures ) { for ( int i = 0 ; i < gestures -> gestures . size (); i ++ ) { ROS_INFO_STREAM ( \"gesture: \" << gestures -> gestures [ i ]. name << \", id: \" << gestures -> gestures [ i ]. id ); dynamic_cast < WaitingStateCB *> ( waitingStateCB ) -> onGestureDetected ( gestures -> gestures [ i ]. name , gestures -> gestures [ i ]. id ); dynamic_cast < PlayStateCB *> ( playStateCB ) -> onGestureDetected ( gestures -> gestures [ i ]. name , gestures -> gestures [ i ]. id ); } } /* void QTGestureGameApp::objectsSubCB(const std_msgs::Float32MultiArray::ConstPtr& objects) { if(objects->data.size() <= 0 ) return; std::string lables; for(size_t i=0; i<objects->data.size(); i+=12) { if(objects->data[i] == 1) lables.push_back('Q'); else if(objects->data[i] == 2) lables.push_back('T'); } // call related callbacks if(lables.size()) { dynamic_cast<WaitingStateCB*>(waitingStateCB)->onObjectsDetected(lables); dynamic_cast<PlayStateCB*>(playStateCB)->onObjectsDetected(lables); } } */","title":"Code"},{"location":"demos/qt_memory_game/","text":"Memory Game Demo \u00b6 About This is memory game demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository. Video \u00b6 Code \u00b6 Check code here #include <ctime> #include <cstdlib> #include <sstream> #include <std_msgs/Float64MultiArray.h> #include \"qt_memgame_app/qt_memgame_app.h\" #include \"qt_idle_app/suspend.h\" #include <boost/thread/thread.hpp> #include <yaml-cpp/yaml.h> #define ROBOT_MEMORY_INCREMENT 1 static char GestureTable [] = { 'Q' , 'T' }; /** * @brief The PlayStateCB class */ class PlayStateCB : public rfsm :: StateCallback { public : PlayStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), serviceHelper ( srvHelper ), with_audio_files ( false ) { srand ( time ( 0 )); if ( ! nh . getParam ( \"/qt_memgame_app/with_audio_files\" , with_audio_files )) { ROS_WARN_STREAM ( \"Cannot find param /qt_memgame_app/with_audio_files.\" ); } if ( with_audio_files ) { if ( ! nh . getParam ( \"/qt_memgame_app/audio_path\" , audio_path )) { ROS_WARN_STREAM ( \"Cannot find param /qt_memgame_app/audio_path.\" ); } ROS_INFO_STREAM ( \"Using audios from '\" << audio_path << \"'\" ); } else { std :: string speech_message_file ; if ( ! nh . getParam ( \"/qt_memgame_app/speech_message_file\" , speech_message_file )) { ROS_WARN_STREAM ( \"Cannot find param /qt_memgame_app/speech_message_file.\" ); } ROS_INFO_STREAM ( \"Loading speech messages from '\" << speech_message_file << \"'\" ); try { speechMessages = YAML :: LoadFile ( speech_message_file ); } catch ( YAML :: BadFile ) { ROS_ERROR_STREAM ( \"Cannot load speech file '\" << speech_message_file << \"'\" ); ros :: shutdown (); return ; } ROS_INFO_STREAM ( \"Using speech in \" << speechMessages [ \"language\" ]. as < std :: string > ()); } } virtual void entry () { ROS_INFO ( \"Play.entry()\" ); if ( ! with_audio_files ) { // set speech language std :: string lang = speechMessages [ \"language\" ]. as < std :: string > (); if ( ! serviceHelper . speechConfig ( lang )) { ROS_WARN_STREAM ( \"Cannot set speech language to \" << lang ); } } prevLevel = - 1 ; if ( with_audio_files ) serviceHelper . talkAudioPlayGesture ( \"memory_game_001\" , \"QT/challenge\" , 2.0 , true , audio_path ); else serviceHelper . talkTextPlayGesture ( speechMessages [ \"memory_game_001\" ]. as < std :: string > (), \"QT/challenge\" , 2.0 , true ); ros :: Duration ( 1.0 ). sleep (); // doo interrupted = false ; robotMemory . clear (); playerMemory . clear (); start_time = ros :: Time :: now (); while ( ! ros :: isShuttingDown () && ! interrupted ) { // motivate player if ( robotMemory . size () == 4 ) talk ( \"memory_game_002\" ); // update robot memory for ( size_t rep = 0 ; rep < ROBOT_MEMORY_INCREMENT ; rep ++ ) { robotMemory += GestureTable [( rand () % 2 )]; } //ROS_INFO_STREAM(\"Show \"<<robotMemory); if ( robotMemory . size () == ROBOT_MEMORY_INCREMENT ) talk ( \"memory_game_003\" ); else talk ( \"memory_game_004\" ); for ( size_t i = 0 ; i < robotMemory . size (); i ++ ) { if ( robotMemory [ i ] == 'Q' ) serviceHelper . playGesture ( \"QT/show_right\" , 1.0 ); else if ( robotMemory [ i ] == 'T' ) serviceHelper . playGesture ( \"QT/show_left\" , 1.0 ); else ROS_WARN_STREAM ( \"Unknown gesture \" << robotMemory [ i ]); } // clear player memory playerMemory . clear (); ROS_INFO_STREAM ( \"Your turn...\" ); talk ( \"memory_game_005\" ); // loop until player take enough moves size_t robotMemorySize = robotMemory . size (); while (( playerMemory . size () <= robotMemorySize ) && ! ros :: isShuttingDown () && ! interrupted ) { mutexLables . lock (); shown_lables . clear (); mutexLables . unlock (); // wait until user show a lable (read from user shwon image) ROS_INFO ( \"Reading...\" ); ros :: Time start_read_time = ros :: Time :: now (); bool read = false ; while ( ! read && ! ros :: isShuttingDown () && ! interrupted ) { if (( ros :: Time :: now () - start_read_time ). toSec () > 10.0 ) { ROS_INFO ( \"timeout! Okay! it seems you do not want to play anymore!\" ); if ( with_audio_files ) serviceHelper . talkAudioPlayGesture ( \"memory_game_006\" , \"QT/angry\" , 1.0 , true , audio_path ); else serviceHelper . talkTextPlayGesture ( speechMessages [ \"memory_game_006\" ]. as < std :: string > (), \"QT/angry\" , 1.0 , true ); interrupted = true ; break ; } mutexLables . lock (); if ( shown_lables . size ()) { //ROS_INFO_STREAM(\"shown \"<< shown_lables[0]); talk (( shown_lables [ 0 ] == 'Q' ) ? \"memory_game_007\" : \"memory_game_008\" ); playerMemory += shown_lables [ 0 ]; read = true ; } mutexLables . unlock (); } ros :: Duration ( 0.5 ). sleep (); if ( playerMemory . size () <= robotMemorySize ) { // ignore the last one if ( playerMemory . size () && ( playerMemory != robotMemory . substr ( 0 , playerMemory . size ()))) break ; } else // add the last gesture to robot memory robotMemory . push_back ( playerMemory . back ()); } // end of moves loop ROS_INFO_STREAM ( \"Player memory: \" << playerMemory ); ROS_INFO_STREAM ( \"Robot memory : \" << robotMemory ); if (( playerMemory != robotMemory ) && ! interrupted ) { //ros::Duration(1.0).sleep(); talk ( \"memory_game_009\" ); serviceHelper . showEmotion ( \"QT/shy\" ); break ; } } // end of main loop } virtual void exit () { int level = robotMemory . size () / 2 ; ros :: Duration game_duration = ros :: Time :: now () - start_time ; if ( robotMemory . size () < 5 ) { ROS_INFO ( \"It was a short game!\" ); talk ( \"memory_game_010\" ); } else if ( robotMemory . size () >= 5 ) { ROS_INFO ( \"Well Done! It was a good game!\" ); talk ( \"memory_game_011\" ); } else if ( robotMemory . size () >= 8 ) { talk ( \"memory_game_012\" ); } if ( prevLevel != - 1 ) { if ( level < prevLevel ) talk ( \"memory_game_013\" ); else talk ( \"memory_game_014\" ); } serviceHelper . showEmotionPlayGesture ( \"QT/kiss\" , \"QT/kiss\" , 2.0 , true ); if ( ! with_audio_files ) { // set speech language to default if ( ! serviceHelper . speechConfig ( \"default\" )) { ROS_WARN_STREAM ( \"Cannot set speech language to 'default'\" ); } } } void onObjectsDetected ( const std :: string & lables ) { mutexLables . lock (); shown_lables = lables ; mutexLables . unlock (); } void interrupt () { interrupted = true ; } bool talk ( std :: string message ){ bool ret = true ; if ( with_audio_files ) { ret = serviceHelper . talkAudio ( message , audio_path ); if ( ! ret ) ROS_WARN_STREAM ( \"Could not play audio \" << message ); } else { try { ROS_INFO_STREAM ( \"talking '\" << speechMessages [ message ]. as < std :: string > () << \"'\" ); ret = serviceHelper . talkText ( speechMessages [ message ]. as < std :: string > ()); } catch (...) { ret = false ; } if ( ! ret ) ROS_WARN_STREAM ( \"Could not talk message \" << message ); } return ret ; } private : bool interrupted ; int prevLevel ; ros :: Time start_time ; std :: string shown_lables ; std :: string robotMemory ; std :: string playerMemory ; boost :: mutex mutexLables ; rfsm :: StateMachine & rfsm ; std :: string audio_path ; bool with_audio_files ; YAML :: Node speechMessages ; QTrobotServiceHelper & serviceHelper ; }; /** * @brief The WaitingStateCB class */ class WaitingStateCB : public rfsm :: StateCallback { public : WaitingStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), inState ( false ), serviceHelper ( srvHelper ){ idleAppClient = nh . serviceClient < qt_idle_app :: suspend > ( \"/qt_idle_app/suspend\" ); if ( ! idleAppClient . exists ()) { ROS_WARN ( \"Could connect to /qt_idle_app/suspend\" ); } } virtual void entry () { ROS_INFO ( \"Waiting.entry()\" ); // resume qt_idle_app suspendIdleApp ( false ); inState = true ; } virtual void exit () { ROS_INFO ( \"Waiting.exit()\" ); // suspend qt_idle_app suspendIdleApp ( true ); // home all robot serviceHelper . homeAll (); inState = false ; } void onObjectsDetected ( const std :: string & lables ) { // TODO check if both Q & T are shown if ( inState && lables . size ()) rfsm . sendEvent ( \"e_start_game\" ); } private : bool suspendIdleApp ( bool flag ) { qt_idle_app :: suspend cmdSuspend ; cmdSuspend . request . flag = flag ; if ( ! idleAppClient . call ( cmdSuspend )) { ROS_WARN ( \"Could not call service qt_idle_app::suspend\" ); return false ; } return cmdSuspend . response . status ; } private : bool inState ; rfsm :: StateMachine & rfsm ; ros :: ServiceClient idleAppClient ; QTrobotServiceHelper serviceHelper ; }; QTMemGameApp :: QTMemGameApp ( ros :: NodeHandle & nh ) : serviceHelper ( nh ) { std :: string fsm_file ; if ( ! nh . getParam ( \"/qt_memgame_app/fsm\" , fsm_file )) { ROS_ERROR_STREAM ( \"Cannot find param /qt_memgame_app/fsm\" ); ros :: shutdown (); } if ( ! rfsm . load ( fsm_file )) { ROS_ERROR_STREAM ( \"Cannot load \" << fsm_file ); ros :: shutdown (); } //serviceSuspend = nh.advertiseService(\"qt_memgame_app/suspend\", &QTMemGameApp::suspendCB, this); subObjects = nh . subscribe ( \"/find_object/objects\" , 10 , & QTMemGameApp :: objectsSubCB , this ); // Waiting callback waitingStateCB = new WaitingStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Waiting\" , * waitingStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } // Play callback playStateCB = new PlayStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Game.Play\" , * playStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } timer = nh . createTimer ( ros :: Duration ( 0.3 ), & QTMemGameApp :: timerCallback , this ); } QTMemGameApp ::~ QTMemGameApp () { timer . stop (); } void QTMemGameApp :: timerCallback ( const ros :: TimerEvent & event ) { mutexRFSM . lock (); rfsm . run (); mutexRFSM . unlock (); } bool QTMemGameApp :: suspend ( bool flag ) { if ( flag ) { //dynamic_cast<LookAroundStateCB*>(lookAroundStateCB)->interrupt(); dynamic_cast < PlayStateCB *> ( playStateCB ) -> interrupt (); rfsm . sendEvent ( \"e_suspend\" ); mutexRFSM . lock (); rfsm . run (); // to ensure being in suspended state mutexRFSM . unlock (); } else { rfsm . sendEvent ( \"e_resume\" ); } return true ; } void QTMemGameApp :: objectsSubCB ( const std_msgs :: Float32MultiArray :: ConstPtr & objects ) { if ( objects -> data . size () <= 0 ) return ; std :: string lables ; for ( size_t i = 0 ; i < objects -> data . size (); i += 12 ) { if ( objects -> data [ i ] == 1 ) lables . push_back ( 'Q' ); else if ( objects -> data [ i ] == 2 ) lables . push_back ( 'T' ); } // call related callbacks if ( lables . size ()) { dynamic_cast < WaitingStateCB *> ( waitingStateCB ) -> onObjectsDetected ( lables ); dynamic_cast < PlayStateCB *> ( playStateCB ) -> onObjectsDetected ( lables ); } }","title":"**Memory Game Demo**"},{"location":"demos/qt_memory_game/#memory-game-demo","text":"About This is memory game demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository.","title":"Memory Game Demo"},{"location":"demos/qt_memory_game/#video","text":"","title":"Video"},{"location":"demos/qt_memory_game/#code","text":"Check code here #include <ctime> #include <cstdlib> #include <sstream> #include <std_msgs/Float64MultiArray.h> #include \"qt_memgame_app/qt_memgame_app.h\" #include \"qt_idle_app/suspend.h\" #include <boost/thread/thread.hpp> #include <yaml-cpp/yaml.h> #define ROBOT_MEMORY_INCREMENT 1 static char GestureTable [] = { 'Q' , 'T' }; /** * @brief The PlayStateCB class */ class PlayStateCB : public rfsm :: StateCallback { public : PlayStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), serviceHelper ( srvHelper ), with_audio_files ( false ) { srand ( time ( 0 )); if ( ! nh . getParam ( \"/qt_memgame_app/with_audio_files\" , with_audio_files )) { ROS_WARN_STREAM ( \"Cannot find param /qt_memgame_app/with_audio_files.\" ); } if ( with_audio_files ) { if ( ! nh . getParam ( \"/qt_memgame_app/audio_path\" , audio_path )) { ROS_WARN_STREAM ( \"Cannot find param /qt_memgame_app/audio_path.\" ); } ROS_INFO_STREAM ( \"Using audios from '\" << audio_path << \"'\" ); } else { std :: string speech_message_file ; if ( ! nh . getParam ( \"/qt_memgame_app/speech_message_file\" , speech_message_file )) { ROS_WARN_STREAM ( \"Cannot find param /qt_memgame_app/speech_message_file.\" ); } ROS_INFO_STREAM ( \"Loading speech messages from '\" << speech_message_file << \"'\" ); try { speechMessages = YAML :: LoadFile ( speech_message_file ); } catch ( YAML :: BadFile ) { ROS_ERROR_STREAM ( \"Cannot load speech file '\" << speech_message_file << \"'\" ); ros :: shutdown (); return ; } ROS_INFO_STREAM ( \"Using speech in \" << speechMessages [ \"language\" ]. as < std :: string > ()); } } virtual void entry () { ROS_INFO ( \"Play.entry()\" ); if ( ! with_audio_files ) { // set speech language std :: string lang = speechMessages [ \"language\" ]. as < std :: string > (); if ( ! serviceHelper . speechConfig ( lang )) { ROS_WARN_STREAM ( \"Cannot set speech language to \" << lang ); } } prevLevel = - 1 ; if ( with_audio_files ) serviceHelper . talkAudioPlayGesture ( \"memory_game_001\" , \"QT/challenge\" , 2.0 , true , audio_path ); else serviceHelper . talkTextPlayGesture ( speechMessages [ \"memory_game_001\" ]. as < std :: string > (), \"QT/challenge\" , 2.0 , true ); ros :: Duration ( 1.0 ). sleep (); // doo interrupted = false ; robotMemory . clear (); playerMemory . clear (); start_time = ros :: Time :: now (); while ( ! ros :: isShuttingDown () && ! interrupted ) { // motivate player if ( robotMemory . size () == 4 ) talk ( \"memory_game_002\" ); // update robot memory for ( size_t rep = 0 ; rep < ROBOT_MEMORY_INCREMENT ; rep ++ ) { robotMemory += GestureTable [( rand () % 2 )]; } //ROS_INFO_STREAM(\"Show \"<<robotMemory); if ( robotMemory . size () == ROBOT_MEMORY_INCREMENT ) talk ( \"memory_game_003\" ); else talk ( \"memory_game_004\" ); for ( size_t i = 0 ; i < robotMemory . size (); i ++ ) { if ( robotMemory [ i ] == 'Q' ) serviceHelper . playGesture ( \"QT/show_right\" , 1.0 ); else if ( robotMemory [ i ] == 'T' ) serviceHelper . playGesture ( \"QT/show_left\" , 1.0 ); else ROS_WARN_STREAM ( \"Unknown gesture \" << robotMemory [ i ]); } // clear player memory playerMemory . clear (); ROS_INFO_STREAM ( \"Your turn...\" ); talk ( \"memory_game_005\" ); // loop until player take enough moves size_t robotMemorySize = robotMemory . size (); while (( playerMemory . size () <= robotMemorySize ) && ! ros :: isShuttingDown () && ! interrupted ) { mutexLables . lock (); shown_lables . clear (); mutexLables . unlock (); // wait until user show a lable (read from user shwon image) ROS_INFO ( \"Reading...\" ); ros :: Time start_read_time = ros :: Time :: now (); bool read = false ; while ( ! read && ! ros :: isShuttingDown () && ! interrupted ) { if (( ros :: Time :: now () - start_read_time ). toSec () > 10.0 ) { ROS_INFO ( \"timeout! Okay! it seems you do not want to play anymore!\" ); if ( with_audio_files ) serviceHelper . talkAudioPlayGesture ( \"memory_game_006\" , \"QT/angry\" , 1.0 , true , audio_path ); else serviceHelper . talkTextPlayGesture ( speechMessages [ \"memory_game_006\" ]. as < std :: string > (), \"QT/angry\" , 1.0 , true ); interrupted = true ; break ; } mutexLables . lock (); if ( shown_lables . size ()) { //ROS_INFO_STREAM(\"shown \"<< shown_lables[0]); talk (( shown_lables [ 0 ] == 'Q' ) ? \"memory_game_007\" : \"memory_game_008\" ); playerMemory += shown_lables [ 0 ]; read = true ; } mutexLables . unlock (); } ros :: Duration ( 0.5 ). sleep (); if ( playerMemory . size () <= robotMemorySize ) { // ignore the last one if ( playerMemory . size () && ( playerMemory != robotMemory . substr ( 0 , playerMemory . size ()))) break ; } else // add the last gesture to robot memory robotMemory . push_back ( playerMemory . back ()); } // end of moves loop ROS_INFO_STREAM ( \"Player memory: \" << playerMemory ); ROS_INFO_STREAM ( \"Robot memory : \" << robotMemory ); if (( playerMemory != robotMemory ) && ! interrupted ) { //ros::Duration(1.0).sleep(); talk ( \"memory_game_009\" ); serviceHelper . showEmotion ( \"QT/shy\" ); break ; } } // end of main loop } virtual void exit () { int level = robotMemory . size () / 2 ; ros :: Duration game_duration = ros :: Time :: now () - start_time ; if ( robotMemory . size () < 5 ) { ROS_INFO ( \"It was a short game!\" ); talk ( \"memory_game_010\" ); } else if ( robotMemory . size () >= 5 ) { ROS_INFO ( \"Well Done! It was a good game!\" ); talk ( \"memory_game_011\" ); } else if ( robotMemory . size () >= 8 ) { talk ( \"memory_game_012\" ); } if ( prevLevel != - 1 ) { if ( level < prevLevel ) talk ( \"memory_game_013\" ); else talk ( \"memory_game_014\" ); } serviceHelper . showEmotionPlayGesture ( \"QT/kiss\" , \"QT/kiss\" , 2.0 , true ); if ( ! with_audio_files ) { // set speech language to default if ( ! serviceHelper . speechConfig ( \"default\" )) { ROS_WARN_STREAM ( \"Cannot set speech language to 'default'\" ); } } } void onObjectsDetected ( const std :: string & lables ) { mutexLables . lock (); shown_lables = lables ; mutexLables . unlock (); } void interrupt () { interrupted = true ; } bool talk ( std :: string message ){ bool ret = true ; if ( with_audio_files ) { ret = serviceHelper . talkAudio ( message , audio_path ); if ( ! ret ) ROS_WARN_STREAM ( \"Could not play audio \" << message ); } else { try { ROS_INFO_STREAM ( \"talking '\" << speechMessages [ message ]. as < std :: string > () << \"'\" ); ret = serviceHelper . talkText ( speechMessages [ message ]. as < std :: string > ()); } catch (...) { ret = false ; } if ( ! ret ) ROS_WARN_STREAM ( \"Could not talk message \" << message ); } return ret ; } private : bool interrupted ; int prevLevel ; ros :: Time start_time ; std :: string shown_lables ; std :: string robotMemory ; std :: string playerMemory ; boost :: mutex mutexLables ; rfsm :: StateMachine & rfsm ; std :: string audio_path ; bool with_audio_files ; YAML :: Node speechMessages ; QTrobotServiceHelper & serviceHelper ; }; /** * @brief The WaitingStateCB class */ class WaitingStateCB : public rfsm :: StateCallback { public : WaitingStateCB ( ros :: NodeHandle & nh , rfsm :: StateMachine & fsm , QTrobotServiceHelper & srvHelper ) : rfsm ( fsm ), inState ( false ), serviceHelper ( srvHelper ){ idleAppClient = nh . serviceClient < qt_idle_app :: suspend > ( \"/qt_idle_app/suspend\" ); if ( ! idleAppClient . exists ()) { ROS_WARN ( \"Could connect to /qt_idle_app/suspend\" ); } } virtual void entry () { ROS_INFO ( \"Waiting.entry()\" ); // resume qt_idle_app suspendIdleApp ( false ); inState = true ; } virtual void exit () { ROS_INFO ( \"Waiting.exit()\" ); // suspend qt_idle_app suspendIdleApp ( true ); // home all robot serviceHelper . homeAll (); inState = false ; } void onObjectsDetected ( const std :: string & lables ) { // TODO check if both Q & T are shown if ( inState && lables . size ()) rfsm . sendEvent ( \"e_start_game\" ); } private : bool suspendIdleApp ( bool flag ) { qt_idle_app :: suspend cmdSuspend ; cmdSuspend . request . flag = flag ; if ( ! idleAppClient . call ( cmdSuspend )) { ROS_WARN ( \"Could not call service qt_idle_app::suspend\" ); return false ; } return cmdSuspend . response . status ; } private : bool inState ; rfsm :: StateMachine & rfsm ; ros :: ServiceClient idleAppClient ; QTrobotServiceHelper serviceHelper ; }; QTMemGameApp :: QTMemGameApp ( ros :: NodeHandle & nh ) : serviceHelper ( nh ) { std :: string fsm_file ; if ( ! nh . getParam ( \"/qt_memgame_app/fsm\" , fsm_file )) { ROS_ERROR_STREAM ( \"Cannot find param /qt_memgame_app/fsm\" ); ros :: shutdown (); } if ( ! rfsm . load ( fsm_file )) { ROS_ERROR_STREAM ( \"Cannot load \" << fsm_file ); ros :: shutdown (); } //serviceSuspend = nh.advertiseService(\"qt_memgame_app/suspend\", &QTMemGameApp::suspendCB, this); subObjects = nh . subscribe ( \"/find_object/objects\" , 10 , & QTMemGameApp :: objectsSubCB , this ); // Waiting callback waitingStateCB = new WaitingStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Waiting\" , * waitingStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } // Play callback playStateCB = new PlayStateCB ( nh , rfsm , serviceHelper ); if ( ! rfsm . setStateCallback ( \"Game.Play\" , * playStateCB )) { ROS_ERROR_STREAM ( \"Cannot set callback for Waiting from \" << fsm_file ); ros :: shutdown (); } timer = nh . createTimer ( ros :: Duration ( 0.3 ), & QTMemGameApp :: timerCallback , this ); } QTMemGameApp ::~ QTMemGameApp () { timer . stop (); } void QTMemGameApp :: timerCallback ( const ros :: TimerEvent & event ) { mutexRFSM . lock (); rfsm . run (); mutexRFSM . unlock (); } bool QTMemGameApp :: suspend ( bool flag ) { if ( flag ) { //dynamic_cast<LookAroundStateCB*>(lookAroundStateCB)->interrupt(); dynamic_cast < PlayStateCB *> ( playStateCB ) -> interrupt (); rfsm . sendEvent ( \"e_suspend\" ); mutexRFSM . lock (); rfsm . run (); // to ensure being in suspended state mutexRFSM . unlock (); } else { rfsm . sendEvent ( \"e_resume\" ); } return true ; } void QTMemGameApp :: objectsSubCB ( const std_msgs :: Float32MultiArray :: ConstPtr & objects ) { if ( objects -> data . size () <= 0 ) return ; std :: string lables ; for ( size_t i = 0 ; i < objects -> data . size (); i += 12 ) { if ( objects -> data [ i ] == 1 ) lables . push_back ( 'Q' ); else if ( objects -> data [ i ] == 2 ) lables . push_back ( 'T' ); } // call related callbacks if ( lables . size ()) { dynamic_cast < WaitingStateCB *> ( waitingStateCB ) -> onObjectsDetected ( lables ); dynamic_cast < PlayStateCB *> ( playStateCB ) -> onObjectsDetected ( lables ); } }","title":"Code"},{"location":"demos/qt_microphone_detection/","text":"Microphone Voice Activity & Direction Detection \u00b6 About This is microphone voice activity and direction detection demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository. Video \u00b6 Setup \u00b6 NOTICE You must run this demo on QTRP (head) How to set it up? This demo needs some prerequisites: sudo apt - get update sudo pip install pyusb click OR sudo apt - get update sudo ` which pip ` install pyusb click PyUSB needs root privileges, if you run the script without root you will see something like this: usb . core . USBError : [ Errno 13 ] Access denied ( insufficient permissions ) To fix this error we need to set up a udev rule file for the microphone to be able to access it with normal user. * Create a udev rules file: ACTION == \"add\" , SUBSYSTEMS == \"usb\" , ATTRS { idVendor } == \"2886\" , ATTRS { idProduct } == \"0018\" , MODE = \"660\" , GROUP = \"plugdev\" Create this file in folder /etc/udev/rules.d/ . For example usual structure of the file name can be Number-Name.rules Add the user to the plugdev group: adduser username plugdev Reload udev system to see your changes: sudo udevadm control --reload sudo udevadm trigger Reboot QTrobot: sudo reboot To run the demo go to qt_microphone_detection folder and run voice_direction python script: cd qt_microphone_detection / python voice_direction . py Now you can speak or sing around the QTrobot and he will follow your voice. Code \u00b6 Check code here from tuning import Tuning import usb.core import usb.util import time import sys import rospy from std_msgs.msg import Float64MultiArray # microphone orientation MICROPHONE_ANGLE_OFFSET = 90 if __name__ == '__main__' : rospy . init_node ( 'voice_direction' , anonymous = True ) dev = usb . core . find ( idVendor = 0x2886 , idProduct = 0x0018 ) if not dev : rospy . logerr ( \"Cannot establish connection!\" ) sys . exit () head_pub = rospy . Publisher ( '/qt_robot/head_position/command' , Float64MultiArray , queue_size = 1 ) # wait for publisher connections wtime_begin = rospy . get_time () while ( head_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for publisher connections...\" ) if rospy . get_time () - wtime_begin > 10.0 : rospy . logerr ( \"Timeout while waiting for publisher connection!\" ) sys . exit () rospy . sleep ( 1 ) # centering the head href = Float64MultiArray ( data = [ 0 , 0 ]) head_pub . publish ( href ) rospy . sleep ( 1 ) microphone = Tuning ( dev ) while not rospy . is_shutdown (): if not microphone . is_voice (): continue mic = abs ( microphone . direction - 180 ) angle = mic - MICROPHONE_ANGLE_OFFSET rospy . loginfo ( \"mic: %d , head: %d \" % ( mic , angle )) href . data = [ angle , 0 ] head_pub . publish ( href ) rospy . loginfo ( \"shutdowned!\" )","title":"**Microphone Voice Activity & Direction Detection**"},{"location":"demos/qt_microphone_detection/#microphone-voice-activity-direction-detection","text":"About This is microphone voice activity and direction detection demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository.","title":"Microphone Voice Activity &amp; Direction Detection"},{"location":"demos/qt_microphone_detection/#video","text":"","title":"Video"},{"location":"demos/qt_microphone_detection/#setup","text":"NOTICE You must run this demo on QTRP (head) How to set it up? This demo needs some prerequisites: sudo apt - get update sudo pip install pyusb click OR sudo apt - get update sudo ` which pip ` install pyusb click PyUSB needs root privileges, if you run the script without root you will see something like this: usb . core . USBError : [ Errno 13 ] Access denied ( insufficient permissions ) To fix this error we need to set up a udev rule file for the microphone to be able to access it with normal user. * Create a udev rules file: ACTION == \"add\" , SUBSYSTEMS == \"usb\" , ATTRS { idVendor } == \"2886\" , ATTRS { idProduct } == \"0018\" , MODE = \"660\" , GROUP = \"plugdev\" Create this file in folder /etc/udev/rules.d/ . For example usual structure of the file name can be Number-Name.rules Add the user to the plugdev group: adduser username plugdev Reload udev system to see your changes: sudo udevadm control --reload sudo udevadm trigger Reboot QTrobot: sudo reboot To run the demo go to qt_microphone_detection folder and run voice_direction python script: cd qt_microphone_detection / python voice_direction . py Now you can speak or sing around the QTrobot and he will follow your voice.","title":"Setup"},{"location":"demos/qt_microphone_detection/#code","text":"Check code here from tuning import Tuning import usb.core import usb.util import time import sys import rospy from std_msgs.msg import Float64MultiArray # microphone orientation MICROPHONE_ANGLE_OFFSET = 90 if __name__ == '__main__' : rospy . init_node ( 'voice_direction' , anonymous = True ) dev = usb . core . find ( idVendor = 0x2886 , idProduct = 0x0018 ) if not dev : rospy . logerr ( \"Cannot establish connection!\" ) sys . exit () head_pub = rospy . Publisher ( '/qt_robot/head_position/command' , Float64MultiArray , queue_size = 1 ) # wait for publisher connections wtime_begin = rospy . get_time () while ( head_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for publisher connections...\" ) if rospy . get_time () - wtime_begin > 10.0 : rospy . logerr ( \"Timeout while waiting for publisher connection!\" ) sys . exit () rospy . sleep ( 1 ) # centering the head href = Float64MultiArray ( data = [ 0 , 0 ]) head_pub . publish ( href ) rospy . sleep ( 1 ) microphone = Tuning ( dev ) while not rospy . is_shutdown (): if not microphone . is_voice (): continue mic = abs ( microphone . direction - 180 ) angle = mic - MICROPHONE_ANGLE_OFFSET rospy . loginfo ( \"mic: %d , head: %d \" % ( mic , angle )) href . data = [ angle , 0 ] head_pub . publish ( href ) rospy . loginfo ( \"shutdowned!\" )","title":"Code"},{"location":"demos/qt_microphone_interaction/","text":"Microphone Voice Interaction \u00b6 About This is microphone voice interaction demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository. Video \u00b6 Setup \u00b6 NOTICE You must read and fully understand Snips voice system before starting this Please read the documentation of snips to understand it https://console.snips.ai/login How to set it up? This demo is already installed on your QTrobot. you can find it under ~/robot/code/qt_app Snips already installed on QTRP (head) how to run the snip servers: sudo systemctl start snips - asr . service snips - audio - server . service snips - dialogue . service snips - hotword . service snips - nlu . service how to run qt_voice_app demo rosrun qt_voice_app qt_voice_app . py Voice commands Hey QT, show me your happy emotion Hey QT, play happy gesture Snips configuration file / etc / snips . toml Code \u00b6 Check code here #!/usr/bin/env python2 # -*- coding: utf-8 -*- import time import threading from hermes_python.hermes import Hermes import rospy from std_msgs.msg import String from qt_gesture_controller.srv import * from qt_motors_controller.srv import * from qt_robot_interface.srv import * talkText = rospy . ServiceProxy ( '/qt_robot/behavior/talkText' , behavior_talk_text ) gesturePlay = rospy . ServiceProxy ( '/qt_robot/gesture/play' , gesture_play ) gestureList = rospy . ServiceProxy ( '/qt_robot/gesture/list' , gesture_list ) gestureSave = rospy . ServiceProxy ( '/qt_robot/gesture/save' , gesture_save ) setControlMode = rospy . ServiceProxy ( '/qt_robot/motors/setControlMode' , set_control_mode ) gestureRecord = rospy . ServiceProxy ( '/qt_robot/gesture/record' , gesture_record ) #gesturePlay_pub = rospy.Publisher('/qt_robot/gesture/play', String, queue_size=10) emotionShow_pub = rospy . Publisher ( '/qt_robot/emotion/show' , String , queue_size = 10 ) action_thread = None def emotion_intent_callback ( hermes , intent_message ): #hermes.publish_end_session(intent_message.session_id, None) print ( \"in emotion_intent_callback\" ) if intent_message . slots : for ( slot_value , slot ) in intent_message . slots . items (): if slot_value == \"ShowEmotion\" : emotion_name = slot [ 0 ] . slot_value . value . value try : print ( \"Showing emotion %s \" % \"QT/ %s \" % emotion_name ) talkText ( \"This is my %s face.\" % emotion_name . replace ( \"_\" , \" \" )) emotionShow_pub . publish ( \"QT/ %s \" % emotion_name ) except rospy . ServiceException , e : print \"Service call failed: %s .\" % e talkText ( \"I have a problem for showing emotion %s \" % emotion_name ) else : talkText ( \"I did not understand which emotion.\" ) emotionShow_pub . publish ( \"QT/confused\" ) print ( \"done!\" ) def play_intent_callback ( hermes , intent_message ): #hermes.publish_end_session(intent_message.session_id, None) # action code goes here... print ( \"in play_intent_callback\" ) if intent_message . slots : for ( slot_value , slot ) in intent_message . slots . items (): if slot_value == \"GastureName\" : gesture_name = slot [ 0 ] . slot_value . value . value try : res = gestureList () if gesture_name not in res . gestures : talkText ( \"I do not know this gesture. But you can always record your gesture. Just ask me, hey Q.T. . record, new gesture!\" ) else : if gesture_name != \"my\" : gesture_name = \"QT/\" + gesture_name print ( \"playing gesture ' %s '.\" % gesture_name ) res = gesturePlay ( gesture_name , 1.0 ) except rospy . ServiceException , e : print \"Service call failed: %s .\" % e talkText ( \"I have a problem for playing gesture %s \" % gesture_name ) else : talkText ( \"I did not understand which gesture.\" ) emotionShow_pub . publish ( \"QT/confused\" ) print ( \"done!\" ) def record_intent_callback ( hermes , intent_message ): #hermes.publish_end_session(intent_message.session_id, None) print ( \"in record_intent_callback\" ) talkText ( \"You can start recording your gesture.\" ) res = gestureRecord ([ \"right_arm\" , \"left_arm\" ], True , 0 , 0 ) print ( \"done!\" ) def stop_intent_callback ( hermes , intent_message ): #hermes.publish_end_session(intent_message.session_id, None) print ( \"in stop_intent_callback\" ) res = gestureSave ( \"my\" , \"\" ) if not res . status : talkText ( \"I have a problem with recording the gesture\" ) setControlMode ([ \"right_arm\" , \"left_arm\" ], 1 ) talkText ( \"Gesture recorded!\" ) print ( \"done!\" ) def unknown_intent_callback ( hermes , intent_message ): talkText ( \"I do not know this. But you can ask me to play gesture or show emotions.\" ) print ( \"done\" ) def intent_received ( hermes , intent_message ): hermes . publish_end_session ( intent_message . session_id , None ) coming_intent = intent_message . intent . intent_name print ( intent_message . intent . confidence_score ) if intent_message . intent . confidence_score < 0.5 : action_thread = threading . Thread ( target = unknown_intent_callback , args = ( hermes , intent_message )) action_thread . start () return print if coming_intent == 'apaikan:Play' : action_thread = threading . Thread ( target = play_intent_callback , args = ( hermes , intent_message )) action_thread . start () elif coming_intent == 'apaikan:Record' : action_thread = threading . Thread ( target = record_intent_callback , args = ( hermes , intent_message )) action_thread . start () elif coming_intent == 'apaikan:Emotion' : action_thread = threading . Thread ( target = emotion_intent_callback , args = ( hermes , intent_message )) action_thread . start () elif coming_intent == 'apaikan:Stop' : action_thread = threading . Thread ( target = stop_intent_callback , args = ( hermes , intent_message )) action_thread . start () else : action_thread = threading . Thread ( target = unknown_intent_callback , args = ( hermes , intent_message )) action_thread . start () def intent_not_recognized ( hermes , intent_nr_message ): print ( \"not recogniozed\" ) action_thread = threading . Thread ( target = unknown_intent_callback , args = ( hermes , intent_nr_message )) action_thread . start () if __name__ == \"__main__\" : # call the relevant service rospy . init_node ( 'qt_voice_interface' , disable_signals = True ) with Hermes ( 'localhost:1883' ) as h : # h.subscribe_intent(\"apaikan:Play\", play_intent_callback) # h.subscribe_intent(\"apaikan:Record\", record_intent_callback) # h.subscribe_intent(\"apaikan:Stop\", stop_intent_callback) # h.subscribe_intent(\"apaikan:Emotion\", emotion_intent_callback) h . subscribe_intents ( intent_received ) h . subscribe_intent_not_recognized ( intent_not_recognized ) h . loop_forever () # async mode using #h.loop_start() rospy.spin() h.loop_stop()","title":"**Microphone Voice Interaction**"},{"location":"demos/qt_microphone_interaction/#microphone-voice-interaction","text":"About This is microphone voice interaction demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository.","title":"Microphone Voice Interaction"},{"location":"demos/qt_microphone_interaction/#video","text":"","title":"Video"},{"location":"demos/qt_microphone_interaction/#setup","text":"NOTICE You must read and fully understand Snips voice system before starting this Please read the documentation of snips to understand it https://console.snips.ai/login How to set it up? This demo is already installed on your QTrobot. you can find it under ~/robot/code/qt_app Snips already installed on QTRP (head) how to run the snip servers: sudo systemctl start snips - asr . service snips - audio - server . service snips - dialogue . service snips - hotword . service snips - nlu . service how to run qt_voice_app demo rosrun qt_voice_app qt_voice_app . py Voice commands Hey QT, show me your happy emotion Hey QT, play happy gesture Snips configuration file / etc / snips . toml","title":"Setup"},{"location":"demos/qt_microphone_interaction/#code","text":"Check code here #!/usr/bin/env python2 # -*- coding: utf-8 -*- import time import threading from hermes_python.hermes import Hermes import rospy from std_msgs.msg import String from qt_gesture_controller.srv import * from qt_motors_controller.srv import * from qt_robot_interface.srv import * talkText = rospy . ServiceProxy ( '/qt_robot/behavior/talkText' , behavior_talk_text ) gesturePlay = rospy . ServiceProxy ( '/qt_robot/gesture/play' , gesture_play ) gestureList = rospy . ServiceProxy ( '/qt_robot/gesture/list' , gesture_list ) gestureSave = rospy . ServiceProxy ( '/qt_robot/gesture/save' , gesture_save ) setControlMode = rospy . ServiceProxy ( '/qt_robot/motors/setControlMode' , set_control_mode ) gestureRecord = rospy . ServiceProxy ( '/qt_robot/gesture/record' , gesture_record ) #gesturePlay_pub = rospy.Publisher('/qt_robot/gesture/play', String, queue_size=10) emotionShow_pub = rospy . Publisher ( '/qt_robot/emotion/show' , String , queue_size = 10 ) action_thread = None def emotion_intent_callback ( hermes , intent_message ): #hermes.publish_end_session(intent_message.session_id, None) print ( \"in emotion_intent_callback\" ) if intent_message . slots : for ( slot_value , slot ) in intent_message . slots . items (): if slot_value == \"ShowEmotion\" : emotion_name = slot [ 0 ] . slot_value . value . value try : print ( \"Showing emotion %s \" % \"QT/ %s \" % emotion_name ) talkText ( \"This is my %s face.\" % emotion_name . replace ( \"_\" , \" \" )) emotionShow_pub . publish ( \"QT/ %s \" % emotion_name ) except rospy . ServiceException , e : print \"Service call failed: %s .\" % e talkText ( \"I have a problem for showing emotion %s \" % emotion_name ) else : talkText ( \"I did not understand which emotion.\" ) emotionShow_pub . publish ( \"QT/confused\" ) print ( \"done!\" ) def play_intent_callback ( hermes , intent_message ): #hermes.publish_end_session(intent_message.session_id, None) # action code goes here... print ( \"in play_intent_callback\" ) if intent_message . slots : for ( slot_value , slot ) in intent_message . slots . items (): if slot_value == \"GastureName\" : gesture_name = slot [ 0 ] . slot_value . value . value try : res = gestureList () if gesture_name not in res . gestures : talkText ( \"I do not know this gesture. But you can always record your gesture. Just ask me, hey Q.T. . record, new gesture!\" ) else : if gesture_name != \"my\" : gesture_name = \"QT/\" + gesture_name print ( \"playing gesture ' %s '.\" % gesture_name ) res = gesturePlay ( gesture_name , 1.0 ) except rospy . ServiceException , e : print \"Service call failed: %s .\" % e talkText ( \"I have a problem for playing gesture %s \" % gesture_name ) else : talkText ( \"I did not understand which gesture.\" ) emotionShow_pub . publish ( \"QT/confused\" ) print ( \"done!\" ) def record_intent_callback ( hermes , intent_message ): #hermes.publish_end_session(intent_message.session_id, None) print ( \"in record_intent_callback\" ) talkText ( \"You can start recording your gesture.\" ) res = gestureRecord ([ \"right_arm\" , \"left_arm\" ], True , 0 , 0 ) print ( \"done!\" ) def stop_intent_callback ( hermes , intent_message ): #hermes.publish_end_session(intent_message.session_id, None) print ( \"in stop_intent_callback\" ) res = gestureSave ( \"my\" , \"\" ) if not res . status : talkText ( \"I have a problem with recording the gesture\" ) setControlMode ([ \"right_arm\" , \"left_arm\" ], 1 ) talkText ( \"Gesture recorded!\" ) print ( \"done!\" ) def unknown_intent_callback ( hermes , intent_message ): talkText ( \"I do not know this. But you can ask me to play gesture or show emotions.\" ) print ( \"done\" ) def intent_received ( hermes , intent_message ): hermes . publish_end_session ( intent_message . session_id , None ) coming_intent = intent_message . intent . intent_name print ( intent_message . intent . confidence_score ) if intent_message . intent . confidence_score < 0.5 : action_thread = threading . Thread ( target = unknown_intent_callback , args = ( hermes , intent_message )) action_thread . start () return print if coming_intent == 'apaikan:Play' : action_thread = threading . Thread ( target = play_intent_callback , args = ( hermes , intent_message )) action_thread . start () elif coming_intent == 'apaikan:Record' : action_thread = threading . Thread ( target = record_intent_callback , args = ( hermes , intent_message )) action_thread . start () elif coming_intent == 'apaikan:Emotion' : action_thread = threading . Thread ( target = emotion_intent_callback , args = ( hermes , intent_message )) action_thread . start () elif coming_intent == 'apaikan:Stop' : action_thread = threading . Thread ( target = stop_intent_callback , args = ( hermes , intent_message )) action_thread . start () else : action_thread = threading . Thread ( target = unknown_intent_callback , args = ( hermes , intent_message )) action_thread . start () def intent_not_recognized ( hermes , intent_nr_message ): print ( \"not recogniozed\" ) action_thread = threading . Thread ( target = unknown_intent_callback , args = ( hermes , intent_nr_message )) action_thread . start () if __name__ == \"__main__\" : # call the relevant service rospy . init_node ( 'qt_voice_interface' , disable_signals = True ) with Hermes ( 'localhost:1883' ) as h : # h.subscribe_intent(\"apaikan:Play\", play_intent_callback) # h.subscribe_intent(\"apaikan:Record\", record_intent_callback) # h.subscribe_intent(\"apaikan:Stop\", stop_intent_callback) # h.subscribe_intent(\"apaikan:Emotion\", emotion_intent_callback) h . subscribe_intents ( intent_received ) h . subscribe_intent_not_recognized ( intent_not_recognized ) h . loop_forever () # async mode using #h.loop_start() rospy.spin() h.loop_stop()","title":"Code"},{"location":"demos/qt_range_of_motion/","text":"Range of Motion and DOF \u00b6 About This is range of motion and DOF demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository. Video \u00b6 Code \u00b6 Check code here #!/usr/bin/env python ''' Copyright (C) 2018 LuxAI S.A Authors: Ali Paikan CopyPolicy: Released under the terms of the LGPLv2.1 or later, see LGPL.TXT ''' import sys import rospy from std_msgs.msg import Float64MultiArray if __name__ == '__main__' : rospy . init_node ( 'qt_motor_command' ) # create a publisher right_pub = rospy . Publisher ( '/qt_robot/right_arm_position/command' , Float64MultiArray , queue_size = 1 ) # wait for publisher/subscriber connections wtime_begin = rospy . get_time () while ( right_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for subscriber connections...\" ) if rospy . get_time () - wtime_begin > 10.0 : rospy . logerr ( \"Timeout while waiting for subscribers connection!\" ) sys . exit () rospy . sleep ( 1 ) rospy . loginfo ( \"publishing motor commnad...\" ) try : ref = Float64MultiArray () RightShoulderPitch = 90 RightShoulderRoll = 0 RightElbowRoll = - 70 ref . data = [ RightShoulderPitch , RightShoulderRoll , RightElbowRoll ] right_pub . publish ( ref ) except rospy . ROSInterruptException : rospy . logerr ( \"could not publish motor commnad!\" ) rospy . loginfo ( \"motor commnad published\" )","title":"**Range of Motion and DOF**"},{"location":"demos/qt_range_of_motion/#range-of-motion-and-dof","text":"About This is range of motion and DOF demo with QTrobot. Check the video for demonstration. Full code for this demo you can find in our github tutorial repository.","title":"Range of Motion and DOF"},{"location":"demos/qt_range_of_motion/#video","text":"","title":"Video"},{"location":"demos/qt_range_of_motion/#code","text":"Check code here #!/usr/bin/env python ''' Copyright (C) 2018 LuxAI S.A Authors: Ali Paikan CopyPolicy: Released under the terms of the LGPLv2.1 or later, see LGPL.TXT ''' import sys import rospy from std_msgs.msg import Float64MultiArray if __name__ == '__main__' : rospy . init_node ( 'qt_motor_command' ) # create a publisher right_pub = rospy . Publisher ( '/qt_robot/right_arm_position/command' , Float64MultiArray , queue_size = 1 ) # wait for publisher/subscriber connections wtime_begin = rospy . get_time () while ( right_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for subscriber connections...\" ) if rospy . get_time () - wtime_begin > 10.0 : rospy . logerr ( \"Timeout while waiting for subscribers connection!\" ) sys . exit () rospy . sleep ( 1 ) rospy . loginfo ( \"publishing motor commnad...\" ) try : ref = Float64MultiArray () RightShoulderPitch = 90 RightShoulderRoll = 0 RightElbowRoll = - 70 ref . data = [ RightShoulderPitch , RightShoulderRoll , RightElbowRoll ] right_pub . publish ( ref ) except rospy . ROSInterruptException : rospy . logerr ( \"could not publish motor commnad!\" ) rospy . loginfo ( \"motor commnad published\" )","title":"Code"},{"location":"examples/qt_audio_interface/","text":"Accessing QTrobot audio interface with Python \u00b6 The QTrobot is using ROS for easier access to basic robot functionalities with ROS publish/subscriber and Service/Client interfaces. Rospy is a pure Python client library for ROS. The rospy client API enables Python programmers to quickly interface with ROS Topics, Services, and Parameters. We will use Python code to access QTrobot audio interface with rospy module. This interface allows you to play a standard audio file (e.g. wav, mp3). The audio file can be given using its complete name (with the file extension) such as happy.mp3 or simply without the file extension: happy. In the second case, the player first looks for happy.mp3 to play and if it is not found it then tries with happy.wav and so on. NOTICE The default path for the audio files is '~/robot/data/audios/' Audio interface is accessible with publish/subscribe and service/client methods. In this example we will use publish/subscribe method. You can also check \"4.2 Audio Interface\" chapter on Wiki ROS. First we should import rospy, QTrobot interface module and data type. Step 1 import sys import rospy from std_msgs.msg import String from qt_robot_interface.srv import * Next up we initialize ROS node and declare a name for it. To create a ROS publisher we need topic name, data type and size of our queue. Topic name for accessing QTrobot audio interface is \"/qt_robot/audio/play\" and data type is text \"String\" audio file name. Step 2 # ros node rospy . init_node ( 'python_qt_example' ) # creating a audio ros publisher audioPlay_pub = rospy . Publisher ( '/qt_robot/audio/play' , String , queue_size = 10 ) # waiting for connection establishment wtime_begin = rospy . get_time () while ( audioPlay_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for publisher connection\" ) if rospy . get_time () - wtime_begin > 5.0 : rospy . logerr ( \"Timeout while waiting for publisher connection!\" ) sys . exit () rospy . sleep ( 1 ) To play audio file with the QTrobot audio interface we need to call publish function of the ROS publisher(audioPlay_pub) that we created with the audio file name. Step 3 # publish audio file audioPlay_pub . publish ( \"QT/5LittleBunnies\" ) NOTICE To play the audio file from the default path, pass an empty string to filepath parameter. Get the full code in our github tutorial repository.","title":"Accessing QTrobot audio interface with Python"},{"location":"examples/qt_audio_interface/#accessing-qtrobot-audio-interface-with-python","text":"The QTrobot is using ROS for easier access to basic robot functionalities with ROS publish/subscriber and Service/Client interfaces. Rospy is a pure Python client library for ROS. The rospy client API enables Python programmers to quickly interface with ROS Topics, Services, and Parameters. We will use Python code to access QTrobot audio interface with rospy module. This interface allows you to play a standard audio file (e.g. wav, mp3). The audio file can be given using its complete name (with the file extension) such as happy.mp3 or simply without the file extension: happy. In the second case, the player first looks for happy.mp3 to play and if it is not found it then tries with happy.wav and so on. NOTICE The default path for the audio files is '~/robot/data/audios/' Audio interface is accessible with publish/subscribe and service/client methods. In this example we will use publish/subscribe method. You can also check \"4.2 Audio Interface\" chapter on Wiki ROS. First we should import rospy, QTrobot interface module and data type. Step 1 import sys import rospy from std_msgs.msg import String from qt_robot_interface.srv import * Next up we initialize ROS node and declare a name for it. To create a ROS publisher we need topic name, data type and size of our queue. Topic name for accessing QTrobot audio interface is \"/qt_robot/audio/play\" and data type is text \"String\" audio file name. Step 2 # ros node rospy . init_node ( 'python_qt_example' ) # creating a audio ros publisher audioPlay_pub = rospy . Publisher ( '/qt_robot/audio/play' , String , queue_size = 10 ) # waiting for connection establishment wtime_begin = rospy . get_time () while ( audioPlay_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for publisher connection\" ) if rospy . get_time () - wtime_begin > 5.0 : rospy . logerr ( \"Timeout while waiting for publisher connection!\" ) sys . exit () rospy . sleep ( 1 ) To play audio file with the QTrobot audio interface we need to call publish function of the ROS publisher(audioPlay_pub) that we created with the audio file name. Step 3 # publish audio file audioPlay_pub . publish ( \"QT/5LittleBunnies\" ) NOTICE To play the audio file from the default path, pass an empty string to filepath parameter. Get the full code in our github tutorial repository.","title":"Accessing QTrobot audio interface with Python"},{"location":"examples/qt_emotion_interface/","text":"Accessing QTrobot Emotion interface with Python \u00b6 The QTrobot is using ROS for easier access to basic robot functionalities with ROS publish/subscriber and Service/Client interfaces. Rospy is a pure Python client library for ROS. The rospy client API enables Python programmers to quickly interface with ROS Topics, Services, and Parameters. We will use Python code to access QTrobot emotion interface with rospy module. This interface allows you to change the QTrobot facial emotions such as 'QT/happy', 'QT/sad', etc. NOTICE The complete list of emotion files can be found in '~/robot/data/emotions/'. Emotion interface is accessible with publish/subscribe and service/client methods. In this example we will use publish/subscribe method. You can also check \"4.3 Emotion Interface\" chapter on Wiki ROS. First we should import rospy, QTrobot interface module and data type. Step 1 import sys import rospy from std_msgs.msg import String from qt_robot_interface.srv import * Next up we initialize ROS node and declare a name for it. To create a ROS publisher we need topic name, data type and size of our queue. Topic name for accessing QTrobot emotion interface is \"/qt_robot/emotion/show\" and data type is text \"String\" emotion name. Step 2 # ros node rospy . init_node ( 'python_qt_example' ) # creating a emotion ros publisher emotionShow_pub = rospy . Publisher ( '/qt_robot/emotion/show' , String , queue_size = 10 ) # waiting for connection establishment wtime_begin = rospy . get_time () while ( emotionShow_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for publisher connection\" ) if rospy . get_time () - wtime_begin > 5.0 : rospy . logerr ( \"Timeout while waiting for publisher connection!\" ) sys . exit () rospy . sleep ( 1 ) To show emotion with the QTrobot emotion interface we need to call publish function of the ROS publisher(emotionShow_pub) that we created with the emotion file name. Step 3 # publish emotion to QTrobot emotionShow_pub . publish ( \"QT/happy\" ) Get the full code in our github tutorial repository.","title":"Accessing QTrobot Emotion interface with Python"},{"location":"examples/qt_emotion_interface/#accessing-qtrobot-emotion-interface-with-python","text":"The QTrobot is using ROS for easier access to basic robot functionalities with ROS publish/subscriber and Service/Client interfaces. Rospy is a pure Python client library for ROS. The rospy client API enables Python programmers to quickly interface with ROS Topics, Services, and Parameters. We will use Python code to access QTrobot emotion interface with rospy module. This interface allows you to change the QTrobot facial emotions such as 'QT/happy', 'QT/sad', etc. NOTICE The complete list of emotion files can be found in '~/robot/data/emotions/'. Emotion interface is accessible with publish/subscribe and service/client methods. In this example we will use publish/subscribe method. You can also check \"4.3 Emotion Interface\" chapter on Wiki ROS. First we should import rospy, QTrobot interface module and data type. Step 1 import sys import rospy from std_msgs.msg import String from qt_robot_interface.srv import * Next up we initialize ROS node and declare a name for it. To create a ROS publisher we need topic name, data type and size of our queue. Topic name for accessing QTrobot emotion interface is \"/qt_robot/emotion/show\" and data type is text \"String\" emotion name. Step 2 # ros node rospy . init_node ( 'python_qt_example' ) # creating a emotion ros publisher emotionShow_pub = rospy . Publisher ( '/qt_robot/emotion/show' , String , queue_size = 10 ) # waiting for connection establishment wtime_begin = rospy . get_time () while ( emotionShow_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for publisher connection\" ) if rospy . get_time () - wtime_begin > 5.0 : rospy . logerr ( \"Timeout while waiting for publisher connection!\" ) sys . exit () rospy . sleep ( 1 ) To show emotion with the QTrobot emotion interface we need to call publish function of the ROS publisher(emotionShow_pub) that we created with the emotion file name. Step 3 # publish emotion to QTrobot emotionShow_pub . publish ( \"QT/happy\" ) Get the full code in our github tutorial repository.","title":"Accessing QTrobot Emotion interface with Python"},{"location":"examples/qt_motors_command/","text":"QTrobot Motors command \u00b6 Get the full code in our github tutorial repository. Code #!/usr/bin/env python ''' Copyright (C) 2018 LuxAI S.A Authors: Ali Paikan CopyPolicy: Released under the terms of the LGPLv2.1 or later, see LGPL.TXT ''' import sys import rospy from std_msgs.msg import Float64MultiArray if __name__ == '__main__' : rospy . init_node ( 'qt_motor_command' ) # create a publisher right_pub = rospy . Publisher ( '/qt_robot/right_arm_position/command' , Float64MultiArray , queue_size = 1 ) # wait for publisher/subscriber connections wtime_begin = rospy . get_time () while ( right_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for subscriber connections...\" ) if rospy . get_time () - wtime_begin > 10.0 : rospy . logerr ( \"Timeout while waiting for subscribers connection!\" ) sys . exit () rospy . sleep ( 1 ) rospy . loginfo ( \"publishing motor commnad...\" ) try : ref = Float64MultiArray () RightShoulderPitch = 90 RightShoulderRoll = 0 RightElbowRoll = - 70 ref . data = [ RightShoulderPitch , RightShoulderRoll , RightElbowRoll ] right_pub . publish ( ref ) except rospy . ROSInterruptException : rospy . logerr ( \"could not publish motor commnad!\" ) rospy . loginfo ( \"motor commnad published\" )","title":"**QTrobot Motors command**"},{"location":"examples/qt_motors_command/#qtrobot-motors-command","text":"Get the full code in our github tutorial repository. Code #!/usr/bin/env python ''' Copyright (C) 2018 LuxAI S.A Authors: Ali Paikan CopyPolicy: Released under the terms of the LGPLv2.1 or later, see LGPL.TXT ''' import sys import rospy from std_msgs.msg import Float64MultiArray if __name__ == '__main__' : rospy . init_node ( 'qt_motor_command' ) # create a publisher right_pub = rospy . Publisher ( '/qt_robot/right_arm_position/command' , Float64MultiArray , queue_size = 1 ) # wait for publisher/subscriber connections wtime_begin = rospy . get_time () while ( right_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for subscriber connections...\" ) if rospy . get_time () - wtime_begin > 10.0 : rospy . logerr ( \"Timeout while waiting for subscribers connection!\" ) sys . exit () rospy . sleep ( 1 ) rospy . loginfo ( \"publishing motor commnad...\" ) try : ref = Float64MultiArray () RightShoulderPitch = 90 RightShoulderRoll = 0 RightElbowRoll = - 70 ref . data = [ RightShoulderPitch , RightShoulderRoll , RightElbowRoll ] right_pub . publish ( ref ) except rospy . ROSInterruptException : rospy . logerr ( \"could not publish motor commnad!\" ) rospy . loginfo ( \"motor commnad published\" )","title":"QTrobot Motors command"},{"location":"examples/qt_motors_gesture/","text":"QTrobot Motors gesture \u00b6 Get the full code in our github tutorial repository. Code #!/usr/bin/env python ''' Copyright (C) 2018 LuxAI S.A Authors: Ali Paikan CopyPolicy: Released under the terms of the LGPLv2.1 or later, see LGPL.TXT ''' import rospy from qt_gesture_controller.srv import * def print_help (): print ( \"QTrobot gesture player example\" ) print ( \"Usage:\" ) print ( \" qt_motors_gesture <name> play a gesture given by its <name>\" ) print ( \"\" ) # main if __name__ == '__main__' : # check the params if len ( sys . argv ) < 2 : print_help () sys . exit ( 1 ) # call the relevant service rospy . init_node ( 'qt_motors_gesture' ) try : gesturePlay = rospy . ServiceProxy ( '/qt_robot/gesture/play' , gesture_play ) res = gesturePlay ( sys . argv [ 1 ], 1.0 ) if not res . status : print ( \"Could not play gesture ' %s '.\" % sys . argv [ 1 ]) except rospy . ServiceException , e : print \"Service call failed: %s .\" % e","title":"**QTrobot Motors gesture**"},{"location":"examples/qt_motors_gesture/#qtrobot-motors-gesture","text":"Get the full code in our github tutorial repository. Code #!/usr/bin/env python ''' Copyright (C) 2018 LuxAI S.A Authors: Ali Paikan CopyPolicy: Released under the terms of the LGPLv2.1 or later, see LGPL.TXT ''' import rospy from qt_gesture_controller.srv import * def print_help (): print ( \"QTrobot gesture player example\" ) print ( \"Usage:\" ) print ( \" qt_motors_gesture <name> play a gesture given by its <name>\" ) print ( \"\" ) # main if __name__ == '__main__' : # check the params if len ( sys . argv ) < 2 : print_help () sys . exit ( 1 ) # call the relevant service rospy . init_node ( 'qt_motors_gesture' ) try : gesturePlay = rospy . ServiceProxy ( '/qt_robot/gesture/play' , gesture_play ) res = gesturePlay ( sys . argv [ 1 ], 1.0 ) if not res . status : print ( \"Could not play gesture ' %s '.\" % sys . argv [ 1 ]) except rospy . ServiceException , e : print \"Service call failed: %s .\" % e","title":"QTrobot Motors gesture"},{"location":"examples/qt_motors_state/","text":"QTrobot Motors state \u00b6 Get the full code in our github tutorial repository. Code #!/usr/bin/env python ''' Copyright (C) 2018 LuxAI S.A Authors: Ali Paikan CopyPolicy: Released under the terms of the LGPLv2.1 or later, see LGPL.TXT ''' import rospy from sensor_msgs.msg import JointState def joint_states_callback ( msg ): strmsg = \"\" for i , joint_name in enumerate ( msg . name ): strmsg += \" %s : %.2f , \" % ( joint_name , msg . position [ i ]) rospy . loginfo ( strmsg ) # main if __name__ == '__main__' : # call the relevant service rospy . init_node ( 'qt_motors_state' ) rospy . Subscriber ( '/qt_robot/joints/state' , JointState , joint_states_callback ) rospy . spin ()","title":"**QTrobot Motors state**"},{"location":"examples/qt_motors_state/#qtrobot-motors-state","text":"Get the full code in our github tutorial repository. Code #!/usr/bin/env python ''' Copyright (C) 2018 LuxAI S.A Authors: Ali Paikan CopyPolicy: Released under the terms of the LGPLv2.1 or later, see LGPL.TXT ''' import rospy from sensor_msgs.msg import JointState def joint_states_callback ( msg ): strmsg = \"\" for i , joint_name in enumerate ( msg . name ): strmsg += \" %s : %.2f , \" % ( joint_name , msg . position [ i ]) rospy . loginfo ( strmsg ) # main if __name__ == '__main__' : # call the relevant service rospy . init_node ( 'qt_motors_state' ) rospy . Subscriber ( '/qt_robot/joints/state' , JointState , joint_states_callback ) rospy . spin ()","title":"QTrobot Motors state"},{"location":"examples/qt_speech_interface/","text":"Accessing QTrobot speech interface with Python \u00b6 The QTrobot is using ROS for easier access to basic robot functionalities with ROS publish/subscriber and Service/Client interfaces. Rospy is a pure Python client library for ROS. The rospy client API enables Python programmers to quickly interface with ROS Topics, Services, and Parameters. We will use Python code to access QTrobot speech interface with rospy module.This interface implements QTrobot text to speech functionality which support many languages. The supported languages can be different for each robot, but for this example we will use American English (en-US). Speech interface is accessible with publish/subscribe and service/client methods. In this example we will use publish/subscribe method. You can also check \"4.1 Speech Interface\" chapter on Wiki ROS. First we should import rospy, QTrobot interface module and data type. Step 1 import sys import rospy from std_msgs.msg import String from qt_robot_interface.srv import * Next up we initialize ROS node and declare a name for it. To create a ROS publisher we need topic name, data type and size of our queue. Topic name for accessing QTrobot speech interface is \"/qt_robot/speech/say\" and data type is text \"String\". Step 2 # ros node rospy . init_node ( 'python_qt_example' ) # creating a ros publisher speechSay_pub = rospy . Publisher ( '/qt_robot/speech/say' , String , queue_size = 10 ) # waiting for connection establishment wtime_begin = rospy . get_time () while ( speechSay_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for publisher connection\" ) if rospy . get_time () - wtime_begin > 5.0 : rospy . logerr ( \"Timeout while waiting for publisher connection!\" ) sys . exit () rospy . sleep ( 1 ) To publish text to the QTrobot speech interface we need to call publish function of the ROS publisher(speechSay_pub) that we created. Step 3 # publish a text message to TTS speechSay_pub . publish ( \"Hello!\" ) NOTICE Default language is set in '/opt/ros/kinetic/share/qt_robot_interface/config/qtrobot-interface.yaml'. the default pitch is usually '140' and speed is '80'. When calling 'speech_config', leave pitch and speed parameters to '0' if you do not want to change them. Get the full code in our github tutorial repository.","title":"Accessing QTrobot speech interface with Python"},{"location":"examples/qt_speech_interface/#accessing-qtrobot-speech-interface-with-python","text":"The QTrobot is using ROS for easier access to basic robot functionalities with ROS publish/subscriber and Service/Client interfaces. Rospy is a pure Python client library for ROS. The rospy client API enables Python programmers to quickly interface with ROS Topics, Services, and Parameters. We will use Python code to access QTrobot speech interface with rospy module.This interface implements QTrobot text to speech functionality which support many languages. The supported languages can be different for each robot, but for this example we will use American English (en-US). Speech interface is accessible with publish/subscribe and service/client methods. In this example we will use publish/subscribe method. You can also check \"4.1 Speech Interface\" chapter on Wiki ROS. First we should import rospy, QTrobot interface module and data type. Step 1 import sys import rospy from std_msgs.msg import String from qt_robot_interface.srv import * Next up we initialize ROS node and declare a name for it. To create a ROS publisher we need topic name, data type and size of our queue. Topic name for accessing QTrobot speech interface is \"/qt_robot/speech/say\" and data type is text \"String\". Step 2 # ros node rospy . init_node ( 'python_qt_example' ) # creating a ros publisher speechSay_pub = rospy . Publisher ( '/qt_robot/speech/say' , String , queue_size = 10 ) # waiting for connection establishment wtime_begin = rospy . get_time () while ( speechSay_pub . get_num_connections () == 0 ) : rospy . loginfo ( \"waiting for publisher connection\" ) if rospy . get_time () - wtime_begin > 5.0 : rospy . logerr ( \"Timeout while waiting for publisher connection!\" ) sys . exit () rospy . sleep ( 1 ) To publish text to the QTrobot speech interface we need to call publish function of the ROS publisher(speechSay_pub) that we created. Step 3 # publish a text message to TTS speechSay_pub . publish ( \"Hello!\" ) NOTICE Default language is set in '/opt/ros/kinetic/share/qt_robot_interface/config/qtrobot-interface.yaml'. the default pitch is usually '140' and speed is '80'. When calling 'speech_config', leave pitch and speed parameters to '0' if you do not want to change them. Get the full code in our github tutorial repository.","title":"Accessing QTrobot speech interface with Python"},{"location":"examples/qt_voice_activity/","text":"QTrobot Voice activity \u00b6 Get the full code in our github tutorial repository. Code from tuning import Tuning import usb.core import usb.util import time if __name__ == '__main__' : dev = usb . core . find ( idVendor = 0x2886 , idProduct = 0x0018 ) if dev : Mic_tuning = Tuning ( dev ) while True : try : print ( \"Voice activity %d \" % Mic_tuning . is_voice ()) time . sleep ( 0.2 ) except KeyboardInterrupt : break","title":"**QTrobot Voice activity**"},{"location":"examples/qt_voice_activity/#qtrobot-voice-activity","text":"Get the full code in our github tutorial repository. Code from tuning import Tuning import usb.core import usb.util import time if __name__ == '__main__' : dev = usb . core . find ( idVendor = 0x2886 , idProduct = 0x0018 ) if dev : Mic_tuning = Tuning ( dev ) while True : try : print ( \"Voice activity %d \" % Mic_tuning . is_voice ()) time . sleep ( 0.2 ) except KeyboardInterrupt : break","title":"QTrobot Voice activity"},{"location":"examples/qt_voice_direction/","text":"QTrobot Voice direction \u00b6 Get the full code in our github tutorial repository. Code from tuning import Tuning import usb.core import usb.util import time if __name__ == '__main__' : dev = usb . core . find ( idVendor = 0x2886 , idProduct = 0x0018 ) if dev : Mic_tuning = Tuning ( dev ) while True : try : if Mic_tuning . is_voice (): print ( \"I detected voice activity at angle %d \" % Mic_tuning . direction ) time . sleep ( 0.2 ) except KeyboardInterrupt : break","title":"**QTrobot Voice direction**"},{"location":"examples/qt_voice_direction/#qtrobot-voice-direction","text":"Get the full code in our github tutorial repository. Code from tuning import Tuning import usb.core import usb.util import time if __name__ == '__main__' : dev = usb . core . find ( idVendor = 0x2886 , idProduct = 0x0018 ) if dev : Mic_tuning = Tuning ( dev ) while True : try : if Mic_tuning . is_voice (): print ( \"I detected voice activity at angle %d \" % Mic_tuning . direction ) time . sleep ( 0.2 ) except KeyboardInterrupt : break","title":"QTrobot Voice direction"}]}